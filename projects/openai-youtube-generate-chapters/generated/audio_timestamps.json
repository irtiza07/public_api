{
  "duration": 1167.56005859375,
  "language": "english",
  "text": "Hey guys, welcome back to the channel. Today, I'll show you how you can use OpenAI to analyze your images There are primarily two approaches. One is going to be through photo URL That's the one I'm using here. The URL can be from any domain. Typically, it's going to be on S3 for you and The other approach is to use Base64 encoded images So you take your image in this case if it is in a URL You download the image, you Base64 encode it, and then you send it to the OpenAI API But that's going to be less common. More common is going to be doing it through URL So that's what we're going to take a look at today So I have different categories of images here. I have got a few Pokemons Some images of people or groups of people some locations and then some some photos of people expressing certain emotions So we're going to go through a couple of these just to show you how the model Does well or poorly depending on the type of photo you'll feed it In terms of the model, we are going to use GPT-4.0, but you can use any model that OpenAI gives you. 4.0 in my opinion is a good balance between The speed with which it gets me a response and the quality of the response Okay, so let's get started. At first, let me just go through the Pokemon images So I'm gonna open a couple here. So you're gonna see Maybe we can go through these three, right? So you see a Bulbasaur, Squirtle, and Arcanine So if I go ahead and call the API that you see over here We're using the responses.create() function and then passing it an input text and the image itself For the input text, this is the question or the prompt you're giving to the model And then the input image is the URL or in other cases It can be the base64 encoded string. In our case, it's gonna be the URL So if I quickly run this and then I'm gonna print the output We might need to change this one to Bulbasaur at first and then let's run it Oops, I do need to change the prompt. So let's just say who's that Pokemon, right? Okay, that's gonna be better All right, so if we run it you're gonna see it takes a few seconds, but it identifies the Pokemon correctly Let's do a couple more. Maybe we can do Pikachu We'll give it a second again. There you go. It recognized it correctly and the last one we can do a Mudkip Mudkip There you go, it recognized all three Pokemons correctly. Now, let's move on to the next group Which is gonna be a photos of a bunch of people. So we're gonna look at two examples Okay, so we have this one where we have one, two, three, four people Lying in a picnic blanket. So I'm gonna use this photo. That's gonna be a group photo URL And the prompt I'm gonna tell it to count the number of people. How many people do you see in the image? Now if I run it, let's see how many it gets right It says there are four people in the image. If we go back to the image, we do see four people So I'm gonna run it again And see it says five people in the image. So this is one limitation I have found with the model, especially when you don't do any prompt engineering The model doesn't do very well when you tell it to count Different number of objects or people in an image. As you saw in in this photo We have four people and it's very clear But the model just in its second try it Identified five people. Now it's hard to say where did they identify the fifth people Maybe they're inferring this side of the image to be the fifth person But it's hard hard to say. If we run it again, we might get four or five Let's see what we get. We get four So I think on average I got the model to give me four more often than not But again, this is not something you can rely on Now let's do a slightly more complicated one Which is gonna be this many people one. So we see multiple people here even in my eyes. I'm not sure how many people There actually actually are there in the photo, but if you try to count it, I see one here one two three four five six seven eight nine Nine maybe ten eleven ish Let's try to see how many the model points So for photos like these where the responses can vary what you're looking for is the ballpark number like does it give you in the ballpark or Does it give you a totally absurd number? So they see ten people in the image I think we counted one two, three, four, five six, seven eight nine ten Eleven sort of eleven ish but the ones over here These are only feet of people. So maybe the model is not considering these people when counting so I'm gonna try to run it again and This time you're gonna see The Eleven people so that's what the model gets usually between 10 and 11 But just like the previous one it does not give me an exact number all the time Okay, so now let's move on to the next category of images which are location images So I have four images that I know where they're from and then I have one which is a random location This is a photo that that came straight from my Google Photos library okay, so I'm gonna start with the first one, which is a photo of a mosque in a Turkey and then I have a photo of Brazil and Then I've got one from my home country So the capital of my home country Dhaka. I Have one from the National Park Smoky Mountain this one I just want to see if it can actually get the Smoky Mountain National Park, or does it just give me a random National Park? and then a random location So this was from my trip during fall this year in Yosemite, California So I just wanted to see if we feed a random model without any context or a random image without any context How close does the model really get like does it say the photo is from California? Does it go as far into the exact location? We're gonna find out in a little bit So let's start with the first one So I'm gonna change the prompt and we're gonna say where was this photo taken? Okay, and then let's run it Okay And it identified the photo correctly it even it can even identify what mosque and Which bridge in the background, which is pretty cool. And now if we do the Brazil one Let's see what happens Give it a few seconds again Perfect. It got Brazil and it also gives you like a little bit of an information about how it's doing the inference So you can see it recognizes Sugarloaf Mountain Which helps it realize that this is a Brazil All right, let's keep going we're gonna try the other one which is gonna be Taka So just to show you the photo again This is a pretty random photo and you can find photos like these in most of Southeast Asia But maybe the the alphabets over here gives away whether it's Bangladesh or some other country But let's try running it through the model Okay, so it says in South Asian City likely Bangladesh and then it gives a little bit of description So the couple of times I've run it before it goes To something as specific as the city Taka, but in this case, it just narrows it down to the country Which is still pretty cool. So I'm gonna try to running it running it again And yeah, it keeps on getting the country but Yeah, it's a typical urban scene in Taka, but it's not as as strong as When it was recommending Turkey or Brazil Okay, awesome and now I will try running it with the GPT 5 model because I have seen the GPT 5 model even though it takes a lot longer it can give you a much More accurate description of the image. So let me come to that in a little bit before that Let's try this Smoky Mountain photo and the one from California So let's start with Smoky Mountain again And what we're looking for is does it just randomly say National Park or does it get the exact National Park It gets the Great Smoky Mountains, which is pretty cool. And then let's try to run it again Again it's very confident that it's getting Great Smoky Mountain Which I found super cool because when I looked at the photo it could have been any National Park in the US Okay, again, I think this gives sort of an idea Why it thinks it's the Great Smoky Mountain and it says that it sees the Clingmans dome which is Do we have it here? Which is I think somewhere over here So yeah, it does a pretty good job Now the last one we have is the random location just to remind you This is from my trip in this fall in California Yosemite So I want to see how close does it get we're just gonna give random location Okay Yeah, it got Auto Camp Yosemite, which is the exact Glamping location that we spend night or two in our trip Which is really cool because when you look at different Auto Camp locations across the US they look very very similar So I'm quite surprised that it understands not only that this is an Auto Camp location But the fact that it is from Yosemite I've run through this multiple times like 10 to 12 time and I think almost every time I got the model to say Auto Camp Yosemite, which is pretty cool. So I'm gonna run it again, maybe three times in total To see if it stays consistent Okay, no, so now it doesn't understand that it is from Yosemite so this is where prompt engineering can come in So if you write your prompt in a way where you almost forced a model to give you a city location Most likely it will narrow it down to Yosemite But at that point you risk the model also giving you a city Answer when it's not too sure but only because you forced it through the prompt but this is interesting because Multiple times I've run it before Every time it told me Auto Camp Yosemite. Now you can see it cannot even determine the location of From the image, right? So again similar to the counting problem. You can see like these models are very Non-deterministic so you cannot always rely on it giving you the same answer every single time Ideally you want to get a ballpark idea of what the answer could be and then you want to write your prompt in such a way that you always Give it sort of in structure to follow when giving you an answer All right, and then let me not run it again, but I'll move back over here now So if you remember for the Dhaka one every time it was narrowing it down to Bangladesh And then for the random for the random one it as you saw sometimes it does not even notice that this is in Yosemite So I'm gonna try these two again, but with a much more powerful model now to to see what happens Okay, so we're gonna try GPT 5 and then we're gonna go back to the Dhaka URL Now, let's see what happens So this will take a little longer so just bear with me here So whenever you're using a powerful model, it's always gonna take a lot longer similarly You saw how long it takes with the GPT 4.0 model But if we're using a much less powerful model, it's gonna give you an answer much quicker So now you're seeing it does say likely Dhaka Bangladesh. I'm gonna run it again To see if it gets me to Dhaka again Give it a few seconds again And while we while we wait for the response, let me go and remind you this is the photo we're working through And They get it again. Yeah, it got it again, which is pretty cool So you can see sort of that when you use a powerful model the responses Yes, they are slower, but they tend to be a lot more accurate than than 4.0 in our case Now the one I really want to try is the Yosemite one because if you remember We tried with like five times and it only got it two times. I want to see if with GPT 5 we have better odds So While we wait again just to remind you this is what we're aiming for. This is the photo that we're processing Yep, it's very direct AutoCAM Yosemite and it even goes as deep as mid pines, California, which is the exact city Run it again So Yeah, the five model always takes a lot longer than 4.0 But let's keep waiting until we get the response Yep both times this time it did not get mid pines But it get it did get a city closer or close which is a Mariposa All right, so I think we can fairly at least from our examples Oh, we can really conclude that a GPT 5 is getting as a better response or more accurate response But it is taking significantly longer than the other model So I'm gonna move back to our 4.0 model and then let's wrap up by looking at these People faces emotions photos. Okay. I've got four over here. Let's take a look. We have a screaming one from unsplash We got a person who is sad frustrated We have got someone who's happy and then we have got someone who's crying Okay, all these all four are taken from unsplash So let's run through them one by one. So we're gonna change the prompt to What emotion do you see in the image? And then let's start with the screaming one Okay This will be quicker because we have switched back to the 4.0 model But it will come at the trade-off of a poor quality responses Okay, let's say it says emotions such as excitement joy or surprise a which it's fairly accurate because when I looked at the photo Let's go back to it Even I wasn't sure about the emotion so you can see like the model not trying too hard to get you one response Now let's move to the second one, which is a lot more clear So we're gonna try the sad face Or anxious, so let's try running it here Yeah, it gets that stress and frustration part which is pretty cool and then we're gonna try the smiling face And the reason I'm not rerunning for the same photo is when I did it before it was always the same Which is pretty cool Yes, joy or happiness and if I run it again most likely you're gonna see the same response Yep, there you go, and then we're gonna try the final one which is the crying face. This is the one All right And it's sadness or distress and it was fairly consistent when I ran it before Yeah, so I think in conclusion You're gonna see that the model does very well with emotions location was really good as well Something as specific as Pokemon did amazingly when it comes to counting it did not do too Well for locations the 4o model did not do too. Well if there weren't any landmarks present in the photo but when I switched to the GPT 5 model, it was doing really well, even though the even though the Response was a lot longer or it took a lot longer So hopefully this was helpful. I will have both the github github repo and a blog post linked in the description below if you want to check it out And yeah, I'll catch y'all in the next one. Take care. Bye. Bye",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.3519589900970459,
      "compression_ratio": 1.495575189590454,
      "end": 6.199999809265137,
      "no_speech_prob": 0.02708214335143566,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " Hey guys, welcome back to the channel. Today, I'll show you how you can use OpenAI to analyze your images",
      "tokens": [
        50364,
        1911,
        1074,
        11,
        2928,
        646,
        281,
        264,
        2269,
        13,
        2692,
        11,
        286,
        603,
        855,
        291,
        577,
        291,
        393,
        764,
        7238,
        48698,
        281,
        12477,
        428,
        5267,
        50674
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.3519589900970459,
      "compression_ratio": 1.495575189590454,
      "end": 11.5600004196167,
      "no_speech_prob": 0.02708214335143566,
      "seek": 0,
      "start": 6.760000228881836,
      "temperature": 0.0,
      "text": " There are primarily two approaches. One is going to be through photo URL",
      "tokens": [
        50702,
        821,
        366,
        10029,
        732,
        11587,
        13,
        1485,
        307,
        516,
        281,
        312,
        807,
        5052,
        12905,
        50942
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.3519589900970459,
      "compression_ratio": 1.495575189590454,
      "end": 17.5,
      "no_speech_prob": 0.02708214335143566,
      "seek": 0,
      "start": 11.899999618530273,
      "temperature": 0.0,
      "text": " That's the one I'm using here. The URL can be from any domain. Typically, it's going to be on",
      "tokens": [
        50959,
        663,
        311,
        264,
        472,
        286,
        478,
        1228,
        510,
        13,
        440,
        12905,
        393,
        312,
        490,
        604,
        9274,
        13,
        23129,
        11,
        309,
        311,
        516,
        281,
        312,
        322,
        51239
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.3519589900970459,
      "compression_ratio": 1.495575189590454,
      "end": 20.520000457763672,
      "no_speech_prob": 0.02708214335143566,
      "seek": 0,
      "start": 18.639999389648438,
      "temperature": 0.0,
      "text": " S3 for you and",
      "tokens": [
        51296,
        318,
        18,
        337,
        291,
        293,
        51390
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.3519589900970459,
      "compression_ratio": 1.495575189590454,
      "end": 24.719999313354492,
      "no_speech_prob": 0.02708214335143566,
      "seek": 0,
      "start": 20.520000457763672,
      "temperature": 0.0,
      "text": " The other approach is to use Base64 encoded images",
      "tokens": [
        51390,
        440,
        661,
        3109,
        307,
        281,
        764,
        21054,
        19395,
        2058,
        12340,
        5267,
        51600
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.3149932622909546,
      "compression_ratio": 1.6951220035552979,
      "end": 28.479999542236328,
      "no_speech_prob": 0.09002400189638138,
      "seek": 2472,
      "start": 24.84000015258789,
      "temperature": 0.0,
      "text": " So you take your image in this case if it is in a URL",
      "tokens": [
        50370,
        407,
        291,
        747,
        428,
        3256,
        294,
        341,
        1389,
        498,
        309,
        307,
        294,
        257,
        12905,
        50552
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.3149932622909546,
      "compression_ratio": 1.6951220035552979,
      "end": 35.040000915527344,
      "no_speech_prob": 0.09002400189638138,
      "seek": 2472,
      "start": 28.920000076293945,
      "temperature": 0.0,
      "text": " You download the image, you Base64 encode it, and then you send it to the OpenAI API",
      "tokens": [
        50574,
        509,
        5484,
        264,
        3256,
        11,
        291,
        21054,
        19395,
        2058,
        1429,
        309,
        11,
        293,
        550,
        291,
        2845,
        309,
        281,
        264,
        7238,
        48698,
        9362,
        50880
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.3149932622909546,
      "compression_ratio": 1.6951220035552979,
      "end": 39.47999954223633,
      "no_speech_prob": 0.09002400189638138,
      "seek": 2472,
      "start": 35.63999938964844,
      "temperature": 0.0,
      "text": " But that's going to be less common. More common is going to be doing it through URL",
      "tokens": [
        50910,
        583,
        300,
        311,
        516,
        281,
        312,
        1570,
        2689,
        13,
        5048,
        2689,
        307,
        516,
        281,
        312,
        884,
        309,
        807,
        12905,
        51102
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.3149932622909546,
      "compression_ratio": 1.6951220035552979,
      "end": 41.47999954223633,
      "no_speech_prob": 0.09002400189638138,
      "seek": 2472,
      "start": 39.47999954223633,
      "temperature": 0.0,
      "text": " So that's what we're going to take a look at today",
      "tokens": [
        51102,
        407,
        300,
        311,
        437,
        321,
        434,
        516,
        281,
        747,
        257,
        574,
        412,
        965,
        51202
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.3149932622909546,
      "compression_ratio": 1.6951220035552979,
      "end": 46.91999816894531,
      "no_speech_prob": 0.09002400189638138,
      "seek": 2472,
      "start": 42.47999954223633,
      "temperature": 0.0,
      "text": " So I have different categories of images here. I have got a few Pokemons",
      "tokens": [
        51252,
        407,
        286,
        362,
        819,
        10479,
        295,
        5267,
        510,
        13,
        286,
        362,
        658,
        257,
        1326,
        12645,
        27229,
        51474
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.3149932622909546,
      "compression_ratio": 1.6951220035552979,
      "end": 50.41999816894531,
      "no_speech_prob": 0.09002400189638138,
      "seek": 2472,
      "start": 47.84000015258789,
      "temperature": 0.0,
      "text": " Some images of people or groups of people",
      "tokens": [
        51520,
        2188,
        5267,
        295,
        561,
        420,
        3935,
        295,
        561,
        51649
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.3149932622909546,
      "compression_ratio": 1.6951220035552979,
      "end": 53.52000045776367,
      "no_speech_prob": 0.09002400189638138,
      "seek": 2472,
      "start": 51.119998931884766,
      "temperature": 0.0,
      "text": " some locations and then some",
      "tokens": [
        51684,
        512,
        9253,
        293,
        550,
        512,
        51804
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.3493427634239197,
      "compression_ratio": 1.5089285373687744,
      "end": 55.91999816894531,
      "no_speech_prob": 9.027673513628542e-05,
      "seek": 5352,
      "start": 54.0,
      "temperature": 0.0,
      "text": " some photos of people",
      "tokens": [
        50388,
        512,
        5787,
        295,
        561,
        50484
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.3493427634239197,
      "compression_ratio": 1.5089285373687744,
      "end": 57.91999816894531,
      "no_speech_prob": 9.027673513628542e-05,
      "seek": 5352,
      "start": 55.91999816894531,
      "temperature": 0.0,
      "text": " expressing certain emotions",
      "tokens": [
        50484,
        22171,
        1629,
        8462,
        50584
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.3493427634239197,
      "compression_ratio": 1.5089285373687744,
      "end": 61.70000076293945,
      "no_speech_prob": 9.027673513628542e-05,
      "seek": 5352,
      "start": 57.959999084472656,
      "temperature": 0.0,
      "text": " So we're going to go through a couple of these just to show you how the model",
      "tokens": [
        50586,
        407,
        321,
        434,
        516,
        281,
        352,
        807,
        257,
        1916,
        295,
        613,
        445,
        281,
        855,
        291,
        577,
        264,
        2316,
        50773
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.3493427634239197,
      "compression_ratio": 1.5089285373687744,
      "end": 67.12000274658203,
      "no_speech_prob": 9.027673513628542e-05,
      "seek": 5352,
      "start": 62.31999969482422,
      "temperature": 0.0,
      "text": " Does well or poorly depending on the type of photo you'll feed it",
      "tokens": [
        50804,
        4402,
        731,
        420,
        22271,
        5413,
        322,
        264,
        2010,
        295,
        5052,
        291,
        603,
        3154,
        309,
        51044
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.3493427634239197,
      "compression_ratio": 1.5089285373687744,
      "end": 73.87999725341797,
      "no_speech_prob": 9.027673513628542e-05,
      "seek": 5352,
      "start": 68.19999694824219,
      "temperature": 0.0,
      "text": " In terms of the model, we are going to use GPT-4.0, but you can use any model that",
      "tokens": [
        51098,
        682,
        2115,
        295,
        264,
        2316,
        11,
        321,
        366,
        516,
        281,
        764,
        26039,
        51,
        12,
        19,
        13,
        15,
        11,
        457,
        291,
        393,
        764,
        604,
        2316,
        300,
        51382
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.3493427634239197,
      "compression_ratio": 1.5089285373687744,
      "end": 79.83999633789062,
      "no_speech_prob": 9.027673513628542e-05,
      "seek": 5352,
      "start": 74.83999633789062,
      "temperature": 0.0,
      "text": " OpenAI gives you. 4.0 in my opinion is a good balance between",
      "tokens": [
        51430,
        7238,
        48698,
        2709,
        291,
        13,
        1017,
        13,
        15,
        294,
        452,
        4800,
        307,
        257,
        665,
        4772,
        1296,
        51680
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.28782716393470764,
      "compression_ratio": 1.5638766288757324,
      "end": 85.63999938964844,
      "no_speech_prob": 0.00026945825084112585,
      "seek": 7984,
      "start": 80.4000015258789,
      "temperature": 0.0,
      "text": " The speed with which it gets me a response and the quality of the response",
      "tokens": [
        50392,
        440,
        3073,
        365,
        597,
        309,
        2170,
        385,
        257,
        4134,
        293,
        264,
        3125,
        295,
        264,
        4134,
        50654
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.28782716393470764,
      "compression_ratio": 1.5638766288757324,
      "end": 91.0,
      "no_speech_prob": 0.00026945825084112585,
      "seek": 7984,
      "start": 86.4800033569336,
      "temperature": 0.0,
      "text": " Okay, so let's get started. At first, let me just go through the Pokemon images",
      "tokens": [
        50696,
        1033,
        11,
        370,
        718,
        311,
        483,
        1409,
        13,
        1711,
        700,
        11,
        718,
        385,
        445,
        352,
        807,
        264,
        13796,
        5267,
        50922
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.28782716393470764,
      "compression_ratio": 1.5638766288757324,
      "end": 94.31999969482422,
      "no_speech_prob": 0.00026945825084112585,
      "seek": 7984,
      "start": 91.16000366210938,
      "temperature": 0.0,
      "text": " So I'm gonna open a couple here. So you're gonna see",
      "tokens": [
        50930,
        407,
        286,
        478,
        799,
        1269,
        257,
        1916,
        510,
        13,
        407,
        291,
        434,
        799,
        536,
        51088
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.28782716393470764,
      "compression_ratio": 1.5638766288757324,
      "end": 102.55999755859375,
      "no_speech_prob": 0.00026945825084112585,
      "seek": 7984,
      "start": 96.04000091552734,
      "temperature": 0.0,
      "text": " Maybe we can go through these three, right? So you see a Bulbasaur, Squirtle, and Arcanine",
      "tokens": [
        51174,
        2704,
        321,
        393,
        352,
        807,
        613,
        1045,
        11,
        558,
        30,
        407,
        291,
        536,
        257,
        19825,
        16342,
        3463,
        11,
        8683,
        2498,
        306,
        11,
        293,
        1587,
        7035,
        533,
        51500
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.28782716393470764,
      "compression_ratio": 1.5638766288757324,
      "end": 108.4000015258789,
      "no_speech_prob": 0.00026945825084112585,
      "seek": 7984,
      "start": 104.08000183105469,
      "temperature": 0.0,
      "text": " So if I go ahead and call the API that you see over here",
      "tokens": [
        51576,
        407,
        498,
        286,
        352,
        2286,
        293,
        818,
        264,
        9362,
        300,
        291,
        536,
        670,
        510,
        51792
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.2808016240596771,
      "compression_ratio": 1.6606334447860718,
      "end": 117.27999877929688,
      "no_speech_prob": 4.9086233048001304e-05,
      "seek": 10840,
      "start": 109.16000366210938,
      "temperature": 0.0,
      "text": " We're using the responses.create() function and then passing it an input text and the image itself",
      "tokens": [
        50402,
        492,
        434,
        1228,
        264,
        13019,
        13,
        14066,
        473,
        45191,
        2445,
        293,
        550,
        8437,
        309,
        364,
        4846,
        2487,
        293,
        264,
        3256,
        2564,
        50808
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.2808016240596771,
      "compression_ratio": 1.6606334447860718,
      "end": 122.19999694824219,
      "no_speech_prob": 4.9086233048001304e-05,
      "seek": 10840,
      "start": 117.76000213623047,
      "temperature": 0.0,
      "text": " For the input text, this is the question or the prompt you're giving to the model",
      "tokens": [
        50832,
        1171,
        264,
        4846,
        2487,
        11,
        341,
        307,
        264,
        1168,
        420,
        264,
        12391,
        291,
        434,
        2902,
        281,
        264,
        2316,
        51054
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.2808016240596771,
      "compression_ratio": 1.6606334447860718,
      "end": 126.80000305175781,
      "no_speech_prob": 4.9086233048001304e-05,
      "seek": 10840,
      "start": 122.19999694824219,
      "temperature": 0.0,
      "text": " And then the input image is the URL or in other cases",
      "tokens": [
        51054,
        400,
        550,
        264,
        4846,
        3256,
        307,
        264,
        12905,
        420,
        294,
        661,
        3331,
        51284
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.2808016240596771,
      "compression_ratio": 1.6606334447860718,
      "end": 132.16000366210938,
      "no_speech_prob": 4.9086233048001304e-05,
      "seek": 10840,
      "start": 126.80000305175781,
      "temperature": 0.0,
      "text": " It can be the base64 encoded string. In our case, it's gonna be the URL",
      "tokens": [
        51284,
        467,
        393,
        312,
        264,
        3096,
        19395,
        2058,
        12340,
        6798,
        13,
        682,
        527,
        1389,
        11,
        309,
        311,
        799,
        312,
        264,
        12905,
        51552
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.2808016240596771,
      "compression_ratio": 1.6606334447860718,
      "end": 135.8800048828125,
      "no_speech_prob": 4.9086233048001304e-05,
      "seek": 10840,
      "start": 132.8800048828125,
      "temperature": 0.0,
      "text": " So if I quickly run this and then I'm gonna print the output",
      "tokens": [
        51588,
        407,
        498,
        286,
        2661,
        1190,
        341,
        293,
        550,
        286,
        478,
        799,
        4482,
        264,
        5598,
        51738
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.2956058084964752,
      "compression_ratio": 1.3525179624557495,
      "end": 146.8800048828125,
      "no_speech_prob": 0.001700588851235807,
      "seek": 13840,
      "start": 138.83999633789062,
      "temperature": 0.0,
      "text": " We might need to change this one to Bulbasaur at first and then let's run it",
      "tokens": [
        50386,
        492,
        1062,
        643,
        281,
        1319,
        341,
        472,
        281,
        19825,
        16342,
        3463,
        412,
        700,
        293,
        550,
        718,
        311,
        1190,
        309,
        50788
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.2956058084964752,
      "compression_ratio": 1.3525179624557495,
      "end": 157.60000610351562,
      "no_speech_prob": 0.001700588851235807,
      "seek": 13840,
      "start": 152.0399932861328,
      "temperature": 0.0,
      "text": " Oops, I do need to change the prompt. So let's just say who's that Pokemon, right?",
      "tokens": [
        51046,
        21726,
        11,
        286,
        360,
        643,
        281,
        1319,
        264,
        12391,
        13,
        407,
        718,
        311,
        445,
        584,
        567,
        311,
        300,
        13796,
        11,
        558,
        30,
        51324
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.2956058084964752,
      "compression_ratio": 1.3525179624557495,
      "end": 161.44000244140625,
      "no_speech_prob": 0.001700588851235807,
      "seek": 13840,
      "start": 159.44000244140625,
      "temperature": 0.0,
      "text": " Okay, that's gonna be better",
      "tokens": [
        51416,
        1033,
        11,
        300,
        311,
        799,
        312,
        1101,
        51516
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.2953413724899292,
      "compression_ratio": 1.4475138187408447,
      "end": 170.27999877929688,
      "no_speech_prob": 0.0009253118187189102,
      "seek": 16144,
      "start": 162.44000244140625,
      "temperature": 0.0,
      "text": " All right, so if we run it you're gonna see it takes a few seconds, but it identifies the Pokemon correctly",
      "tokens": [
        50414,
        1057,
        558,
        11,
        370,
        498,
        321,
        1190,
        309,
        291,
        434,
        799,
        536,
        309,
        2516,
        257,
        1326,
        3949,
        11,
        457,
        309,
        34597,
        264,
        13796,
        8944,
        50806
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.2953413724899292,
      "compression_ratio": 1.4475138187408447,
      "end": 173.27999877929688,
      "no_speech_prob": 0.0009253118187189102,
      "seek": 16144,
      "start": 170.72000122070312,
      "temperature": 0.0,
      "text": " Let's do a couple more. Maybe we can do Pikachu",
      "tokens": [
        50828,
        961,
        311,
        360,
        257,
        1916,
        544,
        13,
        2704,
        321,
        393,
        360,
        35785,
        50956
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.2953413724899292,
      "compression_ratio": 1.4475138187408447,
      "end": 183.39999389648438,
      "no_speech_prob": 0.0009253118187189102,
      "seek": 16144,
      "start": 176.72000122070312,
      "temperature": 0.0,
      "text": " We'll give it a second again. There you go. It recognized it correctly and the last one we can do a Mudkip",
      "tokens": [
        51128,
        492,
        603,
        976,
        309,
        257,
        1150,
        797,
        13,
        821,
        291,
        352,
        13,
        467,
        9823,
        309,
        8944,
        293,
        264,
        1036,
        472,
        321,
        393,
        360,
        257,
        39231,
        74,
        647,
        51462
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.3241390287876129,
      "compression_ratio": 1.5401785373687744,
      "end": 185.39999389648438,
      "no_speech_prob": 0.0017545187147334218,
      "seek": 18340,
      "start": 183.39999389648438,
      "temperature": 0.0,
      "text": " Mudkip",
      "tokens": [
        50364,
        39231,
        74,
        647,
        50464
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.3241390287876129,
      "compression_ratio": 1.5401785373687744,
      "end": 195.72000122070312,
      "no_speech_prob": 0.0017545187147334218,
      "seek": 18340,
      "start": 190.83999633789062,
      "temperature": 0.0,
      "text": " There you go, it recognized all three Pokemons correctly. Now, let's move on to the next group",
      "tokens": [
        50736,
        821,
        291,
        352,
        11,
        309,
        9823,
        439,
        1045,
        12645,
        27229,
        8944,
        13,
        823,
        11,
        718,
        311,
        1286,
        322,
        281,
        264,
        958,
        1594,
        50980
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.3241390287876129,
      "compression_ratio": 1.5401785373687744,
      "end": 200.47999572753906,
      "no_speech_prob": 0.0017545187147334218,
      "seek": 18340,
      "start": 195.72000122070312,
      "temperature": 0.0,
      "text": " Which is gonna be a photos of a bunch of people. So we're gonna look at two examples",
      "tokens": [
        50980,
        3013,
        307,
        799,
        312,
        257,
        5787,
        295,
        257,
        3840,
        295,
        561,
        13,
        407,
        321,
        434,
        799,
        574,
        412,
        732,
        5110,
        51218
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.3241390287876129,
      "compression_ratio": 1.5401785373687744,
      "end": 205.75999450683594,
      "no_speech_prob": 0.0017545187147334218,
      "seek": 18340,
      "start": 201.55999755859375,
      "temperature": 0.0,
      "text": " Okay, so we have this one where we have one, two, three, four people",
      "tokens": [
        51272,
        1033,
        11,
        370,
        321,
        362,
        341,
        472,
        689,
        321,
        362,
        472,
        11,
        732,
        11,
        1045,
        11,
        1451,
        561,
        51482
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.3241390287876129,
      "compression_ratio": 1.5401785373687744,
      "end": 212.55999755859375,
      "no_speech_prob": 0.0017545187147334218,
      "seek": 18340,
      "start": 206.55999755859375,
      "temperature": 0.0,
      "text": " Lying in a picnic blanket. So I'm gonna use this photo. That's gonna be a group photo URL",
      "tokens": [
        51522,
        441,
        1840,
        294,
        257,
        32137,
        17907,
        13,
        407,
        286,
        478,
        799,
        764,
        341,
        5052,
        13,
        663,
        311,
        799,
        312,
        257,
        1594,
        5052,
        12905,
        51822
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.26529523730278015,
      "compression_ratio": 1.6213017702102661,
      "end": 219.9199981689453,
      "no_speech_prob": 0.0009108909871429205,
      "seek": 21256,
      "start": 212.8000030517578,
      "temperature": 0.0,
      "text": " And the prompt I'm gonna tell it to count the number of people. How many people do you see in the image?",
      "tokens": [
        50376,
        400,
        264,
        12391,
        286,
        478,
        799,
        980,
        309,
        281,
        1207,
        264,
        1230,
        295,
        561,
        13,
        1012,
        867,
        561,
        360,
        291,
        536,
        294,
        264,
        3256,
        30,
        50732
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.26529523730278015,
      "compression_ratio": 1.6213017702102661,
      "end": 231.27999877929688,
      "no_speech_prob": 0.0009108909871429205,
      "seek": 21256,
      "start": 227.39999389648438,
      "temperature": 0.0,
      "text": " Now if I run it, let's see how many it gets right",
      "tokens": [
        51106,
        823,
        498,
        286,
        1190,
        309,
        11,
        718,
        311,
        536,
        577,
        867,
        309,
        2170,
        558,
        51300
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.26529523730278015,
      "compression_ratio": 1.6213017702102661,
      "end": 236.32000732421875,
      "no_speech_prob": 0.0009108909871429205,
      "seek": 21256,
      "start": 231.52000427246094,
      "temperature": 0.0,
      "text": " It says there are four people in the image. If we go back to the image, we do see four people",
      "tokens": [
        51312,
        467,
        1619,
        456,
        366,
        1451,
        561,
        294,
        264,
        3256,
        13,
        759,
        321,
        352,
        646,
        281,
        264,
        3256,
        11,
        321,
        360,
        536,
        1451,
        561,
        51552
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.26529523730278015,
      "compression_ratio": 1.6213017702102661,
      "end": 239.0399932861328,
      "no_speech_prob": 0.0009108909871429205,
      "seek": 21256,
      "start": 237.0399932861328,
      "temperature": 0.0,
      "text": " So I'm gonna run it again",
      "tokens": [
        51588,
        407,
        286,
        478,
        799,
        1190,
        309,
        797,
        51688
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.2983478307723999,
      "compression_ratio": 1.6470588445663452,
      "end": 246.63999938964844,
      "no_speech_prob": 0.0005033175111748278,
      "seek": 24256,
      "start": 242.55999755859375,
      "temperature": 0.0,
      "text": " And see it says five people in the image. So this is one limitation",
      "tokens": [
        50364,
        400,
        536,
        309,
        1619,
        1732,
        561,
        294,
        264,
        3256,
        13,
        407,
        341,
        307,
        472,
        27432,
        50568
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.2983478307723999,
      "compression_ratio": 1.6470588445663452,
      "end": 251.36000061035156,
      "no_speech_prob": 0.0005033175111748278,
      "seek": 24256,
      "start": 246.63999938964844,
      "temperature": 0.0,
      "text": " I have found with the model, especially when you don't do any prompt engineering",
      "tokens": [
        50568,
        286,
        362,
        1352,
        365,
        264,
        2316,
        11,
        2318,
        562,
        291,
        500,
        380,
        360,
        604,
        12391,
        7043,
        50804
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.2983478307723999,
      "compression_ratio": 1.6470588445663452,
      "end": 255.60000610351562,
      "no_speech_prob": 0.0005033175111748278,
      "seek": 24256,
      "start": 251.8000030517578,
      "temperature": 0.0,
      "text": " The model doesn't do very well when you tell it to count",
      "tokens": [
        50826,
        440,
        2316,
        1177,
        380,
        360,
        588,
        731,
        562,
        291,
        980,
        309,
        281,
        1207,
        51016
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.2983478307723999,
      "compression_ratio": 1.6470588445663452,
      "end": 262.3999938964844,
      "no_speech_prob": 0.0005033175111748278,
      "seek": 24256,
      "start": 256.32000732421875,
      "temperature": 0.0,
      "text": " Different number of objects or people in an image. As you saw in in this photo",
      "tokens": [
        51052,
        20825,
        1230,
        295,
        6565,
        420,
        561,
        294,
        364,
        3256,
        13,
        1018,
        291,
        1866,
        294,
        294,
        341,
        5052,
        51356
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.2983478307723999,
      "compression_ratio": 1.6470588445663452,
      "end": 264.3999938964844,
      "no_speech_prob": 0.0005033175111748278,
      "seek": 24256,
      "start": 262.3999938964844,
      "temperature": 0.0,
      "text": " We have four people and it's very clear",
      "tokens": [
        51356,
        492,
        362,
        1451,
        561,
        293,
        309,
        311,
        588,
        1850,
        51456
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.2983478307723999,
      "compression_ratio": 1.6470588445663452,
      "end": 267.1199951171875,
      "no_speech_prob": 0.0005033175111748278,
      "seek": 24256,
      "start": 264.67999267578125,
      "temperature": 0.0,
      "text": " But the model just in its second try it",
      "tokens": [
        51470,
        583,
        264,
        2316,
        445,
        294,
        1080,
        1150,
        853,
        309,
        51592
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.26026904582977295,
      "compression_ratio": 1.7079646587371826,
      "end": 272.9599914550781,
      "no_speech_prob": 0.006902900990098715,
      "seek": 26712,
      "start": 268.0,
      "temperature": 0.0,
      "text": " Identified five people. Now it's hard to say where did they identify the fifth people",
      "tokens": [
        50408,
        25905,
        2587,
        1732,
        561,
        13,
        823,
        309,
        311,
        1152,
        281,
        584,
        689,
        630,
        436,
        5876,
        264,
        9266,
        561,
        50656
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.26026904582977295,
      "compression_ratio": 1.7079646587371826,
      "end": 278.239990234375,
      "no_speech_prob": 0.006902900990098715,
      "seek": 26712,
      "start": 272.9599914550781,
      "temperature": 0.0,
      "text": " Maybe they're inferring this side of the image to be the fifth person",
      "tokens": [
        50656,
        2704,
        436,
        434,
        13596,
        2937,
        341,
        1252,
        295,
        264,
        3256,
        281,
        312,
        264,
        9266,
        954,
        50920
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.26026904582977295,
      "compression_ratio": 1.7079646587371826,
      "end": 284.3599853515625,
      "no_speech_prob": 0.006902900990098715,
      "seek": 26712,
      "start": 278.5199890136719,
      "temperature": 0.0,
      "text": " But it's hard hard to say. If we run it again, we might get four or five",
      "tokens": [
        50934,
        583,
        309,
        311,
        1152,
        1152,
        281,
        584,
        13,
        759,
        321,
        1190,
        309,
        797,
        11,
        321,
        1062,
        483,
        1451,
        420,
        1732,
        51226
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.26026904582977295,
      "compression_ratio": 1.7079646587371826,
      "end": 286.3999938964844,
      "no_speech_prob": 0.006902900990098715,
      "seek": 26712,
      "start": 284.3599853515625,
      "temperature": 0.0,
      "text": " Let's see what we get. We get four",
      "tokens": [
        51226,
        961,
        311,
        536,
        437,
        321,
        483,
        13,
        492,
        483,
        1451,
        51328
      ]
    },
    {
      "id": 53,
      "avg_logprob": -0.26026904582977295,
      "compression_ratio": 1.7079646587371826,
      "end": 291.1199951171875,
      "no_speech_prob": 0.006902900990098715,
      "seek": 26712,
      "start": 286.3999938964844,
      "temperature": 0.0,
      "text": " So I think on average I got the model to give me four more often than not",
      "tokens": [
        51328,
        407,
        286,
        519,
        322,
        4274,
        286,
        658,
        264,
        2316,
        281,
        976,
        385,
        1451,
        544,
        2049,
        813,
        406,
        51564
      ]
    },
    {
      "id": 54,
      "avg_logprob": -0.26026904582977295,
      "compression_ratio": 1.7079646587371826,
      "end": 293.79998779296875,
      "no_speech_prob": 0.006902900990098715,
      "seek": 26712,
      "start": 291.32000732421875,
      "temperature": 0.0,
      "text": " But again, this is not something you can rely on",
      "tokens": [
        51574,
        583,
        797,
        11,
        341,
        307,
        406,
        746,
        291,
        393,
        10687,
        322,
        51698
      ]
    },
    {
      "id": 55,
      "avg_logprob": -0.5392106771469116,
      "compression_ratio": 1.5631579160690308,
      "end": 297.67999267578125,
      "no_speech_prob": 0.008311718702316284,
      "seek": 29380,
      "start": 294.32000732421875,
      "temperature": 0.0,
      "text": " Now let's do a slightly more complicated one",
      "tokens": [
        50390,
        823,
        718,
        311,
        360,
        257,
        4748,
        544,
        6179,
        472,
        50558
      ]
    },
    {
      "id": 56,
      "avg_logprob": -0.5392106771469116,
      "compression_ratio": 1.5631579160690308,
      "end": 304.760009765625,
      "no_speech_prob": 0.008311718702316284,
      "seek": 29380,
      "start": 298.44000244140625,
      "temperature": 0.0,
      "text": " Which is gonna be this many people one. So we see multiple people here even in my eyes. I'm not sure how many people",
      "tokens": [
        50596,
        3013,
        307,
        799,
        312,
        341,
        867,
        561,
        472,
        13,
        407,
        321,
        536,
        3866,
        561,
        510,
        754,
        294,
        452,
        2575,
        13,
        286,
        478,
        406,
        988,
        577,
        867,
        561,
        50912
      ]
    },
    {
      "id": 57,
      "avg_logprob": -0.5392106771469116,
      "compression_ratio": 1.5631579160690308,
      "end": 312.760009765625,
      "no_speech_prob": 0.008311718702316284,
      "seek": 29380,
      "start": 305.4800109863281,
      "temperature": 0.0,
      "text": " There actually actually are there in the photo, but if you try to count it, I see one here one two",
      "tokens": [
        50948,
        821,
        767,
        767,
        366,
        456,
        294,
        264,
        5052,
        11,
        457,
        498,
        291,
        853,
        281,
        1207,
        309,
        11,
        286,
        536,
        472,
        510,
        472,
        732,
        51312
      ]
    },
    {
      "id": 58,
      "avg_logprob": -0.5392106771469116,
      "compression_ratio": 1.5631579160690308,
      "end": 317.0799865722656,
      "no_speech_prob": 0.008311718702316284,
      "seek": 29380,
      "start": 313.6400146484375,
      "temperature": 0.0,
      "text": " three four five six seven",
      "tokens": [
        51356,
        1045,
        1451,
        1732,
        2309,
        3407,
        51528
      ]
    },
    {
      "id": 59,
      "avg_logprob": -0.5392106771469116,
      "compression_ratio": 1.5631579160690308,
      "end": 320.20001220703125,
      "no_speech_prob": 0.008311718702316284,
      "seek": 29380,
      "start": 318.20001220703125,
      "temperature": 0.0,
      "text": " eight nine",
      "tokens": [
        51584,
        3180,
        4949,
        51684
      ]
    },
    {
      "id": 60,
      "avg_logprob": -0.3574334383010864,
      "compression_ratio": 1.6089385747909546,
      "end": 325.760009765625,
      "no_speech_prob": 0.0010649069445207715,
      "seek": 32020,
      "start": 320.239990234375,
      "temperature": 0.0,
      "text": " Nine maybe ten eleven ish",
      "tokens": [
        50366,
        18939,
        1310,
        2064,
        21090,
        307,
        71,
        50642
      ]
    },
    {
      "id": 61,
      "avg_logprob": -0.3574334383010864,
      "compression_ratio": 1.6089385747909546,
      "end": 329.760009765625,
      "no_speech_prob": 0.0010649069445207715,
      "seek": 32020,
      "start": 327.3599853515625,
      "temperature": 0.0,
      "text": " Let's try to see how many the model points",
      "tokens": [
        50722,
        961,
        311,
        853,
        281,
        536,
        577,
        867,
        264,
        2316,
        2793,
        50842
      ]
    },
    {
      "id": 62,
      "avg_logprob": -0.3574334383010864,
      "compression_ratio": 1.6089385747909546,
      "end": 336.8399963378906,
      "no_speech_prob": 0.0010649069445207715,
      "seek": 32020,
      "start": 332.2799987792969,
      "temperature": 0.0,
      "text": " So for photos like these where the responses can",
      "tokens": [
        50968,
        407,
        337,
        5787,
        411,
        613,
        689,
        264,
        13019,
        393,
        51196
      ]
    },
    {
      "id": 63,
      "avg_logprob": -0.3574334383010864,
      "compression_ratio": 1.6089385747909546,
      "end": 342.44000244140625,
      "no_speech_prob": 0.0010649069445207715,
      "seek": 32020,
      "start": 337.3599853515625,
      "temperature": 0.0,
      "text": " vary what you're looking for is the ballpark number like does it give you in the ballpark or",
      "tokens": [
        51222,
        10559,
        437,
        291,
        434,
        1237,
        337,
        307,
        264,
        2594,
        31239,
        1230,
        411,
        775,
        309,
        976,
        291,
        294,
        264,
        2594,
        31239,
        420,
        51476
      ]
    },
    {
      "id": 64,
      "avg_logprob": -0.3574334383010864,
      "compression_ratio": 1.6089385747909546,
      "end": 347.0,
      "no_speech_prob": 0.0010649069445207715,
      "seek": 32020,
      "start": 342.79998779296875,
      "temperature": 0.0,
      "text": " Does it give you a totally absurd number? So they see ten people in the image",
      "tokens": [
        51494,
        4402,
        309,
        976,
        291,
        257,
        3879,
        19774,
        1230,
        30,
        407,
        436,
        536,
        2064,
        561,
        294,
        264,
        3256,
        51704
      ]
    },
    {
      "id": 65,
      "avg_logprob": -0.37943655252456665,
      "compression_ratio": 1.5053763389587402,
      "end": 351.8800048828125,
      "no_speech_prob": 0.00021654214651789516,
      "seek": 34700,
      "start": 347.5199890136719,
      "temperature": 0.0,
      "text": " I think we counted one two, three, four, five six, seven eight nine ten",
      "tokens": [
        50390,
        286,
        519,
        321,
        20150,
        472,
        732,
        11,
        1045,
        11,
        1451,
        11,
        1732,
        2309,
        11,
        3407,
        3180,
        4949,
        2064,
        50608
      ]
    },
    {
      "id": 66,
      "avg_logprob": -0.37943655252456665,
      "compression_ratio": 1.5053763389587402,
      "end": 357.55999755859375,
      "no_speech_prob": 0.00021654214651789516,
      "seek": 34700,
      "start": 352.6000061035156,
      "temperature": 0.0,
      "text": " Eleven sort of eleven ish but the ones over here",
      "tokens": [
        50644,
        48548,
        1333,
        295,
        21090,
        307,
        71,
        457,
        264,
        2306,
        670,
        510,
        50892
      ]
    },
    {
      "id": 67,
      "avg_logprob": -0.37943655252456665,
      "compression_ratio": 1.5053763389587402,
      "end": 362.0799865722656,
      "no_speech_prob": 0.00021654214651789516,
      "seek": 34700,
      "start": 357.55999755859375,
      "temperature": 0.0,
      "text": " These are only feet of people. So maybe the model is not considering these",
      "tokens": [
        50892,
        1981,
        366,
        787,
        3521,
        295,
        561,
        13,
        407,
        1310,
        264,
        2316,
        307,
        406,
        8079,
        613,
        51118
      ]
    },
    {
      "id": 68,
      "avg_logprob": -0.37943655252456665,
      "compression_ratio": 1.5053763389587402,
      "end": 364.8800048828125,
      "no_speech_prob": 0.00021654214651789516,
      "seek": 34700,
      "start": 362.8800048828125,
      "temperature": 0.0,
      "text": " people when counting",
      "tokens": [
        51158,
        561,
        562,
        13251,
        51258
      ]
    },
    {
      "id": 69,
      "avg_logprob": -0.37943655252456665,
      "compression_ratio": 1.5053763389587402,
      "end": 366.9200134277344,
      "no_speech_prob": 0.00021654214651789516,
      "seek": 34700,
      "start": 364.9200134277344,
      "temperature": 0.0,
      "text": " so I'm gonna try to run it again and",
      "tokens": [
        51260,
        370,
        286,
        478,
        799,
        853,
        281,
        1190,
        309,
        797,
        293,
        51360
      ]
    },
    {
      "id": 70,
      "avg_logprob": -0.37943655252456665,
      "compression_ratio": 1.5053763389587402,
      "end": 370.3599853515625,
      "no_speech_prob": 0.00021654214651789516,
      "seek": 34700,
      "start": 368.3599853515625,
      "temperature": 0.0,
      "text": " This time you're gonna see",
      "tokens": [
        51432,
        639,
        565,
        291,
        434,
        799,
        536,
        51532
      ]
    },
    {
      "id": 71,
      "avg_logprob": -0.2984212040901184,
      "compression_ratio": 1.560185194015503,
      "end": 372.4800109863281,
      "no_speech_prob": 8.092683856375515e-05,
      "seek": 37036,
      "start": 371.3599853515625,
      "temperature": 0.0,
      "text": " The",
      "tokens": [
        50414,
        440,
        50470
      ]
    },
    {
      "id": 72,
      "avg_logprob": -0.2984212040901184,
      "compression_ratio": 1.560185194015503,
      "end": 376.4800109863281,
      "no_speech_prob": 8.092683856375515e-05,
      "seek": 37036,
      "start": 372.4800109863281,
      "temperature": 0.0,
      "text": " Eleven people so that's what the model gets usually between 10 and 11",
      "tokens": [
        50470,
        48548,
        561,
        370,
        300,
        311,
        437,
        264,
        2316,
        2170,
        2673,
        1296,
        1266,
        293,
        2975,
        50670
      ]
    },
    {
      "id": 73,
      "avg_logprob": -0.2984212040901184,
      "compression_ratio": 1.560185194015503,
      "end": 381.32000732421875,
      "no_speech_prob": 8.092683856375515e-05,
      "seek": 37036,
      "start": 376.6400146484375,
      "temperature": 0.0,
      "text": " But just like the previous one it does not give me an exact number all the time",
      "tokens": [
        50678,
        583,
        445,
        411,
        264,
        3894,
        472,
        309,
        775,
        406,
        976,
        385,
        364,
        1900,
        1230,
        439,
        264,
        565,
        50912
      ]
    },
    {
      "id": 74,
      "avg_logprob": -0.2984212040901184,
      "compression_ratio": 1.560185194015503,
      "end": 388.8800048828125,
      "no_speech_prob": 8.092683856375515e-05,
      "seek": 37036,
      "start": 383.239990234375,
      "temperature": 0.0,
      "text": " Okay, so now let's move on to the next category of images which are location images",
      "tokens": [
        51008,
        1033,
        11,
        370,
        586,
        718,
        311,
        1286,
        322,
        281,
        264,
        958,
        7719,
        295,
        5267,
        597,
        366,
        4914,
        5267,
        51290
      ]
    },
    {
      "id": 75,
      "avg_logprob": -0.2984212040901184,
      "compression_ratio": 1.560185194015503,
      "end": 397.0400085449219,
      "no_speech_prob": 8.092683856375515e-05,
      "seek": 37036,
      "start": 389.0400085449219,
      "temperature": 0.0,
      "text": " So I have four images that I know where they're from and then I have one which is a random location",
      "tokens": [
        51298,
        407,
        286,
        362,
        1451,
        5267,
        300,
        286,
        458,
        689,
        436,
        434,
        490,
        293,
        550,
        286,
        362,
        472,
        597,
        307,
        257,
        4974,
        4914,
        51698
      ]
    },
    {
      "id": 76,
      "avg_logprob": -0.2727731764316559,
      "compression_ratio": 1.5913461446762085,
      "end": 401.32000732421875,
      "no_speech_prob": 0.003172290977090597,
      "seek": 39704,
      "start": 397.0400085449219,
      "temperature": 0.0,
      "text": " This is a photo that that came straight from my Google Photos library",
      "tokens": [
        50364,
        639,
        307,
        257,
        5052,
        300,
        300,
        1361,
        2997,
        490,
        452,
        3329,
        13919,
        329,
        6405,
        50578
      ]
    },
    {
      "id": 77,
      "avg_logprob": -0.2727731764316559,
      "compression_ratio": 1.5913461446762085,
      "end": 408.0,
      "no_speech_prob": 0.003172290977090597,
      "seek": 39704,
      "start": 401.5199890136719,
      "temperature": 0.0,
      "text": " okay, so I'm gonna start with the first one, which is a photo of a mosque in a Turkey and",
      "tokens": [
        50588,
        1392,
        11,
        370,
        286,
        478,
        799,
        722,
        365,
        264,
        700,
        472,
        11,
        597,
        307,
        257,
        5052,
        295,
        257,
        31501,
        294,
        257,
        12647,
        293,
        50912
      ]
    },
    {
      "id": 78,
      "avg_logprob": -0.2727731764316559,
      "compression_ratio": 1.5913461446762085,
      "end": 410.79998779296875,
      "no_speech_prob": 0.003172290977090597,
      "seek": 39704,
      "start": 408.79998779296875,
      "temperature": 0.0,
      "text": " then I have a photo of",
      "tokens": [
        50952,
        550,
        286,
        362,
        257,
        5052,
        295,
        51052
      ]
    },
    {
      "id": 79,
      "avg_logprob": -0.2727731764316559,
      "compression_ratio": 1.5913461446762085,
      "end": 413.32000732421875,
      "no_speech_prob": 0.003172290977090597,
      "seek": 39704,
      "start": 411.32000732421875,
      "temperature": 0.0,
      "text": " Brazil and",
      "tokens": [
        51078,
        9435,
        293,
        51178
      ]
    },
    {
      "id": 80,
      "avg_logprob": -0.2727731764316559,
      "compression_ratio": 1.5913461446762085,
      "end": 415.5199890136719,
      "no_speech_prob": 0.003172290977090597,
      "seek": 39704,
      "start": 413.5199890136719,
      "temperature": 0.0,
      "text": " Then I've got one from my home country",
      "tokens": [
        51188,
        1396,
        286,
        600,
        658,
        472,
        490,
        452,
        1280,
        1941,
        51288
      ]
    },
    {
      "id": 81,
      "avg_logprob": -0.2727731764316559,
      "compression_ratio": 1.5913461446762085,
      "end": 418.7200012207031,
      "no_speech_prob": 0.003172290977090597,
      "seek": 39704,
      "start": 416.0400085449219,
      "temperature": 0.0,
      "text": " So the capital of my home country Dhaka. I",
      "tokens": [
        51314,
        407,
        264,
        4238,
        295,
        452,
        1280,
        1941,
        34414,
        7849,
        13,
        286,
        51448
      ]
    },
    {
      "id": 82,
      "avg_logprob": -0.2727731764316559,
      "compression_ratio": 1.5913461446762085,
      "end": 423.1600036621094,
      "no_speech_prob": 0.003172290977090597,
      "seek": 39704,
      "start": 419.2799987792969,
      "temperature": 0.0,
      "text": " Have one from the National Park Smoky Mountain this one",
      "tokens": [
        51476,
        3560,
        472,
        490,
        264,
        4862,
        4964,
        3915,
        453,
        88,
        15586,
        341,
        472,
        51670
      ]
    },
    {
      "id": 83,
      "avg_logprob": -0.30154746770858765,
      "compression_ratio": 1.8070175647735596,
      "end": 430.32000732421875,
      "no_speech_prob": 0.003649694612249732,
      "seek": 42316,
      "start": 423.1600036621094,
      "temperature": 0.0,
      "text": " I just want to see if it can actually get the Smoky Mountain National Park, or does it just give me a random National Park?",
      "tokens": [
        50364,
        286,
        445,
        528,
        281,
        536,
        498,
        309,
        393,
        767,
        483,
        264,
        3915,
        453,
        88,
        15586,
        4862,
        4964,
        11,
        420,
        775,
        309,
        445,
        976,
        385,
        257,
        4974,
        4862,
        4964,
        30,
        50722
      ]
    },
    {
      "id": 84,
      "avg_logprob": -0.30154746770858765,
      "compression_ratio": 1.8070175647735596,
      "end": 433.20001220703125,
      "no_speech_prob": 0.003649694612249732,
      "seek": 42316,
      "start": 430.9599914550781,
      "temperature": 0.0,
      "text": " and then a random location",
      "tokens": [
        50754,
        293,
        550,
        257,
        4974,
        4914,
        50866
      ]
    },
    {
      "id": 85,
      "avg_logprob": -0.30154746770858765,
      "compression_ratio": 1.8070175647735596,
      "end": 438.6400146484375,
      "no_speech_prob": 0.003649694612249732,
      "seek": 42316,
      "start": 433.20001220703125,
      "temperature": 0.0,
      "text": " So this was from my trip during fall this year in Yosemite, California",
      "tokens": [
        50866,
        407,
        341,
        390,
        490,
        452,
        4931,
        1830,
        2100,
        341,
        1064,
        294,
        398,
        329,
        443,
        642,
        11,
        5384,
        51138
      ]
    },
    {
      "id": 86,
      "avg_logprob": -0.30154746770858765,
      "compression_ratio": 1.8070175647735596,
      "end": 444.9200134277344,
      "no_speech_prob": 0.003649694612249732,
      "seek": 42316,
      "start": 438.8399963378906,
      "temperature": 0.0,
      "text": " So I just wanted to see if we feed a random model without any context or a random image without any context",
      "tokens": [
        51148,
        407,
        286,
        445,
        1415,
        281,
        536,
        498,
        321,
        3154,
        257,
        4974,
        2316,
        1553,
        604,
        4319,
        420,
        257,
        4974,
        3256,
        1553,
        604,
        4319,
        51452
      ]
    },
    {
      "id": 87,
      "avg_logprob": -0.30154746770858765,
      "compression_ratio": 1.8070175647735596,
      "end": 450.760009765625,
      "no_speech_prob": 0.003649694612249732,
      "seek": 42316,
      "start": 445.760009765625,
      "temperature": 0.0,
      "text": " How close does the model really get like does it say the photo is from California?",
      "tokens": [
        51494,
        1012,
        1998,
        775,
        264,
        2316,
        534,
        483,
        411,
        775,
        309,
        584,
        264,
        5052,
        307,
        490,
        5384,
        30,
        51744
      ]
    },
    {
      "id": 88,
      "avg_logprob": -0.31692802906036377,
      "compression_ratio": 1.442307710647583,
      "end": 456.6000061035156,
      "no_speech_prob": 8.34937090985477e-05,
      "seek": 45076,
      "start": 451.20001220703125,
      "temperature": 0.0,
      "text": " Does it go as far into the exact location? We're gonna find out in a little bit",
      "tokens": [
        50386,
        4402,
        309,
        352,
        382,
        1400,
        666,
        264,
        1900,
        4914,
        30,
        492,
        434,
        799,
        915,
        484,
        294,
        257,
        707,
        857,
        50656
      ]
    },
    {
      "id": 89,
      "avg_logprob": -0.31692802906036377,
      "compression_ratio": 1.442307710647583,
      "end": 459.55999755859375,
      "no_speech_prob": 8.34937090985477e-05,
      "seek": 45076,
      "start": 457.55999755859375,
      "temperature": 0.0,
      "text": " So let's start with the first one",
      "tokens": [
        50704,
        407,
        718,
        311,
        722,
        365,
        264,
        700,
        472,
        50804
      ]
    },
    {
      "id": 90,
      "avg_logprob": -0.31692802906036377,
      "compression_ratio": 1.442307710647583,
      "end": 465.5199890136719,
      "no_speech_prob": 8.34937090985477e-05,
      "seek": 45076,
      "start": 459.9200134277344,
      "temperature": 0.0,
      "text": " So I'm gonna change the prompt and we're gonna say where was this photo taken?",
      "tokens": [
        50822,
        407,
        286,
        478,
        799,
        1319,
        264,
        12391,
        293,
        321,
        434,
        799,
        584,
        689,
        390,
        341,
        5052,
        2726,
        30,
        51102
      ]
    },
    {
      "id": 91,
      "avg_logprob": -0.31692802906036377,
      "compression_ratio": 1.442307710647583,
      "end": 469.44000244140625,
      "no_speech_prob": 8.34937090985477e-05,
      "seek": 45076,
      "start": 466.760009765625,
      "temperature": 0.0,
      "text": " Okay, and then let's run it",
      "tokens": [
        51164,
        1033,
        11,
        293,
        550,
        718,
        311,
        1190,
        309,
        51298
      ]
    },
    {
      "id": 92,
      "avg_logprob": -0.31692802906036377,
      "compression_ratio": 1.442307710647583,
      "end": 474.6400146484375,
      "no_speech_prob": 8.34937090985477e-05,
      "seek": 45076,
      "start": 472.6400146484375,
      "temperature": 0.0,
      "text": " Okay",
      "tokens": [
        51458,
        1033,
        51558
      ]
    },
    {
      "id": 93,
      "avg_logprob": -0.263867050409317,
      "compression_ratio": 1.5158370733261108,
      "end": 481.32000732421875,
      "no_speech_prob": 0.0011158135021105409,
      "seek": 47464,
      "start": 475.55999755859375,
      "temperature": 0.0,
      "text": " And it identified the photo correctly it even it can even identify what mosque and",
      "tokens": [
        50410,
        400,
        309,
        9234,
        264,
        5052,
        8944,
        309,
        754,
        309,
        393,
        754,
        5876,
        437,
        31501,
        293,
        50698
      ]
    },
    {
      "id": 94,
      "avg_logprob": -0.263867050409317,
      "compression_ratio": 1.5158370733261108,
      "end": 487.17999267578125,
      "no_speech_prob": 0.0011158135021105409,
      "seek": 47464,
      "start": 481.760009765625,
      "temperature": 0.0,
      "text": " Which bridge in the background, which is pretty cool. And now if we do the Brazil one",
      "tokens": [
        50720,
        3013,
        7283,
        294,
        264,
        3678,
        11,
        597,
        307,
        1238,
        1627,
        13,
        400,
        586,
        498,
        321,
        360,
        264,
        9435,
        472,
        50991
      ]
    },
    {
      "id": 95,
      "avg_logprob": -0.263867050409317,
      "compression_ratio": 1.5158370733261108,
      "end": 489.760009765625,
      "no_speech_prob": 0.0011158135021105409,
      "seek": 47464,
      "start": 487.760009765625,
      "temperature": 0.0,
      "text": " Let's see what happens",
      "tokens": [
        51020,
        961,
        311,
        536,
        437,
        2314,
        51120
      ]
    },
    {
      "id": 96,
      "avg_logprob": -0.263867050409317,
      "compression_ratio": 1.5158370733261108,
      "end": 494.7200012207031,
      "no_speech_prob": 0.0011158135021105409,
      "seek": 47464,
      "start": 492.7200012207031,
      "temperature": 0.0,
      "text": " Give it a few seconds again",
      "tokens": [
        51268,
        5303,
        309,
        257,
        1326,
        3949,
        797,
        51368
      ]
    },
    {
      "id": 97,
      "avg_logprob": -0.263867050409317,
      "compression_ratio": 1.5158370733261108,
      "end": 502.55999755859375,
      "no_speech_prob": 0.0011158135021105409,
      "seek": 47464,
      "start": 495.5199890136719,
      "temperature": 0.0,
      "text": " Perfect. It got Brazil and it also gives you like a little bit of an information about how it's doing the inference",
      "tokens": [
        51408,
        10246,
        13,
        467,
        658,
        9435,
        293,
        309,
        611,
        2709,
        291,
        411,
        257,
        707,
        857,
        295,
        364,
        1589,
        466,
        577,
        309,
        311,
        884,
        264,
        38253,
        51760
      ]
    },
    {
      "id": 98,
      "avg_logprob": -0.3157057464122772,
      "compression_ratio": 1.5306122303009033,
      "end": 505.67999267578125,
      "no_speech_prob": 0.00017674063565209508,
      "seek": 50256,
      "start": 502.55999755859375,
      "temperature": 0.0,
      "text": " So you can see it recognizes Sugarloaf Mountain",
      "tokens": [
        50364,
        407,
        291,
        393,
        536,
        309,
        26564,
        24576,
        752,
        2792,
        15586,
        50520
      ]
    },
    {
      "id": 99,
      "avg_logprob": -0.3157057464122772,
      "compression_ratio": 1.5306122303009033,
      "end": 509.6400146484375,
      "no_speech_prob": 0.00017674063565209508,
      "seek": 50256,
      "start": 506.4800109863281,
      "temperature": 0.0,
      "text": " Which helps it realize that this is a Brazil",
      "tokens": [
        50560,
        3013,
        3665,
        309,
        4325,
        300,
        341,
        307,
        257,
        9435,
        50718
      ]
    },
    {
      "id": 100,
      "avg_logprob": -0.3157057464122772,
      "compression_ratio": 1.5306122303009033,
      "end": 517.0800170898438,
      "no_speech_prob": 0.00017674063565209508,
      "seek": 50256,
      "start": 511.55999755859375,
      "temperature": 0.0,
      "text": " All right, let's keep going we're gonna try the other one which is gonna be Taka",
      "tokens": [
        50814,
        1057,
        558,
        11,
        718,
        311,
        1066,
        516,
        321,
        434,
        799,
        853,
        264,
        661,
        472,
        597,
        307,
        799,
        312,
        314,
        7849,
        51090
      ]
    },
    {
      "id": 101,
      "avg_logprob": -0.3157057464122772,
      "compression_ratio": 1.5306122303009033,
      "end": 520.6400146484375,
      "no_speech_prob": 0.00017674063565209508,
      "seek": 50256,
      "start": 518.6400146484375,
      "temperature": 0.0,
      "text": " So just to show you the photo again",
      "tokens": [
        51168,
        407,
        445,
        281,
        855,
        291,
        264,
        5052,
        797,
        51268
      ]
    },
    {
      "id": 102,
      "avg_logprob": -0.3157057464122772,
      "compression_ratio": 1.5306122303009033,
      "end": 529.4000244140625,
      "no_speech_prob": 0.00017674063565209508,
      "seek": 50256,
      "start": 523.47998046875,
      "temperature": 0.0,
      "text": " This is a pretty random photo and you can find photos like these in most of Southeast Asia",
      "tokens": [
        51410,
        639,
        307,
        257,
        1238,
        4974,
        5052,
        293,
        291,
        393,
        915,
        5787,
        411,
        613,
        294,
        881,
        295,
        27906,
        10038,
        51706
      ]
    },
    {
      "id": 103,
      "avg_logprob": -0.26693645119667053,
      "compression_ratio": 1.5,
      "end": 535.8400268554688,
      "no_speech_prob": 0.0008167155319824815,
      "seek": 52940,
      "start": 529.7999877929688,
      "temperature": 0.0,
      "text": " But maybe the the alphabets over here gives away whether it's Bangladesh or some other country",
      "tokens": [
        50384,
        583,
        1310,
        264,
        264,
        419,
        950,
        455,
        1385,
        670,
        510,
        2709,
        1314,
        1968,
        309,
        311,
        35260,
        420,
        512,
        661,
        1941,
        50686
      ]
    },
    {
      "id": 104,
      "avg_logprob": -0.26693645119667053,
      "compression_ratio": 1.5,
      "end": 538.4400024414062,
      "no_speech_prob": 0.0008167155319824815,
      "seek": 52940,
      "start": 536.239990234375,
      "temperature": 0.0,
      "text": " But let's try running it through the model",
      "tokens": [
        50706,
        583,
        718,
        311,
        853,
        2614,
        309,
        807,
        264,
        2316,
        50816
      ]
    },
    {
      "id": 105,
      "avg_logprob": -0.26693645119667053,
      "compression_ratio": 1.5,
      "end": 552.4400024414062,
      "no_speech_prob": 0.0008167155319824815,
      "seek": 52940,
      "start": 545.5999755859375,
      "temperature": 0.0,
      "text": " Okay, so it says in South Asian City likely Bangladesh and then it gives a little bit of description",
      "tokens": [
        51174,
        1033,
        11,
        370,
        309,
        1619,
        294,
        4242,
        10645,
        4392,
        3700,
        35260,
        293,
        550,
        309,
        2709,
        257,
        707,
        857,
        295,
        3855,
        51516
      ]
    },
    {
      "id": 106,
      "avg_logprob": -0.26693645119667053,
      "compression_ratio": 1.5,
      "end": 555.3200073242188,
      "no_speech_prob": 0.0008167155319824815,
      "seek": 52940,
      "start": 552.4400024414062,
      "temperature": 0.0,
      "text": " So the couple of times I've run it before it goes",
      "tokens": [
        51516,
        407,
        264,
        1916,
        295,
        1413,
        286,
        600,
        1190,
        309,
        949,
        309,
        1709,
        51660
      ]
    },
    {
      "id": 107,
      "avg_logprob": -0.3163629174232483,
      "compression_ratio": 1.5829384326934814,
      "end": 562.4000244140625,
      "no_speech_prob": 0.0020187541376799345,
      "seek": 55532,
      "start": 555.8800048828125,
      "temperature": 0.0,
      "text": " To something as specific as the city Taka, but in this case, it just narrows it down to the country",
      "tokens": [
        50392,
        1407,
        746,
        382,
        2685,
        382,
        264,
        2307,
        314,
        7849,
        11,
        457,
        294,
        341,
        1389,
        11,
        309,
        445,
        6397,
        1509,
        309,
        760,
        281,
        264,
        1941,
        50718
      ]
    },
    {
      "id": 108,
      "avg_logprob": -0.3163629174232483,
      "compression_ratio": 1.5829384326934814,
      "end": 565.4400024414062,
      "no_speech_prob": 0.0020187541376799345,
      "seek": 55532,
      "start": 562.4000244140625,
      "temperature": 0.0,
      "text": " Which is still pretty cool. So I'm gonna try to running it running it again",
      "tokens": [
        50718,
        3013,
        307,
        920,
        1238,
        1627,
        13,
        407,
        286,
        478,
        799,
        853,
        281,
        2614,
        309,
        2614,
        309,
        797,
        50870
      ]
    },
    {
      "id": 109,
      "avg_logprob": -0.3163629174232483,
      "compression_ratio": 1.5829384326934814,
      "end": 571.5599975585938,
      "no_speech_prob": 0.0020187541376799345,
      "seek": 55532,
      "start": 568.0,
      "temperature": 0.0,
      "text": " And yeah, it keeps on getting the country but",
      "tokens": [
        50998,
        400,
        1338,
        11,
        309,
        5965,
        322,
        1242,
        264,
        1941,
        457,
        51176
      ]
    },
    {
      "id": 110,
      "avg_logprob": -0.3163629174232483,
      "compression_ratio": 1.5829384326934814,
      "end": 579.0399780273438,
      "no_speech_prob": 0.0020187541376799345,
      "seek": 55532,
      "start": 573.4400024414062,
      "temperature": 0.0,
      "text": " Yeah, it's a typical urban scene in Taka, but it's not as as strong as",
      "tokens": [
        51270,
        865,
        11,
        309,
        311,
        257,
        7476,
        9681,
        4145,
        294,
        314,
        7849,
        11,
        457,
        309,
        311,
        406,
        382,
        382,
        2068,
        382,
        51550
      ]
    },
    {
      "id": 111,
      "avg_logprob": -0.3163629174232483,
      "compression_ratio": 1.5829384326934814,
      "end": 583.239990234375,
      "no_speech_prob": 0.0020187541376799345,
      "seek": 55532,
      "start": 580.4400024414062,
      "temperature": 0.0,
      "text": " When it was recommending Turkey or Brazil",
      "tokens": [
        51620,
        1133,
        309,
        390,
        30559,
        12647,
        420,
        9435,
        51760
      ]
    },
    {
      "id": 112,
      "avg_logprob": -0.3069930374622345,
      "compression_ratio": 1.5688889026641846,
      "end": 585.280029296875,
      "no_speech_prob": 9.610050619812682e-05,
      "seek": 58324,
      "start": 584.239990234375,
      "temperature": 0.0,
      "text": " Okay, awesome",
      "tokens": [
        50414,
        1033,
        11,
        3476,
        50466
      ]
    },
    {
      "id": 113,
      "avg_logprob": -0.3069930374622345,
      "compression_ratio": 1.5688889026641846,
      "end": 590.719970703125,
      "no_speech_prob": 9.610050619812682e-05,
      "seek": 58324,
      "start": 585.280029296875,
      "temperature": 0.0,
      "text": " and now I will try running it with the GPT 5 model because I have seen the",
      "tokens": [
        50466,
        293,
        586,
        286,
        486,
        853,
        2614,
        309,
        365,
        264,
        26039,
        51,
        1025,
        2316,
        570,
        286,
        362,
        1612,
        264,
        50738
      ]
    },
    {
      "id": 114,
      "avg_logprob": -0.3069930374622345,
      "compression_ratio": 1.5688889026641846,
      "end": 596.5999755859375,
      "no_speech_prob": 9.610050619812682e-05,
      "seek": 58324,
      "start": 591.0399780273438,
      "temperature": 0.0,
      "text": " GPT 5 model even though it takes a lot longer it can give you a much",
      "tokens": [
        50754,
        26039,
        51,
        1025,
        2316,
        754,
        1673,
        309,
        2516,
        257,
        688,
        2854,
        309,
        393,
        976,
        291,
        257,
        709,
        51032
      ]
    },
    {
      "id": 115,
      "avg_logprob": -0.3069930374622345,
      "compression_ratio": 1.5688889026641846,
      "end": 602.3200073242188,
      "no_speech_prob": 9.610050619812682e-05,
      "seek": 58324,
      "start": 597.0399780273438,
      "temperature": 0.0,
      "text": " More accurate description of the image. So let me come to that in a little bit before that",
      "tokens": [
        51054,
        5048,
        8559,
        3855,
        295,
        264,
        3256,
        13,
        407,
        718,
        385,
        808,
        281,
        300,
        294,
        257,
        707,
        857,
        949,
        300,
        51318
      ]
    },
    {
      "id": 116,
      "avg_logprob": -0.3069930374622345,
      "compression_ratio": 1.5688889026641846,
      "end": 605.760009765625,
      "no_speech_prob": 9.610050619812682e-05,
      "seek": 58324,
      "start": 602.3200073242188,
      "temperature": 0.0,
      "text": " Let's try this Smoky Mountain photo and the one from California",
      "tokens": [
        51318,
        961,
        311,
        853,
        341,
        3915,
        453,
        88,
        15586,
        5052,
        293,
        264,
        472,
        490,
        5384,
        51490
      ]
    },
    {
      "id": 117,
      "avg_logprob": -0.3069930374622345,
      "compression_ratio": 1.5688889026641846,
      "end": 609.1799926757812,
      "no_speech_prob": 9.610050619812682e-05,
      "seek": 58324,
      "start": 606.280029296875,
      "temperature": 0.0,
      "text": " So let's start with Smoky Mountain again",
      "tokens": [
        51516,
        407,
        718,
        311,
        722,
        365,
        3915,
        453,
        88,
        15586,
        797,
        51661
      ]
    },
    {
      "id": 118,
      "avg_logprob": -0.2604638636112213,
      "compression_ratio": 1.6607142686843872,
      "end": 616.4199829101562,
      "no_speech_prob": 0.0001039080525515601,
      "seek": 60918,
      "start": 610.1799926757812,
      "temperature": 0.0,
      "text": " And what we're looking for is does it just randomly say National Park or does it get the exact National Park",
      "tokens": [
        50414,
        400,
        437,
        321,
        434,
        1237,
        337,
        307,
        775,
        309,
        445,
        16979,
        584,
        4862,
        4964,
        420,
        775,
        309,
        483,
        264,
        1900,
        4862,
        4964,
        50726
      ]
    },
    {
      "id": 119,
      "avg_logprob": -0.2604638636112213,
      "compression_ratio": 1.6607142686843872,
      "end": 623.7000122070312,
      "no_speech_prob": 0.0001039080525515601,
      "seek": 60918,
      "start": 617.7000122070312,
      "temperature": 0.0,
      "text": " It gets the Great Smoky Mountains, which is pretty cool. And then let's try to run it again",
      "tokens": [
        50790,
        467,
        2170,
        264,
        3769,
        3915,
        453,
        88,
        30970,
        11,
        597,
        307,
        1238,
        1627,
        13,
        400,
        550,
        718,
        311,
        853,
        281,
        1190,
        309,
        797,
        51090
      ]
    },
    {
      "id": 120,
      "avg_logprob": -0.2604638636112213,
      "compression_ratio": 1.6607142686843872,
      "end": 631.3800048828125,
      "no_speech_prob": 0.0001039080525515601,
      "seek": 60918,
      "start": 628.0999755859375,
      "temperature": 0.0,
      "text": " Again it's very confident that it's getting Great Smoky Mountain",
      "tokens": [
        51310,
        3764,
        309,
        311,
        588,
        6679,
        300,
        309,
        311,
        1242,
        3769,
        3915,
        453,
        88,
        15586,
        51474
      ]
    },
    {
      "id": 121,
      "avg_logprob": -0.2604638636112213,
      "compression_ratio": 1.6607142686843872,
      "end": 636.5399780273438,
      "no_speech_prob": 0.0001039080525515601,
      "seek": 60918,
      "start": 631.3800048828125,
      "temperature": 0.0,
      "text": " Which I found super cool because when I looked at the photo it could have been any National Park in the US",
      "tokens": [
        51474,
        3013,
        286,
        1352,
        1687,
        1627,
        570,
        562,
        286,
        2956,
        412,
        264,
        5052,
        309,
        727,
        362,
        668,
        604,
        4862,
        4964,
        294,
        264,
        2546,
        51732
      ]
    },
    {
      "id": 122,
      "avg_logprob": -0.33151423931121826,
      "compression_ratio": 1.5384615659713745,
      "end": 642.1400146484375,
      "no_speech_prob": 0.0005702570197172463,
      "seek": 63654,
      "start": 637.5399780273438,
      "temperature": 0.0,
      "text": " Okay, again, I think this gives sort of an idea",
      "tokens": [
        50414,
        1033,
        11,
        797,
        11,
        286,
        519,
        341,
        2709,
        1333,
        295,
        364,
        1558,
        50644
      ]
    },
    {
      "id": 123,
      "avg_logprob": -0.33151423931121826,
      "compression_ratio": 1.5384615659713745,
      "end": 648.7000122070312,
      "no_speech_prob": 0.0005702570197172463,
      "seek": 63654,
      "start": 642.8200073242188,
      "temperature": 0.0,
      "text": " Why it thinks it's the Great Smoky Mountain and it says that it sees the Clingmans dome",
      "tokens": [
        50678,
        1545,
        309,
        7309,
        309,
        311,
        264,
        3769,
        3915,
        453,
        88,
        15586,
        293,
        309,
        1619,
        300,
        309,
        8194,
        264,
        383,
        1688,
        44734,
        27191,
        50972
      ]
    },
    {
      "id": 124,
      "avg_logprob": -0.33151423931121826,
      "compression_ratio": 1.5384615659713745,
      "end": 651.219970703125,
      "no_speech_prob": 0.0005702570197172463,
      "seek": 63654,
      "start": 649.5399780273438,
      "temperature": 0.0,
      "text": " which is",
      "tokens": [
        51014,
        597,
        307,
        51098
      ]
    },
    {
      "id": 125,
      "avg_logprob": -0.33151423931121826,
      "compression_ratio": 1.5384615659713745,
      "end": 654.1400146484375,
      "no_speech_prob": 0.0005702570197172463,
      "seek": 63654,
      "start": 651.219970703125,
      "temperature": 0.0,
      "text": " Do we have it here? Which is I think somewhere over here",
      "tokens": [
        51098,
        1144,
        321,
        362,
        309,
        510,
        30,
        3013,
        307,
        286,
        519,
        4079,
        670,
        510,
        51244
      ]
    },
    {
      "id": 126,
      "avg_logprob": -0.33151423931121826,
      "compression_ratio": 1.5384615659713745,
      "end": 656.9000244140625,
      "no_speech_prob": 0.0005702570197172463,
      "seek": 63654,
      "start": 654.9000244140625,
      "temperature": 0.0,
      "text": " So yeah, it does a pretty good job",
      "tokens": [
        51282,
        407,
        1338,
        11,
        309,
        775,
        257,
        1238,
        665,
        1691,
        51382
      ]
    },
    {
      "id": 127,
      "avg_logprob": -0.33151423931121826,
      "compression_ratio": 1.5384615659713745,
      "end": 661.0999755859375,
      "no_speech_prob": 0.0005702570197172463,
      "seek": 63654,
      "start": 656.9400024414062,
      "temperature": 0.0,
      "text": " Now the last one we have is the random location just to remind you",
      "tokens": [
        51384,
        823,
        264,
        1036,
        472,
        321,
        362,
        307,
        264,
        4974,
        4914,
        445,
        281,
        4160,
        291,
        51592
      ]
    },
    {
      "id": 128,
      "avg_logprob": -0.33151423931121826,
      "compression_ratio": 1.5384615659713745,
      "end": 664.97998046875,
      "no_speech_prob": 0.0005702570197172463,
      "seek": 63654,
      "start": 661.0999755859375,
      "temperature": 0.0,
      "text": " This is from my trip in this fall in California Yosemite",
      "tokens": [
        51592,
        639,
        307,
        490,
        452,
        4931,
        294,
        341,
        2100,
        294,
        5384,
        398,
        329,
        443,
        642,
        51786
      ]
    },
    {
      "id": 129,
      "avg_logprob": -0.3228360414505005,
      "compression_ratio": 1.517241358757019,
      "end": 670.1400146484375,
      "no_speech_prob": 0.0015730808954685926,
      "seek": 66498,
      "start": 665.4199829101562,
      "temperature": 0.0,
      "text": " So I want to see how close does it get we're just gonna give random location",
      "tokens": [
        50386,
        407,
        286,
        528,
        281,
        536,
        577,
        1998,
        775,
        309,
        483,
        321,
        434,
        445,
        799,
        976,
        4974,
        4914,
        50622
      ]
    },
    {
      "id": 130,
      "avg_logprob": -0.3228360414505005,
      "compression_ratio": 1.517241358757019,
      "end": 678.8200073242188,
      "no_speech_prob": 0.0015730808954685926,
      "seek": 66498,
      "start": 677.6199951171875,
      "temperature": 0.0,
      "text": " Okay",
      "tokens": [
        50996,
        1033,
        51056
      ]
    },
    {
      "id": 131,
      "avg_logprob": -0.3228360414505005,
      "compression_ratio": 1.517241358757019,
      "end": 682.5,
      "no_speech_prob": 0.0015730808954685926,
      "seek": 66498,
      "start": 678.8200073242188,
      "temperature": 0.0,
      "text": " Yeah, it got Auto Camp Yosemite, which is the exact",
      "tokens": [
        51056,
        865,
        11,
        309,
        658,
        13738,
        9189,
        398,
        329,
        443,
        642,
        11,
        597,
        307,
        264,
        1900,
        51240
      ]
    },
    {
      "id": 132,
      "avg_logprob": -0.3228360414505005,
      "compression_ratio": 1.517241358757019,
      "end": 687.8599853515625,
      "no_speech_prob": 0.0015730808954685926,
      "seek": 66498,
      "start": 683.9400024414062,
      "temperature": 0.0,
      "text": " Glamping location that we spend night or two in our trip",
      "tokens": [
        51312,
        5209,
        1215,
        278,
        4914,
        300,
        321,
        3496,
        1818,
        420,
        732,
        294,
        527,
        4931,
        51508
      ]
    },
    {
      "id": 133,
      "avg_logprob": -0.3228360414505005,
      "compression_ratio": 1.517241358757019,
      "end": 694.7000122070312,
      "no_speech_prob": 0.0015730808954685926,
      "seek": 66498,
      "start": 687.9000244140625,
      "temperature": 0.0,
      "text": " Which is really cool because when you look at different Auto Camp locations across the US they look very very similar",
      "tokens": [
        51510,
        3013,
        307,
        534,
        1627,
        570,
        562,
        291,
        574,
        412,
        819,
        13738,
        9189,
        9253,
        2108,
        264,
        2546,
        436,
        574,
        588,
        588,
        2531,
        51850
      ]
    },
    {
      "id": 134,
      "avg_logprob": -0.24607905745506287,
      "compression_ratio": 1.567685604095459,
      "end": 700.9000244140625,
      "no_speech_prob": 0.00010390940587967634,
      "seek": 69498,
      "start": 694.97998046875,
      "temperature": 0.0,
      "text": " So I'm quite surprised that it understands not only that this is an Auto Camp location",
      "tokens": [
        50364,
        407,
        286,
        478,
        1596,
        6100,
        300,
        309,
        15146,
        406,
        787,
        300,
        341,
        307,
        364,
        13738,
        9189,
        4914,
        50660
      ]
    },
    {
      "id": 135,
      "avg_logprob": -0.24607905745506287,
      "compression_ratio": 1.567685604095459,
      "end": 703.7000122070312,
      "no_speech_prob": 0.00010390940587967634,
      "seek": 69498,
      "start": 700.9000244140625,
      "temperature": 0.0,
      "text": " But the fact that it is from Yosemite",
      "tokens": [
        50660,
        583,
        264,
        1186,
        300,
        309,
        307,
        490,
        398,
        329,
        443,
        642,
        50800
      ]
    },
    {
      "id": 136,
      "avg_logprob": -0.24607905745506287,
      "compression_ratio": 1.567685604095459,
      "end": 711.4600219726562,
      "no_speech_prob": 0.00010390940587967634,
      "seek": 69498,
      "start": 703.7000122070312,
      "temperature": 0.0,
      "text": " I've run through this multiple times like 10 to 12 time and I think almost every time I got the model to say",
      "tokens": [
        50800,
        286,
        600,
        1190,
        807,
        341,
        3866,
        1413,
        411,
        1266,
        281,
        2272,
        565,
        293,
        286,
        519,
        1920,
        633,
        565,
        286,
        658,
        264,
        2316,
        281,
        584,
        51188
      ]
    },
    {
      "id": 137,
      "avg_logprob": -0.24607905745506287,
      "compression_ratio": 1.567685604095459,
      "end": 716.8200073242188,
      "no_speech_prob": 0.00010390940587967634,
      "seek": 69498,
      "start": 711.6199951171875,
      "temperature": 0.0,
      "text": " Auto Camp Yosemite, which is pretty cool. So I'm gonna run it again, maybe three times in total",
      "tokens": [
        51196,
        13738,
        9189,
        398,
        329,
        443,
        642,
        11,
        597,
        307,
        1238,
        1627,
        13,
        407,
        286,
        478,
        799,
        1190,
        309,
        797,
        11,
        1310,
        1045,
        1413,
        294,
        3217,
        51456
      ]
    },
    {
      "id": 138,
      "avg_logprob": -0.24607905745506287,
      "compression_ratio": 1.567685604095459,
      "end": 719.4199829101562,
      "no_speech_prob": 0.00010390940587967634,
      "seek": 69498,
      "start": 717.4199829101562,
      "temperature": 0.0,
      "text": " To see if it stays consistent",
      "tokens": [
        51486,
        1407,
        536,
        498,
        309,
        10834,
        8398,
        51586
      ]
    },
    {
      "id": 139,
      "avg_logprob": -0.27448517084121704,
      "compression_ratio": 1.623711347579956,
      "end": 729.6199951171875,
      "no_speech_prob": 0.00031014729756861925,
      "seek": 72498,
      "start": 725.3400268554688,
      "temperature": 0.0,
      "text": " Okay, no, so now it doesn't understand that it is from",
      "tokens": [
        50382,
        1033,
        11,
        572,
        11,
        370,
        586,
        309,
        1177,
        380,
        1223,
        300,
        309,
        307,
        490,
        50596
      ]
    },
    {
      "id": 140,
      "avg_logprob": -0.27448517084121704,
      "compression_ratio": 1.623711347579956,
      "end": 734.0999755859375,
      "no_speech_prob": 0.00031014729756861925,
      "seek": 72498,
      "start": 730.8599853515625,
      "temperature": 0.0,
      "text": " Yosemite so this is where prompt engineering can come in",
      "tokens": [
        50658,
        398,
        329,
        443,
        642,
        370,
        341,
        307,
        689,
        12391,
        7043,
        393,
        808,
        294,
        50820
      ]
    },
    {
      "id": 141,
      "avg_logprob": -0.27448517084121704,
      "compression_ratio": 1.623711347579956,
      "end": 740.8200073242188,
      "no_speech_prob": 0.00031014729756861925,
      "seek": 72498,
      "start": 734.260009765625,
      "temperature": 0.0,
      "text": " So if you write your prompt in a way where you almost forced a model to give you a city location",
      "tokens": [
        50828,
        407,
        498,
        291,
        2464,
        428,
        12391,
        294,
        257,
        636,
        689,
        291,
        1920,
        7579,
        257,
        2316,
        281,
        976,
        291,
        257,
        2307,
        4914,
        51156
      ]
    },
    {
      "id": 142,
      "avg_logprob": -0.27448517084121704,
      "compression_ratio": 1.623711347579956,
      "end": 746.0999755859375,
      "no_speech_prob": 0.00031014729756861925,
      "seek": 72498,
      "start": 741.739990234375,
      "temperature": 0.0,
      "text": " Most likely it will narrow it down to Yosemite",
      "tokens": [
        51202,
        3335,
        372,
        3700,
        309,
        486,
        9432,
        309,
        760,
        281,
        398,
        329,
        443,
        642,
        51420
      ]
    },
    {
      "id": 143,
      "avg_logprob": -0.27448517084121704,
      "compression_ratio": 1.623711347579956,
      "end": 750.5800170898438,
      "no_speech_prob": 0.00031014729756861925,
      "seek": 72498,
      "start": 746.2999877929688,
      "temperature": 0.0,
      "text": " But at that point you risk the model also giving you a city",
      "tokens": [
        51430,
        583,
        412,
        300,
        935,
        291,
        3148,
        264,
        2316,
        611,
        2902,
        291,
        257,
        2307,
        51644
      ]
    },
    {
      "id": 144,
      "avg_logprob": -0.32283854484558105,
      "compression_ratio": 1.5263158082962036,
      "end": 756.8599853515625,
      "no_speech_prob": 0.0005527702160179615,
      "seek": 75058,
      "start": 751.3400268554688,
      "temperature": 0.0,
      "text": " Answer when it's not too sure but only because you forced it through the prompt",
      "tokens": [
        50402,
        24545,
        562,
        309,
        311,
        406,
        886,
        988,
        457,
        787,
        570,
        291,
        7579,
        309,
        807,
        264,
        12391,
        50678
      ]
    },
    {
      "id": 145,
      "avg_logprob": -0.32283854484558105,
      "compression_ratio": 1.5263158082962036,
      "end": 759.6599731445312,
      "no_speech_prob": 0.0005527702160179615,
      "seek": 75058,
      "start": 757.6599731445312,
      "temperature": 0.0,
      "text": " but this is interesting because",
      "tokens": [
        50718,
        457,
        341,
        307,
        1880,
        570,
        50818
      ]
    },
    {
      "id": 146,
      "avg_logprob": -0.32283854484558105,
      "compression_ratio": 1.5263158082962036,
      "end": 762.1799926757812,
      "no_speech_prob": 0.0005527702160179615,
      "seek": 75058,
      "start": 760.1799926757812,
      "temperature": 0.0,
      "text": " Multiple times I've run it before",
      "tokens": [
        50844,
        40056,
        1413,
        286,
        600,
        1190,
        309,
        949,
        50944
      ]
    },
    {
      "id": 147,
      "avg_logprob": -0.32283854484558105,
      "compression_ratio": 1.5263158082962036,
      "end": 764.3400268554688,
      "no_speech_prob": 0.0005527702160179615,
      "seek": 75058,
      "start": 762.3400268554688,
      "temperature": 0.0,
      "text": " Every time it told me",
      "tokens": [
        50952,
        2048,
        565,
        309,
        1907,
        385,
        51052
      ]
    },
    {
      "id": 148,
      "avg_logprob": -0.32283854484558105,
      "compression_ratio": 1.5263158082962036,
      "end": 769.4199829101562,
      "no_speech_prob": 0.0005527702160179615,
      "seek": 75058,
      "start": 764.739990234375,
      "temperature": 0.0,
      "text": " Auto Camp Yosemite. Now you can see it cannot even determine the location of",
      "tokens": [
        51072,
        13738,
        9189,
        398,
        329,
        443,
        642,
        13,
        823,
        291,
        393,
        536,
        309,
        2644,
        754,
        6997,
        264,
        4914,
        295,
        51306
      ]
    },
    {
      "id": 149,
      "avg_logprob": -0.32283854484558105,
      "compression_ratio": 1.5263158082962036,
      "end": 777.5,
      "no_speech_prob": 0.0005527702160179615,
      "seek": 75058,
      "start": 770.5399780273438,
      "temperature": 0.0,
      "text": " From the image, right? So again similar to the counting problem. You can see like these models are very",
      "tokens": [
        51362,
        3358,
        264,
        3256,
        11,
        558,
        30,
        407,
        797,
        2531,
        281,
        264,
        13251,
        1154,
        13,
        509,
        393,
        536,
        411,
        613,
        5245,
        366,
        588,
        51710
      ]
    },
    {
      "id": 150,
      "avg_logprob": -0.2746299207210541,
      "compression_ratio": 1.6622222661972046,
      "end": 784.5,
      "no_speech_prob": 0.0008166807820089161,
      "seek": 77750,
      "start": 778.260009765625,
      "temperature": 0.0,
      "text": " Non-deterministic so you cannot always rely on it giving you the same answer every single time",
      "tokens": [
        50402,
        8774,
        12,
        49136,
        259,
        3142,
        370,
        291,
        2644,
        1009,
        10687,
        322,
        309,
        2902,
        291,
        264,
        912,
        1867,
        633,
        2167,
        565,
        50714
      ]
    },
    {
      "id": 151,
      "avg_logprob": -0.2746299207210541,
      "compression_ratio": 1.6622222661972046,
      "end": 791.2999877929688,
      "no_speech_prob": 0.0008166807820089161,
      "seek": 77750,
      "start": 785.1400146484375,
      "temperature": 0.0,
      "text": " Ideally you want to get a ballpark idea of what the answer could be and then you want to write your prompt in such a",
      "tokens": [
        50746,
        40817,
        291,
        528,
        281,
        483,
        257,
        2594,
        31239,
        1558,
        295,
        437,
        264,
        1867,
        727,
        312,
        293,
        550,
        291,
        528,
        281,
        2464,
        428,
        12391,
        294,
        1270,
        257,
        51054
      ]
    },
    {
      "id": 152,
      "avg_logprob": -0.2746299207210541,
      "compression_ratio": 1.6622222661972046,
      "end": 793.2999877929688,
      "no_speech_prob": 0.0008166807820089161,
      "seek": 77750,
      "start": 791.2999877929688,
      "temperature": 0.0,
      "text": " way that you always",
      "tokens": [
        51054,
        636,
        300,
        291,
        1009,
        51154
      ]
    },
    {
      "id": 153,
      "avg_logprob": -0.2746299207210541,
      "compression_ratio": 1.6622222661972046,
      "end": 798.0999755859375,
      "no_speech_prob": 0.0008166807820089161,
      "seek": 77750,
      "start": 793.5800170898438,
      "temperature": 0.0,
      "text": " Give it sort of in structure to follow when giving you an answer",
      "tokens": [
        51168,
        5303,
        309,
        1333,
        295,
        294,
        3877,
        281,
        1524,
        562,
        2902,
        291,
        364,
        1867,
        51394
      ]
    },
    {
      "id": 154,
      "avg_logprob": -0.2746299207210541,
      "compression_ratio": 1.6622222661972046,
      "end": 804.9000244140625,
      "no_speech_prob": 0.0008166807820089161,
      "seek": 77750,
      "start": 799.9400024414062,
      "temperature": 0.0,
      "text": " All right, and then let me not run it again, but I'll move back over here now",
      "tokens": [
        51486,
        1057,
        558,
        11,
        293,
        550,
        718,
        385,
        406,
        1190,
        309,
        797,
        11,
        457,
        286,
        603,
        1286,
        646,
        670,
        510,
        586,
        51734
      ]
    },
    {
      "id": 155,
      "avg_logprob": -0.2774978578090668,
      "compression_ratio": 1.6557377576828003,
      "end": 809.739990234375,
      "no_speech_prob": 0.00011060956603614613,
      "seek": 80490,
      "start": 805.1799926757812,
      "temperature": 0.0,
      "text": " So if you remember for the Dhaka one every time it was narrowing it down to Bangladesh",
      "tokens": [
        50378,
        407,
        498,
        291,
        1604,
        337,
        264,
        34414,
        7849,
        472,
        633,
        565,
        309,
        390,
        9432,
        278,
        309,
        760,
        281,
        35260,
        50606
      ]
    },
    {
      "id": 156,
      "avg_logprob": -0.2774978578090668,
      "compression_ratio": 1.6557377576828003,
      "end": 817.5,
      "no_speech_prob": 0.00011060956603614613,
      "seek": 80490,
      "start": 810.2999877929688,
      "temperature": 0.0,
      "text": " And then for the random for the random one it as you saw sometimes it does not even notice that this is in Yosemite",
      "tokens": [
        50634,
        400,
        550,
        337,
        264,
        3342,
        273,
        298,
        337,
        264,
        4974,
        472,
        309,
        382,
        291,
        1866,
        2171,
        309,
        775,
        406,
        754,
        3449,
        300,
        341,
        307,
        294,
        398,
        329,
        443,
        642,
        50994
      ]
    },
    {
      "id": 157,
      "avg_logprob": -0.2774978578090668,
      "compression_ratio": 1.6557377576828003,
      "end": 823.739990234375,
      "no_speech_prob": 0.00011060956603614613,
      "seek": 80490,
      "start": 817.780029296875,
      "temperature": 0.0,
      "text": " So I'm gonna try these two again, but with a much more powerful model now to to see what happens",
      "tokens": [
        51008,
        407,
        286,
        478,
        799,
        853,
        613,
        732,
        797,
        11,
        457,
        365,
        257,
        709,
        544,
        4005,
        2316,
        586,
        281,
        281,
        536,
        437,
        2314,
        51306
      ]
    },
    {
      "id": 158,
      "avg_logprob": -0.2774978578090668,
      "compression_ratio": 1.6557377576828003,
      "end": 829.4199829101562,
      "no_speech_prob": 0.00011060956603614613,
      "seek": 80490,
      "start": 823.8599853515625,
      "temperature": 0.0,
      "text": " Okay, so we're gonna try GPT 5 and then we're gonna go back to the Dhaka URL",
      "tokens": [
        51312,
        1033,
        11,
        370,
        321,
        434,
        799,
        853,
        26039,
        51,
        1025,
        293,
        550,
        321,
        434,
        799,
        352,
        646,
        281,
        264,
        34414,
        7849,
        12905,
        51590
      ]
    },
    {
      "id": 159,
      "avg_logprob": -0.2774978578090668,
      "compression_ratio": 1.6557377576828003,
      "end": 832.3800048828125,
      "no_speech_prob": 0.00011060956603614613,
      "seek": 80490,
      "start": 830.3800048828125,
      "temperature": 0.0,
      "text": " Now, let's see what happens",
      "tokens": [
        51638,
        823,
        11,
        718,
        311,
        536,
        437,
        2314,
        51738
      ]
    },
    {
      "id": 160,
      "avg_logprob": -0.25887078046798706,
      "compression_ratio": 1.6140351295471191,
      "end": 837.219970703125,
      "no_speech_prob": 3.219076097593643e-05,
      "seek": 83238,
      "start": 832.97998046875,
      "temperature": 0.0,
      "text": " So this will take a little longer so just bear with me here",
      "tokens": [
        50394,
        407,
        341,
        486,
        747,
        257,
        707,
        2854,
        370,
        445,
        6155,
        365,
        385,
        510,
        50606
      ]
    },
    {
      "id": 161,
      "avg_logprob": -0.25887078046798706,
      "compression_ratio": 1.6140351295471191,
      "end": 844.8200073242188,
      "no_speech_prob": 3.219076097593643e-05,
      "seek": 83238,
      "start": 840.5399780273438,
      "temperature": 0.0,
      "text": " So whenever you're using a powerful model, it's always gonna take a lot longer",
      "tokens": [
        50772,
        407,
        5699,
        291,
        434,
        1228,
        257,
        4005,
        2316,
        11,
        309,
        311,
        1009,
        799,
        747,
        257,
        688,
        2854,
        50986
      ]
    },
    {
      "id": 162,
      "avg_logprob": -0.25887078046798706,
      "compression_ratio": 1.6140351295471191,
      "end": 847.4199829101562,
      "no_speech_prob": 3.219076097593643e-05,
      "seek": 83238,
      "start": 846.0599975585938,
      "temperature": 0.0,
      "text": " similarly",
      "tokens": [
        51048,
        14138,
        51116
      ]
    },
    {
      "id": 163,
      "avg_logprob": -0.25887078046798706,
      "compression_ratio": 1.6140351295471191,
      "end": 850.5,
      "no_speech_prob": 3.219076097593643e-05,
      "seek": 83238,
      "start": 847.4199829101562,
      "temperature": 0.0,
      "text": " You saw how long it takes with the GPT 4.0 model",
      "tokens": [
        51116,
        509,
        1866,
        577,
        938,
        309,
        2516,
        365,
        264,
        26039,
        51,
        1017,
        13,
        15,
        2316,
        51270
      ]
    },
    {
      "id": 164,
      "avg_logprob": -0.25887078046798706,
      "compression_ratio": 1.6140351295471191,
      "end": 855.5399780273438,
      "no_speech_prob": 3.219076097593643e-05,
      "seek": 83238,
      "start": 850.5399780273438,
      "temperature": 0.0,
      "text": " But if we're using a much less powerful model, it's gonna give you an answer much quicker",
      "tokens": [
        51272,
        583,
        498,
        321,
        434,
        1228,
        257,
        709,
        1570,
        4005,
        2316,
        11,
        309,
        311,
        799,
        976,
        291,
        364,
        1867,
        709,
        16255,
        51522
      ]
    },
    {
      "id": 165,
      "avg_logprob": -0.25887078046798706,
      "compression_ratio": 1.6140351295471191,
      "end": 861.3800048828125,
      "no_speech_prob": 3.219076097593643e-05,
      "seek": 83238,
      "start": 856.2999877929688,
      "temperature": 0.0,
      "text": " So now you're seeing it does say likely Dhaka Bangladesh. I'm gonna run it again",
      "tokens": [
        51560,
        407,
        586,
        291,
        434,
        2577,
        309,
        775,
        584,
        3700,
        34414,
        7849,
        35260,
        13,
        286,
        478,
        799,
        1190,
        309,
        797,
        51814
      ]
    },
    {
      "id": 166,
      "avg_logprob": -0.30770137906074524,
      "compression_ratio": 1.4814814329147339,
      "end": 865.5399780273438,
      "no_speech_prob": 0.00032996837398968637,
      "seek": 86238,
      "start": 862.6599731445312,
      "temperature": 0.0,
      "text": " To see if it gets me to Dhaka again",
      "tokens": [
        50378,
        1407,
        536,
        498,
        309,
        2170,
        385,
        281,
        34414,
        7849,
        797,
        50522
      ]
    },
    {
      "id": 167,
      "avg_logprob": -0.30770137906074524,
      "compression_ratio": 1.4814814329147339,
      "end": 871.1400146484375,
      "no_speech_prob": 0.00032996837398968637,
      "seek": 86238,
      "start": 869.1400146484375,
      "temperature": 0.0,
      "text": " Give it a few seconds again",
      "tokens": [
        50702,
        5303,
        309,
        257,
        1326,
        3949,
        797,
        50802
      ]
    },
    {
      "id": 168,
      "avg_logprob": -0.30770137906074524,
      "compression_ratio": 1.4814814329147339,
      "end": 880.0999755859375,
      "no_speech_prob": 0.00032996837398968637,
      "seek": 86238,
      "start": 872.9400024414062,
      "temperature": 0.0,
      "text": " And while we while we wait for the response, let me go and remind you this is the photo we're working through",
      "tokens": [
        50892,
        400,
        1339,
        321,
        1339,
        321,
        1699,
        337,
        264,
        4134,
        11,
        718,
        385,
        352,
        293,
        4160,
        291,
        341,
        307,
        264,
        5052,
        321,
        434,
        1364,
        807,
        51250
      ]
    },
    {
      "id": 169,
      "avg_logprob": -0.30770137906074524,
      "compression_ratio": 1.4814814329147339,
      "end": 884.02001953125,
      "no_speech_prob": 0.00032996837398968637,
      "seek": 86238,
      "start": 882.4600219726562,
      "temperature": 0.0,
      "text": " And",
      "tokens": [
        51368,
        400,
        51446
      ]
    },
    {
      "id": 170,
      "avg_logprob": -0.30770137906074524,
      "compression_ratio": 1.4814814329147339,
      "end": 887.4199829101562,
      "no_speech_prob": 0.00032996837398968637,
      "seek": 86238,
      "start": 884.02001953125,
      "temperature": 0.0,
      "text": " They get it again. Yeah, it got it again, which is pretty cool",
      "tokens": [
        51446,
        814,
        483,
        309,
        797,
        13,
        865,
        11,
        309,
        658,
        309,
        797,
        11,
        597,
        307,
        1238,
        1627,
        51616
      ]
    },
    {
      "id": 171,
      "avg_logprob": -0.2842100262641907,
      "compression_ratio": 1.5288889408111572,
      "end": 891.9000244140625,
      "no_speech_prob": 0.0008426010608673096,
      "seek": 88742,
      "start": 887.4199829101562,
      "temperature": 0.0,
      "text": " So you can see sort of that when you use a powerful model the responses",
      "tokens": [
        50364,
        407,
        291,
        393,
        536,
        1333,
        295,
        300,
        562,
        291,
        764,
        257,
        4005,
        2316,
        264,
        13019,
        50588
      ]
    },
    {
      "id": 172,
      "avg_logprob": -0.2842100262641907,
      "compression_ratio": 1.5288889408111572,
      "end": 895.6199951171875,
      "no_speech_prob": 0.0008426010608673096,
      "seek": 88742,
      "start": 891.97998046875,
      "temperature": 0.0,
      "text": " Yes, they are slower, but they tend to be a lot more accurate than",
      "tokens": [
        50592,
        1079,
        11,
        436,
        366,
        14009,
        11,
        457,
        436,
        3928,
        281,
        312,
        257,
        688,
        544,
        8559,
        813,
        50774
      ]
    },
    {
      "id": 173,
      "avg_logprob": -0.2842100262641907,
      "compression_ratio": 1.5288889408111572,
      "end": 898.3400268554688,
      "no_speech_prob": 0.0008426010608673096,
      "seek": 88742,
      "start": 896.3400268554688,
      "temperature": 0.0,
      "text": " than 4.0 in our case",
      "tokens": [
        50810,
        813,
        1017,
        13,
        15,
        294,
        527,
        1389,
        50910
      ]
    },
    {
      "id": 174,
      "avg_logprob": -0.2842100262641907,
      "compression_ratio": 1.5288889408111572,
      "end": 903.780029296875,
      "no_speech_prob": 0.0008426010608673096,
      "seek": 88742,
      "start": 899.260009765625,
      "temperature": 0.0,
      "text": " Now the one I really want to try is the Yosemite one because if you remember",
      "tokens": [
        50956,
        823,
        264,
        472,
        286,
        534,
        528,
        281,
        853,
        307,
        264,
        398,
        329,
        443,
        642,
        472,
        570,
        498,
        291,
        1604,
        51182
      ]
    },
    {
      "id": 175,
      "avg_logprob": -0.2842100262641907,
      "compression_ratio": 1.5288889408111572,
      "end": 908.739990234375,
      "no_speech_prob": 0.0008426010608673096,
      "seek": 88742,
      "start": 904.0999755859375,
      "temperature": 0.0,
      "text": " We tried with like five times and it only got it two times. I want to see if with",
      "tokens": [
        51198,
        492,
        3031,
        365,
        411,
        1732,
        1413,
        293,
        309,
        787,
        658,
        309,
        732,
        1413,
        13,
        286,
        528,
        281,
        536,
        498,
        365,
        51430
      ]
    },
    {
      "id": 176,
      "avg_logprob": -0.2842100262641907,
      "compression_ratio": 1.5288889408111572,
      "end": 912.0999755859375,
      "no_speech_prob": 0.0008426010608673096,
      "seek": 88742,
      "start": 909.9400024414062,
      "temperature": 0.0,
      "text": " GPT 5 we have better odds",
      "tokens": [
        51490,
        26039,
        51,
        1025,
        321,
        362,
        1101,
        17439,
        51598
      ]
    },
    {
      "id": 177,
      "avg_logprob": -0.4358220100402832,
      "compression_ratio": 1.4311376810073853,
      "end": 914.5399780273438,
      "no_speech_prob": 0.0008692577830515802,
      "seek": 91210,
      "start": 912.5399780273438,
      "temperature": 0.0,
      "text": " So",
      "tokens": [
        50386,
        407,
        50486
      ]
    },
    {
      "id": 178,
      "avg_logprob": -0.4358220100402832,
      "compression_ratio": 1.4311376810073853,
      "end": 919.9400024414062,
      "no_speech_prob": 0.0008692577830515802,
      "seek": 91210,
      "start": 914.5399780273438,
      "temperature": 0.0,
      "text": " While we wait again just to remind you this is what we're aiming for. This is the photo that we're processing",
      "tokens": [
        50486,
        3987,
        321,
        1699,
        797,
        445,
        281,
        4160,
        291,
        341,
        307,
        437,
        321,
        434,
        20253,
        337,
        13,
        639,
        307,
        264,
        5052,
        300,
        321,
        434,
        9510,
        442,
        278,
        50756
      ]
    },
    {
      "id": 179,
      "avg_logprob": -0.4358220100402832,
      "compression_ratio": 1.4311376810073853,
      "end": 929.0599975585938,
      "no_speech_prob": 0.0008692577830515802,
      "seek": 91210,
      "start": 922.02001953125,
      "temperature": 0.0,
      "text": " Yep, it's very direct AutoCAM Yosemite and it even goes as deep as mid pines, California, which is the exact city",
      "tokens": [
        50860,
        7010,
        11,
        309,
        311,
        588,
        2047,
        13738,
        34,
        2865,
        398,
        329,
        443,
        642,
        293,
        309,
        754,
        1709,
        382,
        2452,
        382,
        2062,
        280,
        1652,
        11,
        5384,
        11,
        597,
        307,
        264,
        1900,
        2307,
        51212
      ]
    },
    {
      "id": 180,
      "avg_logprob": -0.4358220100402832,
      "compression_ratio": 1.4311376810073853,
      "end": 931.9400024414062,
      "no_speech_prob": 0.0008692577830515802,
      "seek": 91210,
      "start": 929.9400024414062,
      "temperature": 0.0,
      "text": " Run it again",
      "tokens": [
        51256,
        8950,
        309,
        797,
        51356
      ]
    },
    {
      "id": 181,
      "avg_logprob": -0.40335291624069214,
      "compression_ratio": 1.4140127897262573,
      "end": 944.0999755859375,
      "no_speech_prob": 0.0002341278304811567,
      "seek": 94210,
      "start": 942.0999755859375,
      "temperature": 0.0,
      "text": " So",
      "tokens": [
        50364,
        407,
        50464
      ]
    },
    {
      "id": 182,
      "avg_logprob": -0.40335291624069214,
      "compression_ratio": 1.4140127897262573,
      "end": 950.3400268554688,
      "no_speech_prob": 0.0002341278304811567,
      "seek": 94210,
      "start": 946.4600219726562,
      "temperature": 0.0,
      "text": " Yeah, the five model always takes a lot longer than 4.0",
      "tokens": [
        50582,
        865,
        11,
        264,
        1732,
        2316,
        1009,
        2516,
        257,
        688,
        2854,
        813,
        1017,
        13,
        15,
        50776
      ]
    },
    {
      "id": 183,
      "avg_logprob": -0.40335291624069214,
      "compression_ratio": 1.4140127897262573,
      "end": 955.219970703125,
      "no_speech_prob": 0.0002341278304811567,
      "seek": 94210,
      "start": 951.2999877929688,
      "temperature": 0.0,
      "text": " But let's keep waiting until we get the response",
      "tokens": [
        50824,
        583,
        718,
        311,
        1066,
        3806,
        1826,
        321,
        483,
        264,
        4134,
        51020
      ]
    },
    {
      "id": 184,
      "avg_logprob": -0.40335291624069214,
      "compression_ratio": 1.4140127897262573,
      "end": 963.1799926757812,
      "no_speech_prob": 0.0002341278304811567,
      "seek": 94210,
      "start": 959.3800048828125,
      "temperature": 0.0,
      "text": " Yep both times this time it did not get mid pines",
      "tokens": [
        51228,
        7010,
        1293,
        1413,
        341,
        565,
        309,
        630,
        406,
        483,
        2062,
        280,
        1652,
        51418
      ]
    },
    {
      "id": 185,
      "avg_logprob": -0.40335291624069214,
      "compression_ratio": 1.4140127897262573,
      "end": 968.7000122070312,
      "no_speech_prob": 0.0002341278304811567,
      "seek": 94210,
      "start": 963.1799926757812,
      "temperature": 0.0,
      "text": " But it get it did get a city closer or close which is a Mariposa",
      "tokens": [
        51418,
        583,
        309,
        483,
        309,
        630,
        483,
        257,
        2307,
        4966,
        420,
        1998,
        597,
        307,
        257,
        2039,
        647,
        6447,
        51694
      ]
    },
    {
      "id": 186,
      "avg_logprob": -0.26803067326545715,
      "compression_ratio": 1.5328466892242432,
      "end": 973.4199829101562,
      "no_speech_prob": 3.59125915565528e-05,
      "seek": 96870,
      "start": 969.4199829101562,
      "temperature": 0.0,
      "text": " All right, so I think we can fairly at least from our examples",
      "tokens": [
        50400,
        1057,
        558,
        11,
        370,
        286,
        519,
        321,
        393,
        6457,
        412,
        1935,
        490,
        527,
        5110,
        50600
      ]
    },
    {
      "id": 187,
      "avg_logprob": -0.26803067326545715,
      "compression_ratio": 1.5328466892242432,
      "end": 979.8200073242188,
      "no_speech_prob": 3.59125915565528e-05,
      "seek": 96870,
      "start": 973.4199829101562,
      "temperature": 0.0,
      "text": " Oh, we can really conclude that a GPT 5 is getting as a better response or more accurate response",
      "tokens": [
        50600,
        876,
        11,
        321,
        393,
        534,
        16886,
        300,
        257,
        26039,
        51,
        1025,
        307,
        1242,
        382,
        257,
        1101,
        4134,
        420,
        544,
        8559,
        4134,
        50920
      ]
    },
    {
      "id": 188,
      "avg_logprob": -0.26803067326545715,
      "compression_ratio": 1.5328466892242432,
      "end": 982.8200073242188,
      "no_speech_prob": 3.59125915565528e-05,
      "seek": 96870,
      "start": 979.8200073242188,
      "temperature": 0.0,
      "text": " But it is taking significantly longer than the other model",
      "tokens": [
        50920,
        583,
        309,
        307,
        1940,
        10591,
        2854,
        813,
        264,
        661,
        2316,
        51070
      ]
    },
    {
      "id": 189,
      "avg_logprob": -0.26803067326545715,
      "compression_ratio": 1.5328466892242432,
      "end": 988.780029296875,
      "no_speech_prob": 3.59125915565528e-05,
      "seek": 96870,
      "start": 983.3400268554688,
      "temperature": 0.0,
      "text": " So I'm gonna move back to our 4.0 model and then let's wrap up by looking at these",
      "tokens": [
        51096,
        407,
        286,
        478,
        799,
        1286,
        646,
        281,
        527,
        1017,
        13,
        15,
        2316,
        293,
        550,
        718,
        311,
        7019,
        493,
        538,
        1237,
        412,
        613,
        51368
      ]
    },
    {
      "id": 190,
      "avg_logprob": -0.26803067326545715,
      "compression_ratio": 1.5328466892242432,
      "end": 996.3800048828125,
      "no_speech_prob": 3.59125915565528e-05,
      "seek": 96870,
      "start": 989.4600219726562,
      "temperature": 0.0,
      "text": " People faces emotions photos. Okay. I've got four over here. Let's take a look. We have a screaming one from unsplash",
      "tokens": [
        51402,
        3432,
        8475,
        8462,
        5787,
        13,
        1033,
        13,
        286,
        600,
        658,
        1451,
        670,
        510,
        13,
        961,
        311,
        747,
        257,
        574,
        13,
        492,
        362,
        257,
        12636,
        472,
        490,
        2693,
        564,
        1299,
        51748
      ]
    },
    {
      "id": 191,
      "avg_logprob": -0.30595865845680237,
      "compression_ratio": 1.6040608882904053,
      "end": 1000.7000122070312,
      "no_speech_prob": 0.00022692054335493594,
      "seek": 99638,
      "start": 997.0999755859375,
      "temperature": 0.0,
      "text": " We got a person who is sad frustrated",
      "tokens": [
        50400,
        492,
        658,
        257,
        954,
        567,
        307,
        4227,
        15751,
        50580
      ]
    },
    {
      "id": 192,
      "avg_logprob": -0.30595865845680237,
      "compression_ratio": 1.6040608882904053,
      "end": 1006.1400146484375,
      "no_speech_prob": 0.00022692054335493594,
      "seek": 99638,
      "start": 1002.219970703125,
      "temperature": 0.0,
      "text": " We have got someone who's happy and then we have got someone who's crying",
      "tokens": [
        50656,
        492,
        362,
        658,
        1580,
        567,
        311,
        2055,
        293,
        550,
        321,
        362,
        658,
        1580,
        567,
        311,
        8554,
        50852
      ]
    },
    {
      "id": 193,
      "avg_logprob": -0.30595865845680237,
      "compression_ratio": 1.6040608882904053,
      "end": 1010.0999755859375,
      "no_speech_prob": 0.00022692054335493594,
      "seek": 99638,
      "start": 1006.3800048828125,
      "temperature": 0.0,
      "text": " Okay, all these all four are taken from unsplash",
      "tokens": [
        50864,
        1033,
        11,
        439,
        613,
        439,
        1451,
        366,
        2726,
        490,
        2693,
        564,
        1299,
        51050
      ]
    },
    {
      "id": 194,
      "avg_logprob": -0.30595865845680237,
      "compression_ratio": 1.6040608882904053,
      "end": 1014.4600219726562,
      "no_speech_prob": 0.00022692054335493594,
      "seek": 99638,
      "start": 1010.97998046875,
      "temperature": 0.0,
      "text": " So let's run through them one by one. So we're gonna change the",
      "tokens": [
        51094,
        407,
        718,
        311,
        1190,
        807,
        552,
        472,
        538,
        472,
        13,
        407,
        321,
        434,
        799,
        1319,
        264,
        51268
      ]
    },
    {
      "id": 195,
      "avg_logprob": -0.30595865845680237,
      "compression_ratio": 1.6040608882904053,
      "end": 1016.8599853515625,
      "no_speech_prob": 0.00022692054335493594,
      "seek": 99638,
      "start": 1015.1799926757812,
      "temperature": 0.0,
      "text": " prompt to",
      "tokens": [
        51304,
        12391,
        281,
        51388
      ]
    },
    {
      "id": 196,
      "avg_logprob": -0.30595865845680237,
      "compression_ratio": 1.6040608882904053,
      "end": 1020.1799926757812,
      "no_speech_prob": 0.00022692054335493594,
      "seek": 99638,
      "start": 1016.8599853515625,
      "temperature": 0.0,
      "text": " What emotion do you see in the image?",
      "tokens": [
        51388,
        708,
        8913,
        360,
        291,
        536,
        294,
        264,
        3256,
        30,
        51554
      ]
    },
    {
      "id": 197,
      "avg_logprob": -0.30595865845680237,
      "compression_ratio": 1.6040608882904053,
      "end": 1023.02001953125,
      "no_speech_prob": 0.00022692054335493594,
      "seek": 99638,
      "start": 1020.8599853515625,
      "temperature": 0.0,
      "text": " And then let's start with the screaming one",
      "tokens": [
        51588,
        400,
        550,
        718,
        311,
        722,
        365,
        264,
        12636,
        472,
        51696
      ]
    },
    {
      "id": 198,
      "avg_logprob": -0.3008972704410553,
      "compression_ratio": 1.581673264503479,
      "end": 1029.3800048828125,
      "no_speech_prob": 0.00034061860060319304,
      "seek": 102638,
      "start": 1027.3800048828125,
      "temperature": 0.0,
      "text": " Okay",
      "tokens": [
        50414,
        1033,
        50514
      ]
    },
    {
      "id": 199,
      "avg_logprob": -0.3008972704410553,
      "compression_ratio": 1.581673264503479,
      "end": 1034.3800048828125,
      "no_speech_prob": 0.00034061860060319304,
      "seek": 102638,
      "start": 1030.219970703125,
      "temperature": 0.0,
      "text": " This will be quicker because we have switched back to the 4.0 model",
      "tokens": [
        50556,
        639,
        486,
        312,
        16255,
        570,
        321,
        362,
        16858,
        646,
        281,
        264,
        1017,
        13,
        15,
        2316,
        50764
      ]
    },
    {
      "id": 200,
      "avg_logprob": -0.3008972704410553,
      "compression_ratio": 1.581673264503479,
      "end": 1038.8599853515625,
      "no_speech_prob": 0.00034061860060319304,
      "seek": 102638,
      "start": 1034.3800048828125,
      "temperature": 0.0,
      "text": " But it will come at the trade-off of a poor quality responses",
      "tokens": [
        50764,
        583,
        309,
        486,
        808,
        412,
        264,
        4923,
        12,
        4506,
        295,
        257,
        4716,
        3125,
        13019,
        50988
      ]
    },
    {
      "id": 201,
      "avg_logprob": -0.3008972704410553,
      "compression_ratio": 1.581673264503479,
      "end": 1048.9000244140625,
      "no_speech_prob": 0.00034061860060319304,
      "seek": 102638,
      "start": 1041.739990234375,
      "temperature": 0.0,
      "text": " Okay, let's say it says emotions such as excitement joy or surprise a which it's fairly accurate because when I looked at the photo",
      "tokens": [
        51132,
        1033,
        11,
        718,
        311,
        584,
        309,
        1619,
        8462,
        1270,
        382,
        14755,
        6258,
        420,
        6365,
        257,
        597,
        309,
        311,
        6457,
        8559,
        570,
        562,
        286,
        2956,
        412,
        264,
        5052,
        51490
      ]
    },
    {
      "id": 202,
      "avg_logprob": -0.3008972704410553,
      "compression_ratio": 1.581673264503479,
      "end": 1050.0999755859375,
      "no_speech_prob": 0.00034061860060319304,
      "seek": 102638,
      "start": 1048.9000244140625,
      "temperature": 0.0,
      "text": " Let's go back to it",
      "tokens": [
        51490,
        961,
        311,
        352,
        646,
        281,
        309,
        51550
      ]
    },
    {
      "id": 203,
      "avg_logprob": -0.3008972704410553,
      "compression_ratio": 1.581673264503479,
      "end": 1055.4200439453125,
      "no_speech_prob": 0.00034061860060319304,
      "seek": 102638,
      "start": 1050.0999755859375,
      "temperature": 0.0,
      "text": " Even I wasn't sure about the emotion so you can see like the model not trying too hard to get you one response",
      "tokens": [
        51550,
        2754,
        286,
        2067,
        380,
        988,
        466,
        264,
        8913,
        370,
        291,
        393,
        536,
        411,
        264,
        2316,
        406,
        1382,
        886,
        1152,
        281,
        483,
        291,
        472,
        4134,
        51816
      ]
    },
    {
      "id": 204,
      "avg_logprob": -0.3110843300819397,
      "compression_ratio": 1.5714285373687744,
      "end": 1059.8599853515625,
      "no_speech_prob": 0.00016345511539839208,
      "seek": 105542,
      "start": 1056.4200439453125,
      "temperature": 0.0,
      "text": " Now let's move to the second one, which is a lot more clear",
      "tokens": [
        50414,
        823,
        718,
        311,
        1286,
        281,
        264,
        1150,
        472,
        11,
        597,
        307,
        257,
        688,
        544,
        1850,
        50586
      ]
    },
    {
      "id": 205,
      "avg_logprob": -0.3110843300819397,
      "compression_ratio": 1.5714285373687744,
      "end": 1063.219970703125,
      "no_speech_prob": 0.00016345511539839208,
      "seek": 105542,
      "start": 1060.699951171875,
      "temperature": 0.0,
      "text": " So we're gonna try the sad face",
      "tokens": [
        50628,
        407,
        321,
        434,
        799,
        853,
        264,
        4227,
        1851,
        50754
      ]
    },
    {
      "id": 206,
      "avg_logprob": -0.3110843300819397,
      "compression_ratio": 1.5714285373687744,
      "end": 1067.780029296875,
      "no_speech_prob": 0.00016345511539839208,
      "seek": 105542,
      "start": 1064.97998046875,
      "temperature": 0.0,
      "text": " Or anxious, so let's try running it here",
      "tokens": [
        50842,
        1610,
        15166,
        11,
        370,
        718,
        311,
        853,
        2614,
        309,
        510,
        50982
      ]
    },
    {
      "id": 207,
      "avg_logprob": -0.3110843300819397,
      "compression_ratio": 1.5714285373687744,
      "end": 1080.06005859375,
      "no_speech_prob": 0.00016345511539839208,
      "seek": 105542,
      "start": 1073.02001953125,
      "temperature": 0.0,
      "text": " Yeah, it gets that stress and frustration part which is pretty cool and then we're gonna try the smiling face",
      "tokens": [
        51244,
        865,
        11,
        309,
        2170,
        300,
        4244,
        293,
        20491,
        644,
        597,
        307,
        1238,
        1627,
        293,
        550,
        321,
        434,
        799,
        853,
        264,
        16005,
        1851,
        51596
      ]
    },
    {
      "id": 208,
      "avg_logprob": -0.2738538980484009,
      "compression_ratio": 1.600000023841858,
      "end": 1086.1400146484375,
      "no_speech_prob": 0.001501086400821805,
      "seek": 108006,
      "start": 1080.97998046875,
      "temperature": 0.0,
      "text": " And the reason I'm not rerunning for the same photo is when I did it before it was always the same",
      "tokens": [
        50410,
        400,
        264,
        1778,
        286,
        478,
        406,
        43819,
        25589,
        337,
        264,
        912,
        5052,
        307,
        562,
        286,
        630,
        309,
        949,
        309,
        390,
        1009,
        264,
        912,
        50668
      ]
    },
    {
      "id": 209,
      "avg_logprob": -0.2738538980484009,
      "compression_ratio": 1.600000023841858,
      "end": 1089.02001953125,
      "no_speech_prob": 0.001501086400821805,
      "seek": 108006,
      "start": 1087.02001953125,
      "temperature": 0.0,
      "text": " Which is pretty cool",
      "tokens": [
        50712,
        3013,
        307,
        1238,
        1627,
        50812
      ]
    },
    {
      "id": 210,
      "avg_logprob": -0.2738538980484009,
      "compression_ratio": 1.600000023841858,
      "end": 1095.06005859375,
      "no_speech_prob": 0.001501086400821805,
      "seek": 108006,
      "start": 1089.9000244140625,
      "temperature": 0.0,
      "text": " Yes, joy or happiness and if I run it again most likely you're gonna see the same response",
      "tokens": [
        50856,
        1079,
        11,
        6258,
        420,
        8324,
        293,
        498,
        286,
        1190,
        309,
        797,
        881,
        3700,
        291,
        434,
        799,
        536,
        264,
        912,
        4134,
        51114
      ]
    },
    {
      "id": 211,
      "avg_logprob": -0.2738538980484009,
      "compression_ratio": 1.600000023841858,
      "end": 1101.780029296875,
      "no_speech_prob": 0.001501086400821805,
      "seek": 108006,
      "start": 1096.97998046875,
      "temperature": 0.0,
      "text": " Yep, there you go, and then we're gonna try the final one which is the crying face. This is the one",
      "tokens": [
        51210,
        7010,
        11,
        456,
        291,
        352,
        11,
        293,
        550,
        321,
        434,
        799,
        853,
        264,
        2572,
        472,
        597,
        307,
        264,
        8554,
        1851,
        13,
        639,
        307,
        264,
        472,
        51450
      ]
    },
    {
      "id": 212,
      "avg_logprob": -0.2738538980484009,
      "compression_ratio": 1.600000023841858,
      "end": 1108.9000244140625,
      "no_speech_prob": 0.001501086400821805,
      "seek": 108006,
      "start": 1106.9000244140625,
      "temperature": 0.0,
      "text": " All right",
      "tokens": [
        51706,
        1057,
        558,
        51806
      ]
    },
    {
      "id": 213,
      "avg_logprob": -0.2960578203201294,
      "compression_ratio": 1.5233160257339478,
      "end": 1117.1400146484375,
      "no_speech_prob": 0.00022340990835800767,
      "seek": 111006,
      "start": 1111.06005859375,
      "temperature": 0.0,
      "text": " And it's sadness or distress and it was fairly consistent when I ran it before",
      "tokens": [
        50414,
        400,
        309,
        311,
        22462,
        420,
        24516,
        293,
        309,
        390,
        6457,
        8398,
        562,
        286,
        5872,
        309,
        949,
        50718
      ]
    },
    {
      "id": 214,
      "avg_logprob": -0.2960578203201294,
      "compression_ratio": 1.5233160257339478,
      "end": 1121.8199462890625,
      "no_speech_prob": 0.00022340990835800767,
      "seek": 111006,
      "start": 1119.8199462890625,
      "temperature": 0.0,
      "text": " Yeah, so I think in conclusion",
      "tokens": [
        50852,
        865,
        11,
        370,
        286,
        519,
        294,
        10063,
        50952
      ]
    },
    {
      "id": 215,
      "avg_logprob": -0.2960578203201294,
      "compression_ratio": 1.5233160257339478,
      "end": 1127.739990234375,
      "no_speech_prob": 0.00022340990835800767,
      "seek": 111006,
      "start": 1122.780029296875,
      "temperature": 0.0,
      "text": " You're gonna see that the model does very well with emotions location was really good as well",
      "tokens": [
        51000,
        509,
        434,
        799,
        536,
        300,
        264,
        2316,
        775,
        588,
        731,
        365,
        8462,
        4914,
        390,
        534,
        665,
        382,
        731,
        51248
      ]
    },
    {
      "id": 216,
      "avg_logprob": -0.2960578203201294,
      "compression_ratio": 1.5233160257339478,
      "end": 1134.4599609375,
      "no_speech_prob": 0.00022340990835800767,
      "seek": 111006,
      "start": 1128.5799560546875,
      "temperature": 0.0,
      "text": " Something as specific as Pokemon did amazingly when it comes to counting it did not do too",
      "tokens": [
        51290,
        6595,
        382,
        2685,
        382,
        13796,
        630,
        31762,
        562,
        309,
        1487,
        281,
        13251,
        309,
        630,
        406,
        360,
        886,
        51584
      ]
    },
    {
      "id": 217,
      "avg_logprob": -0.32451194524765015,
      "compression_ratio": 1.615384578704834,
      "end": 1141.93994140625,
      "no_speech_prob": 0.012819337658584118,
      "seek": 113446,
      "start": 1134.4599609375,
      "temperature": 0.0,
      "text": " Well for locations the 4o model did not do too. Well if there weren't any landmarks present in the photo",
      "tokens": [
        50364,
        1042,
        337,
        9253,
        264,
        1017,
        78,
        2316,
        630,
        406,
        360,
        886,
        13,
        1042,
        498,
        456,
        4999,
        380,
        604,
        26962,
        82,
        1974,
        294,
        264,
        5052,
        50738
      ]
    },
    {
      "id": 218,
      "avg_logprob": -0.32451194524765015,
      "compression_ratio": 1.615384578704834,
      "end": 1147.4599609375,
      "no_speech_prob": 0.012819337658584118,
      "seek": 113446,
      "start": 1142.3399658203125,
      "temperature": 0.0,
      "text": " but when I switched to the GPT 5 model, it was doing really well, even though the",
      "tokens": [
        50758,
        457,
        562,
        286,
        16858,
        281,
        264,
        26039,
        51,
        1025,
        2316,
        11,
        309,
        390,
        884,
        534,
        731,
        11,
        754,
        1673,
        264,
        51014
      ]
    },
    {
      "id": 219,
      "avg_logprob": -0.32451194524765015,
      "compression_ratio": 1.615384578704834,
      "end": 1149.97998046875,
      "no_speech_prob": 0.012819337658584118,
      "seek": 113446,
      "start": 1148.06005859375,
      "temperature": 0.0,
      "text": " even though the",
      "tokens": [
        51044,
        754,
        1673,
        264,
        51140
      ]
    },
    {
      "id": 220,
      "avg_logprob": -0.32451194524765015,
      "compression_ratio": 1.615384578704834,
      "end": 1153.1800537109375,
      "no_speech_prob": 0.012819337658584118,
      "seek": 113446,
      "start": 1149.97998046875,
      "temperature": 0.0,
      "text": " Response was a lot longer or it took a lot longer",
      "tokens": [
        51140,
        43937,
        390,
        257,
        688,
        2854,
        420,
        309,
        1890,
        257,
        688,
        2854,
        51300
      ]
    },
    {
      "id": 221,
      "avg_logprob": -0.32451194524765015,
      "compression_ratio": 1.615384578704834,
      "end": 1158.260009765625,
      "no_speech_prob": 0.012819337658584118,
      "seek": 113446,
      "start": 1154.3800048828125,
      "temperature": 0.0,
      "text": " So hopefully this was helpful. I will have both the github",
      "tokens": [
        51360,
        407,
        4696,
        341,
        390,
        4961,
        13,
        286,
        486,
        362,
        1293,
        264,
        290,
        355,
        836,
        51554
      ]
    },
    {
      "id": 222,
      "avg_logprob": -0.32451194524765015,
      "compression_ratio": 1.615384578704834,
      "end": 1163.6600341796875,
      "no_speech_prob": 0.012819337658584118,
      "seek": 113446,
      "start": 1158.9000244140625,
      "temperature": 0.0,
      "text": " github repo and a blog post linked in the description below if you want to check it out",
      "tokens": [
        51586,
        290,
        355,
        836,
        49040,
        293,
        257,
        6968,
        2183,
        9408,
        294,
        264,
        3855,
        2507,
        498,
        291,
        528,
        281,
        1520,
        309,
        484,
        51824
      ]
    },
    {
      "id": 223,
      "avg_logprob": -0.3059464693069458,
      "compression_ratio": 1.0,
      "end": 1167.4200439453125,
      "no_speech_prob": 0.0032988456077873707,
      "seek": 116446,
      "start": 1164.4599609375,
      "temperature": 0.0,
      "text": " And yeah, I'll catch y'all in the next one. Take care. Bye. Bye",
      "tokens": [
        50368,
        400,
        1338,
        11,
        286,
        603,
        3745,
        288,
        6,
        336,
        294,
        264,
        958,
        472,
        13,
        3664,
        1127,
        13,
        4621,
        13,
        4621,
        50512
      ]
    }
  ],
  "usage": {
    "seconds": 1168.0,
    "type": "duration"
  },
  "words": null,
  "task": "transcribe"
}