{
  "duration": 713.6599731445312,
  "language": "english",
  "text": "Hey guys, welcome back to the channel. Today, I'll show you how to build an AI pipeline to generate YouTube thumbnails. Here's an example of a thumbnail I generated right now for the video that you're watching, I'll divide the video into three parts. We're going to do a working demo at first, then we're going to look into a system design diagram, and finally a deep dive into the code. So if you take a look at the example we see here, this is the exact video you're watching right now, and you're going to see, we have a headline at the top, we have a subtitle and then three icons, and the way the script is passing these to OpenAI is something like this, where I am asking the user to input the video title, subtitle, background color, as well as the description of the three icons they want. In my case, it's going to be the three icons. We have the OpenAI icon, the YouTube icon, and then just a random thumbnail icon. So we pass in the title, subtitle, background color, as well as the descriptions for the icons, and then a summary for the video. Okay. Just by doing those, when you call the API, it takes a few minutes, but then it gives you the thumbnail you see here. A couple of other things to keep in mind when you're calling the API, you need to pass it the model, the prompt, which is a combination of everything that the user input, and then it takes in these two things, an image and the mask. Both of these are image files, and I'm going to talk about them in a little bit. You'd give it a background, output format, and size. When the, when the model returns the thumbnail, it gives you as a base64 encoded, the full file. So you want to decode it and then save it in a JPEG or PNG file. Okay. So let's quickly go to my terminal. So I am going to kick off a job to generate a new thumbnail, but it takes a couple of minutes. So we can only check at the end of the video, how good or bad of a job the model actually did. So let me run the file. I'm going to zoom in. Okay. So if I quickly run the file here, it asks me from a video title. So let's say, um, I don't know, maybe we'll do something similar, uh, AI thumbnails. And then the subtitle, let's say it's going to be GPT image one. And then let's say, uh, dolly two. Okay. Uh, there you go. And then the background color, let's do a black, uh, the description for icon one, let's say we, we want open AI's branded icon. Uh, the middle one, let's say we want a YouTube branded icon. And then the third one, let's say we want a penguin, uh, working on a laptop sitting near a beach. Okay. And then a brief summary of the video. So we're going to just say like AI pipeline, uh, to automatically generate YouTube thumbnails based on user context. Okay. So, uh, it is generating right now. So we're going to switch back to the other parts of the video, and then we're going to come back to see what the output images now, uh, if we go to the system design diagram here, you're going to see that to the model, we're going to pass a base image and this is going to be the image, uh, here. So this is my base image where I tell the model how my thumbnail should look like. So I'm passing it the title, subtitle, and then three placeholders. The next thing is the mask. And if you look at the mask image, this is another image file. It's almost the same format as the base image, but for the icons, I need to make them transparent and send them to the model so that they can actually fill in, uh, the three placeholders with the actual icon. So here's the mask image. Here's the base image, and we need to pass both of them to the, to the model. If you don't want to deal with the mask and base image, you can just tell the model to generate a thumbnail, but it's going to just randomly pick a format rather than confirming, rather than conforming to the, to the templates that you pass it. In my case, if you looked at my other videos, I usually use a very similar thumbnail format for all my videos. So this way I can make sure everything is consistent. Okay. So going back to the diagram, you have the base image, the mask image, a summary of the video that you just saw as input into the terminal, and then the mask fill in detail. So this is going to tell the model for each mask, how to exactly replace them. So in our case, we told it to replace the three icons with a penguin, uh, and two logos, one for OpenAI, one for YouTube. So once you have everything in, you just call the OpenAI model and the model generates the file in its response. But when you get the file back, you can set it to two different modes. In the first mode, the response is going to be a base 64 encoded image file that needs to be decoded. And in the second mode, you can, uh, you can ask it to give you a URL, right? So the model is going to generate the image, upload it somewhere in the cloud, and then give you the URL. In that case, when you get the URL back, you need to download it into your local device. And in our case, we're going to stick to the base 64 encoded image. And if I go into the code, you're going to see, we do it right here, where we take the response, we decode it, and then we save it to file. Okay. So that's how the design looks like. As a recap, we have base image, mask image, a summary of the video, and then a prompt with all the details that the model needs to fill in the mask. We pass everything to the model. The model generates the file either as a base 64 encoded file or upload it into the cloud with the URL. It returns back either the encoded file or the URL, and you can just download it to save it locally. Okay. So now let's move to the final part where we're going to look at the code. In the code, if I go from top to bottom, you're going to see, we have some of the API keys listed, and then we have the path to the template file and the mask, a mask file, right? Uh, both of these needs to be passed into the model. And you're going to see how we're doing that right here. Okay. Um, all right. So now this is where bulk of the logic is where we're opening both the files. So we're opening both the template file and the mask file. And then we're asking the user to input a bunch of details, going through them one by one. We want the user to give us the title, the subtitle. So if I move here, so we're essentially asking the user, give us the title here, give us the subtitle, and then the background colors, in my case it's always black, but if you want a different color, you can input that into the model as well. And then for the three icons, I'm going to ask them for a description. Okay. Finally, at the video summary to give a lot more context to the model. Once we gather all the information, we're just calling the images model with a prompt, the image file, the mask file, the background, output and size. Okay. For the model, uh, to, to do the workflow that I'm showing here, I think you can only do this with two models. One is the GPT, uh, image one. And the other is, um, I'm forgetting. I think it's a image 1.5 or one of the GPT 4.0 model or the DALI models. So you can look at the documentation, but after trying multiple times, I, I got the best result with GPT image one. For the prompt, uh, you can see it's a prompt where I sub in the values that the user, uh, input before. And so we have the title going in, the subtitle going in, the background color, the three icons, and then I think, do I pass the summary? Yeah, I'm passing the summary here. Okay. Whoops. The summary is here. Okay. So we get the result and then we do a base 64 decoding before writing it into a new file called youtube-thumbnail.jpg. So that's the full end-to-end system. We start with the template file. We go through the OpenAI API, and finally we save the file into our local hard drive. So that's everything I had for you today. We're going to quickly go and look at the program we kicked off in the background to, to end the video. So let me go back to terminal. You can see that we have generating thumbnail, generated, and then saving. And it saved the file in LLM images, YouTube thumbnail. So let's see what it came up with. Uh, here you go. So it came up with, uh, the same, uh, title, subtitle, and then the two logos. And finally, uh, the icon of a penguin. Now you're going to see that, uh, the outlines are white over here, which makes the image quite jarring to look at. What you can do is, and this is going to be in my next video. You're going to see when you receive, uh, when you receive an input or when you receive an image from the model, you can keep iterating on it by passing more and more prompts to the model. So let's say in this example, we got the image back, but we don't like the white outline or the white background here. So I can just do a follow-up to the model where we pass the image back and we tell it, Hey, uh, it looks pretty good, but we want it, we want you to remove the outline, maybe make the logo more colored and as you iterate two to three times, you're going to soon come to a form that you really like. So this is needed in the first few iterations. And the goal is as you're generating more and more thumbnails, you start understanding patterns and then you incorporate the fixes to the issues in your prompt, right? So if we go to your prompt here, I can just edit the prompt to say that for my three icons, make sure the icons are colorful, make sure that don't have an outline, um, and make sure that, uh, the, uh, the background for every icon is transparent. So something like this, not something like this, this is going to be a work in progress. The more you see the output, the better you can refine the prompt. And hopefully at some point you're going to reach a sweet balance between, uh, quality and the number of times you need to iterate. Okay. So that's everything I had for you today. Hopefully this was helpful. I will have both the diagram and the code linked in the description below, and you can also find both of them on my website if you're interested. Uh, that's it. I'll end it here. Thank you so much for watching. Talk to you all in the next one. Take care. Bye bye.",
  "segments": [
    {
      "id": 0,
      "avg_logprob": -0.3055996298789978,
      "compression_ratio": 1.6124999523162842,
      "end": 1.7000000476837158,
      "no_speech_prob": 0.0037597408518195152,
      "seek": 0,
      "start": 0.0,
      "temperature": 0.0,
      "text": " Hey guys, welcome back to the channel.",
      "tokens": [
        50364,
        1911,
        1074,
        11,
        2928,
        646,
        281,
        264,
        2269,
        13,
        50449
      ]
    },
    {
      "id": 1,
      "avg_logprob": -0.3055996298789978,
      "compression_ratio": 1.6124999523162842,
      "end": 7.599999904632568,
      "no_speech_prob": 0.0037597408518195152,
      "seek": 0,
      "start": 2.200000047683716,
      "temperature": 0.0,
      "text": " Today, I'll show you how to build an AI pipeline to generate YouTube thumbnails.",
      "tokens": [
        50474,
        2692,
        11,
        286,
        603,
        855,
        291,
        577,
        281,
        1322,
        364,
        7318,
        15517,
        281,
        8460,
        3088,
        46987,
        13,
        50744
      ]
    },
    {
      "id": 2,
      "avg_logprob": -0.3055996298789978,
      "compression_ratio": 1.6124999523162842,
      "end": 12.0600004196167,
      "no_speech_prob": 0.0037597408518195152,
      "seek": 0,
      "start": 8.279999732971191,
      "temperature": 0.0,
      "text": " Here's an example of a thumbnail I generated right now for the",
      "tokens": [
        50778,
        1692,
        311,
        364,
        1365,
        295,
        257,
        26746,
        286,
        10833,
        558,
        586,
        337,
        264,
        50967
      ]
    },
    {
      "id": 3,
      "avg_logprob": -0.3055996298789978,
      "compression_ratio": 1.6124999523162842,
      "end": 16.420000076293945,
      "no_speech_prob": 0.0037597408518195152,
      "seek": 0,
      "start": 12.0600004196167,
      "temperature": 0.0,
      "text": " video that you're watching, I'll divide the video into three parts.",
      "tokens": [
        50967,
        960,
        300,
        291,
        434,
        1976,
        11,
        286,
        603,
        9845,
        264,
        960,
        666,
        1045,
        3166,
        13,
        51185
      ]
    },
    {
      "id": 4,
      "avg_logprob": -0.3055996298789978,
      "compression_ratio": 1.6124999523162842,
      "end": 20.739999771118164,
      "no_speech_prob": 0.0037597408518195152,
      "seek": 0,
      "start": 16.780000686645508,
      "temperature": 0.0,
      "text": " We're going to do a working demo at first, then we're going to look",
      "tokens": [
        51203,
        492,
        434,
        516,
        281,
        360,
        257,
        1364,
        10723,
        412,
        700,
        11,
        550,
        321,
        434,
        516,
        281,
        574,
        51401
      ]
    },
    {
      "id": 5,
      "avg_logprob": -0.3055996298789978,
      "compression_ratio": 1.6124999523162842,
      "end": 25.079999923706055,
      "no_speech_prob": 0.0037597408518195152,
      "seek": 0,
      "start": 20.739999771118164,
      "temperature": 0.0,
      "text": " into a system design diagram, and finally a deep dive into the code.",
      "tokens": [
        51401,
        666,
        257,
        1185,
        1715,
        10686,
        11,
        293,
        2721,
        257,
        2452,
        9192,
        666,
        264,
        3089,
        13,
        51618
      ]
    },
    {
      "id": 6,
      "avg_logprob": -0.24093982577323914,
      "compression_ratio": 1.73305082321167,
      "end": 30.360000610351562,
      "no_speech_prob": 0.005057206843048334,
      "seek": 2508,
      "start": 26.079999923706055,
      "temperature": 0.0,
      "text": " So if you take a look at the example we see here, this is the exact video",
      "tokens": [
        50414,
        407,
        498,
        291,
        747,
        257,
        574,
        412,
        264,
        1365,
        321,
        536,
        510,
        11,
        341,
        307,
        264,
        1900,
        960,
        50628
      ]
    },
    {
      "id": 7,
      "avg_logprob": -0.24093982577323914,
      "compression_ratio": 1.73305082321167,
      "end": 34.15999984741211,
      "no_speech_prob": 0.005057206843048334,
      "seek": 2508,
      "start": 30.360000610351562,
      "temperature": 0.0,
      "text": " you're watching right now, and you're going to see, we have a headline at the",
      "tokens": [
        50628,
        291,
        434,
        1976,
        558,
        586,
        11,
        293,
        291,
        434,
        516,
        281,
        536,
        11,
        321,
        362,
        257,
        28380,
        412,
        264,
        50818
      ]
    },
    {
      "id": 8,
      "avg_logprob": -0.24093982577323914,
      "compression_ratio": 1.73305082321167,
      "end": 39.959999084472656,
      "no_speech_prob": 0.005057206843048334,
      "seek": 2508,
      "start": 34.15999984741211,
      "temperature": 0.0,
      "text": " top, we have a subtitle and then three icons, and the way the script is",
      "tokens": [
        50818,
        1192,
        11,
        321,
        362,
        257,
        30706,
        306,
        293,
        550,
        1045,
        23308,
        11,
        293,
        264,
        636,
        264,
        5755,
        307,
        51108
      ]
    },
    {
      "id": 9,
      "avg_logprob": -0.24093982577323914,
      "compression_ratio": 1.73305082321167,
      "end": 46.400001525878906,
      "no_speech_prob": 0.005057206843048334,
      "seek": 2508,
      "start": 39.959999084472656,
      "temperature": 0.0,
      "text": " passing these to OpenAI is something like this, where I am asking the user",
      "tokens": [
        51108,
        8437,
        613,
        281,
        7238,
        48698,
        307,
        746,
        411,
        341,
        11,
        689,
        286,
        669,
        3365,
        264,
        4195,
        51430
      ]
    },
    {
      "id": 10,
      "avg_logprob": -0.24093982577323914,
      "compression_ratio": 1.73305082321167,
      "end": 52.599998474121094,
      "no_speech_prob": 0.005057206843048334,
      "seek": 2508,
      "start": 46.439998626708984,
      "temperature": 0.0,
      "text": " to input the video title, subtitle, background color, as well as the",
      "tokens": [
        51432,
        281,
        4846,
        264,
        960,
        4876,
        11,
        30706,
        306,
        11,
        3678,
        2017,
        11,
        382,
        731,
        382,
        264,
        51740
      ]
    },
    {
      "id": 11,
      "avg_logprob": -0.24093982577323914,
      "compression_ratio": 1.73305082321167,
      "end": 55.02000045776367,
      "no_speech_prob": 0.005057206843048334,
      "seek": 2508,
      "start": 52.599998474121094,
      "temperature": 0.0,
      "text": " description of the three icons they want.",
      "tokens": [
        51740,
        3855,
        295,
        264,
        1045,
        23308,
        436,
        528,
        13,
        51861
      ]
    },
    {
      "id": 12,
      "avg_logprob": -0.25132954120635986,
      "compression_ratio": 1.6075949668884277,
      "end": 57.91999816894531,
      "no_speech_prob": 7.141353853512555e-05,
      "seek": 5508,
      "start": 55.560001373291016,
      "temperature": 0.0,
      "text": " In my case, it's going to be the three icons.",
      "tokens": [
        50388,
        682,
        452,
        1389,
        11,
        309,
        311,
        516,
        281,
        312,
        264,
        1045,
        23308,
        13,
        50506
      ]
    },
    {
      "id": 13,
      "avg_logprob": -0.25132954120635986,
      "compression_ratio": 1.6075949668884277,
      "end": 63.2400016784668,
      "no_speech_prob": 7.141353853512555e-05,
      "seek": 5508,
      "start": 57.91999816894531,
      "temperature": 0.0,
      "text": " We have the OpenAI icon, the YouTube icon, and then just a random thumbnail icon.",
      "tokens": [
        50506,
        492,
        362,
        264,
        7238,
        48698,
        6528,
        11,
        264,
        3088,
        6528,
        11,
        293,
        550,
        445,
        257,
        4974,
        26746,
        6528,
        13,
        50772
      ]
    },
    {
      "id": 14,
      "avg_logprob": -0.25132954120635986,
      "compression_ratio": 1.6075949668884277,
      "end": 69.66000366210938,
      "no_speech_prob": 7.141353853512555e-05,
      "seek": 5508,
      "start": 65.0,
      "temperature": 0.0,
      "text": " So we pass in the title, subtitle, background color, as well as the",
      "tokens": [
        50860,
        407,
        321,
        1320,
        294,
        264,
        4876,
        11,
        30706,
        306,
        11,
        3678,
        2017,
        11,
        382,
        731,
        382,
        264,
        51093
      ]
    },
    {
      "id": 15,
      "avg_logprob": -0.25132954120635986,
      "compression_ratio": 1.6075949668884277,
      "end": 72.76000213623047,
      "no_speech_prob": 7.141353853512555e-05,
      "seek": 5508,
      "start": 69.66000366210938,
      "temperature": 0.0,
      "text": " descriptions for the icons, and then a summary for the video.",
      "tokens": [
        51093,
        24406,
        337,
        264,
        23308,
        11,
        293,
        550,
        257,
        12691,
        337,
        264,
        960,
        13,
        51248
      ]
    },
    {
      "id": 16,
      "avg_logprob": -0.25132954120635986,
      "compression_ratio": 1.6075949668884277,
      "end": 73.86000061035156,
      "no_speech_prob": 7.141353853512555e-05,
      "seek": 5508,
      "start": 73.36000061035156,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        51278,
        1033,
        13,
        51303
      ]
    },
    {
      "id": 17,
      "avg_logprob": -0.25132954120635986,
      "compression_ratio": 1.6075949668884277,
      "end": 79.54000091552734,
      "no_speech_prob": 7.141353853512555e-05,
      "seek": 5508,
      "start": 74.08000183105469,
      "temperature": 0.0,
      "text": " Just by doing those, when you call the API, it takes a few minutes, but then",
      "tokens": [
        51314,
        1449,
        538,
        884,
        729,
        11,
        562,
        291,
        818,
        264,
        9362,
        11,
        309,
        2516,
        257,
        1326,
        2077,
        11,
        457,
        550,
        51587
      ]
    },
    {
      "id": 18,
      "avg_logprob": -0.25132954120635986,
      "compression_ratio": 1.6075949668884277,
      "end": 81.95999908447266,
      "no_speech_prob": 7.141353853512555e-05,
      "seek": 5508,
      "start": 79.54000091552734,
      "temperature": 0.0,
      "text": " it gives you the thumbnail you see here.",
      "tokens": [
        51587,
        309,
        2709,
        291,
        264,
        26746,
        291,
        536,
        510,
        13,
        51708
      ]
    },
    {
      "id": 19,
      "avg_logprob": -0.2941417396068573,
      "compression_ratio": 1.6441947221755981,
      "end": 87.12000274658203,
      "no_speech_prob": 0.00015117967268452048,
      "seek": 8196,
      "start": 82.95999908447266,
      "temperature": 0.0,
      "text": " A couple of other things to keep in mind when you're calling the API, you",
      "tokens": [
        50414,
        316,
        1916,
        295,
        661,
        721,
        281,
        1066,
        294,
        1575,
        562,
        291,
        434,
        5141,
        264,
        9362,
        11,
        291,
        50622
      ]
    },
    {
      "id": 20,
      "avg_logprob": -0.2941417396068573,
      "compression_ratio": 1.6441947221755981,
      "end": 91.44000244140625,
      "no_speech_prob": 0.00015117967268452048,
      "seek": 8196,
      "start": 87.12000274658203,
      "temperature": 0.0,
      "text": " need to pass it the model, the prompt, which is a combination of everything",
      "tokens": [
        50622,
        643,
        281,
        1320,
        309,
        264,
        2316,
        11,
        264,
        12391,
        11,
        597,
        307,
        257,
        6562,
        295,
        1203,
        50838
      ]
    },
    {
      "id": 21,
      "avg_logprob": -0.2941417396068573,
      "compression_ratio": 1.6441947221755981,
      "end": 97.27999877929688,
      "no_speech_prob": 0.00015117967268452048,
      "seek": 8196,
      "start": 91.44000244140625,
      "temperature": 0.0,
      "text": " that the user input, and then it takes in these two things, an image and the mask.",
      "tokens": [
        50838,
        300,
        264,
        4195,
        4846,
        11,
        293,
        550,
        309,
        2516,
        294,
        613,
        732,
        721,
        11,
        364,
        3256,
        293,
        264,
        6094,
        13,
        51130
      ]
    },
    {
      "id": 22,
      "avg_logprob": -0.2941417396068573,
      "compression_ratio": 1.6441947221755981,
      "end": 100.4000015258789,
      "no_speech_prob": 0.00015117967268452048,
      "seek": 8196,
      "start": 97.36000061035156,
      "temperature": 0.0,
      "text": " Both of these are image files, and I'm going to talk about them in a little bit.",
      "tokens": [
        51134,
        6767,
        295,
        613,
        366,
        3256,
        7098,
        11,
        293,
        286,
        478,
        516,
        281,
        751,
        466,
        552,
        294,
        257,
        707,
        857,
        13,
        51286
      ]
    },
    {
      "id": 23,
      "avg_logprob": -0.2941417396068573,
      "compression_ratio": 1.6441947221755981,
      "end": 104.08000183105469,
      "no_speech_prob": 0.00015117967268452048,
      "seek": 8196,
      "start": 101.23999786376953,
      "temperature": 0.0,
      "text": " You'd give it a background, output format, and size.",
      "tokens": [
        51328,
        509,
        1116,
        976,
        309,
        257,
        3678,
        11,
        5598,
        7877,
        11,
        293,
        2744,
        13,
        51470
      ]
    },
    {
      "id": 24,
      "avg_logprob": -0.2941417396068573,
      "compression_ratio": 1.6441947221755981,
      "end": 111.16000366210938,
      "no_speech_prob": 0.00015117967268452048,
      "seek": 8196,
      "start": 104.63999938964844,
      "temperature": 0.0,
      "text": " When the, when the model returns the thumbnail, it gives you as a base64",
      "tokens": [
        51498,
        1133,
        264,
        11,
        562,
        264,
        2316,
        11247,
        264,
        26746,
        11,
        309,
        2709,
        291,
        382,
        257,
        3096,
        19395,
        51824
      ]
    },
    {
      "id": 25,
      "avg_logprob": -0.2340184897184372,
      "compression_ratio": 1.5829787254333496,
      "end": 113.19999694824219,
      "no_speech_prob": 0.00020027175196446478,
      "seek": 11116,
      "start": 111.19999694824219,
      "temperature": 0.0,
      "text": " encoded, the full file.",
      "tokens": [
        50366,
        2058,
        12340,
        11,
        264,
        1577,
        3991,
        13,
        50466
      ]
    },
    {
      "id": 26,
      "avg_logprob": -0.2340184897184372,
      "compression_ratio": 1.5829787254333496,
      "end": 117.31999969482422,
      "no_speech_prob": 0.00020027175196446478,
      "seek": 11116,
      "start": 113.4800033569336,
      "temperature": 0.0,
      "text": " So you want to decode it and then save it in a JPEG or PNG file.",
      "tokens": [
        50480,
        407,
        291,
        528,
        281,
        979,
        1429,
        309,
        293,
        550,
        3155,
        309,
        294,
        257,
        508,
        5208,
        38,
        420,
        430,
        30237,
        3991,
        13,
        50672
      ]
    },
    {
      "id": 27,
      "avg_logprob": -0.2340184897184372,
      "compression_ratio": 1.5829787254333496,
      "end": 119.0999984741211,
      "no_speech_prob": 0.00020027175196446478,
      "seek": 11116,
      "start": 118.5999984741211,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        50736,
        1033,
        13,
        50761
      ]
    },
    {
      "id": 28,
      "avg_logprob": -0.2340184897184372,
      "compression_ratio": 1.5829787254333496,
      "end": 122.27999877929688,
      "no_speech_prob": 0.00020027175196446478,
      "seek": 11116,
      "start": 119.16000366210938,
      "temperature": 0.0,
      "text": " So let's quickly go to my terminal.",
      "tokens": [
        50764,
        407,
        718,
        311,
        2661,
        352,
        281,
        452,
        14709,
        13,
        50920
      ]
    },
    {
      "id": 29,
      "avg_logprob": -0.2340184897184372,
      "compression_ratio": 1.5829787254333496,
      "end": 127.5999984741211,
      "no_speech_prob": 0.00020027175196446478,
      "seek": 11116,
      "start": 122.72000122070312,
      "temperature": 0.0,
      "text": " So I am going to kick off a job to generate a new thumbnail, but",
      "tokens": [
        50942,
        407,
        286,
        669,
        516,
        281,
        4437,
        766,
        257,
        1691,
        281,
        8460,
        257,
        777,
        26746,
        11,
        457,
        51186
      ]
    },
    {
      "id": 30,
      "avg_logprob": -0.2340184897184372,
      "compression_ratio": 1.5829787254333496,
      "end": 129.16000366210938,
      "no_speech_prob": 0.00020027175196446478,
      "seek": 11116,
      "start": 127.5999984741211,
      "temperature": 0.0,
      "text": " it takes a couple of minutes.",
      "tokens": [
        51186,
        309,
        2516,
        257,
        1916,
        295,
        2077,
        13,
        51264
      ]
    },
    {
      "id": 31,
      "avg_logprob": -0.2340184897184372,
      "compression_ratio": 1.5829787254333496,
      "end": 133.83999633789062,
      "no_speech_prob": 0.00020027175196446478,
      "seek": 11116,
      "start": 129.16000366210938,
      "temperature": 0.0,
      "text": " So we can only check at the end of the video, how good or bad",
      "tokens": [
        51264,
        407,
        321,
        393,
        787,
        1520,
        412,
        264,
        917,
        295,
        264,
        960,
        11,
        577,
        665,
        420,
        1578,
        51498
      ]
    },
    {
      "id": 32,
      "avg_logprob": -0.2340184897184372,
      "compression_ratio": 1.5829787254333496,
      "end": 135.8000030517578,
      "no_speech_prob": 0.00020027175196446478,
      "seek": 11116,
      "start": 133.83999633789062,
      "temperature": 0.0,
      "text": " of a job the model actually did.",
      "tokens": [
        51498,
        295,
        257,
        1691,
        264,
        2316,
        767,
        630,
        13,
        51596
      ]
    },
    {
      "id": 33,
      "avg_logprob": -0.2340184897184372,
      "compression_ratio": 1.5829787254333496,
      "end": 137.1199951171875,
      "no_speech_prob": 0.00020027175196446478,
      "seek": 11116,
      "start": 136.0399932861328,
      "temperature": 0.0,
      "text": " So let me run the file.",
      "tokens": [
        51608,
        407,
        718,
        385,
        1190,
        264,
        3991,
        13,
        51662
      ]
    },
    {
      "id": 34,
      "avg_logprob": -0.2340184897184372,
      "compression_ratio": 1.5829787254333496,
      "end": 138.1199951171875,
      "no_speech_prob": 0.00020027175196446478,
      "seek": 11116,
      "start": 137.24000549316406,
      "temperature": 0.0,
      "text": " I'm going to zoom in.",
      "tokens": [
        51668,
        286,
        478,
        516,
        281,
        8863,
        294,
        13,
        51712
      ]
    },
    {
      "id": 35,
      "avg_logprob": -0.2340184897184372,
      "compression_ratio": 1.5829787254333496,
      "end": 139.5399932861328,
      "no_speech_prob": 0.00020027175196446478,
      "seek": 11116,
      "start": 139.0399932861328,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        51758,
        1033,
        13,
        51783
      ]
    },
    {
      "id": 36,
      "avg_logprob": -0.2657776176929474,
      "compression_ratio": 1.5662100315093994,
      "end": 145.5399932861328,
      "no_speech_prob": 0.0006985930376686156,
      "seek": 13954,
      "start": 140.17999267578125,
      "temperature": 0.0,
      "text": " So if I quickly run the file here, it asks me from a video title.",
      "tokens": [
        50396,
        407,
        498,
        286,
        2661,
        1190,
        264,
        3991,
        510,
        11,
        309,
        8962,
        385,
        490,
        257,
        960,
        4876,
        13,
        50664
      ]
    },
    {
      "id": 37,
      "avg_logprob": -0.2657776176929474,
      "compression_ratio": 1.5662100315093994,
      "end": 151.3000030517578,
      "no_speech_prob": 0.0006985930376686156,
      "seek": 13954,
      "start": 145.5399932861328,
      "temperature": 0.0,
      "text": " So let's say, um, I don't know, maybe we'll do something similar, uh, AI thumbnails.",
      "tokens": [
        50664,
        407,
        718,
        311,
        584,
        11,
        1105,
        11,
        286,
        500,
        380,
        458,
        11,
        1310,
        321,
        603,
        360,
        746,
        2531,
        11,
        2232,
        11,
        7318,
        46987,
        13,
        50952
      ]
    },
    {
      "id": 38,
      "avg_logprob": -0.2657776176929474,
      "compression_ratio": 1.5662100315093994,
      "end": 157.3800048828125,
      "no_speech_prob": 0.0006985930376686156,
      "seek": 13954,
      "start": 152.5800018310547,
      "temperature": 0.0,
      "text": " And then the subtitle, let's say it's going to be GPT image one.",
      "tokens": [
        51016,
        400,
        550,
        264,
        30706,
        306,
        11,
        718,
        311,
        584,
        309,
        311,
        516,
        281,
        312,
        26039,
        51,
        3256,
        472,
        13,
        51256
      ]
    },
    {
      "id": 39,
      "avg_logprob": -0.2657776176929474,
      "compression_ratio": 1.5662100315093994,
      "end": 161.77999877929688,
      "no_speech_prob": 0.0006985930376686156,
      "seek": 13954,
      "start": 158.25999450683594,
      "temperature": 0.0,
      "text": " And then let's say, uh, dolly two.",
      "tokens": [
        51300,
        400,
        550,
        718,
        311,
        584,
        11,
        2232,
        11,
        2722,
        88,
        732,
        13,
        51476
      ]
    },
    {
      "id": 40,
      "avg_logprob": -0.2657776176929474,
      "compression_ratio": 1.5662100315093994,
      "end": 163.1199951171875,
      "no_speech_prob": 0.0006985930376686156,
      "seek": 13954,
      "start": 162.6199951171875,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        51518,
        1033,
        13,
        51543
      ]
    },
    {
      "id": 41,
      "avg_logprob": -0.2657776176929474,
      "compression_ratio": 1.5662100315093994,
      "end": 165.13999938964844,
      "no_speech_prob": 0.0006985930376686156,
      "seek": 13954,
      "start": 164.4199981689453,
      "temperature": 0.0,
      "text": " Uh, there you go.",
      "tokens": [
        51608,
        4019,
        11,
        456,
        291,
        352,
        13,
        51644
      ]
    },
    {
      "id": 42,
      "avg_logprob": -0.2657776176929474,
      "compression_ratio": 1.5662100315093994,
      "end": 168.74000549316406,
      "no_speech_prob": 0.0006985930376686156,
      "seek": 13954,
      "start": 165.6199951171875,
      "temperature": 0.0,
      "text": " And then the background color, let's do a black, uh, the description",
      "tokens": [
        51668,
        400,
        550,
        264,
        3678,
        2017,
        11,
        718,
        311,
        360,
        257,
        2211,
        11,
        2232,
        11,
        264,
        3855,
        51824
      ]
    },
    {
      "id": 43,
      "avg_logprob": -0.23875197768211365,
      "compression_ratio": 1.65625,
      "end": 174.02000427246094,
      "no_speech_prob": 0.0019265918526798487,
      "seek": 16874,
      "start": 168.74000549316406,
      "temperature": 0.0,
      "text": " for icon one, let's say we, we want open AI's branded icon.",
      "tokens": [
        50364,
        337,
        6528,
        472,
        11,
        718,
        311,
        584,
        321,
        11,
        321,
        528,
        1269,
        7318,
        311,
        38510,
        6528,
        13,
        50628
      ]
    },
    {
      "id": 44,
      "avg_logprob": -0.23875197768211365,
      "compression_ratio": 1.65625,
      "end": 179.3000030517578,
      "no_speech_prob": 0.0019265918526798487,
      "seek": 16874,
      "start": 174.6999969482422,
      "temperature": 0.0,
      "text": " Uh, the middle one, let's say we want a YouTube branded icon.",
      "tokens": [
        50662,
        4019,
        11,
        264,
        2808,
        472,
        11,
        718,
        311,
        584,
        321,
        528,
        257,
        3088,
        38510,
        6528,
        13,
        50892
      ]
    },
    {
      "id": 45,
      "avg_logprob": -0.23875197768211365,
      "compression_ratio": 1.65625,
      "end": 185.05999755859375,
      "no_speech_prob": 0.0019265918526798487,
      "seek": 16874,
      "start": 179.86000061035156,
      "temperature": 0.0,
      "text": " And then the third one, let's say we want a penguin, uh, working",
      "tokens": [
        50920,
        400,
        550,
        264,
        2636,
        472,
        11,
        718,
        311,
        584,
        321,
        528,
        257,
        45752,
        11,
        2232,
        11,
        1364,
        51180
      ]
    },
    {
      "id": 46,
      "avg_logprob": -0.23875197768211365,
      "compression_ratio": 1.65625,
      "end": 188.82000732421875,
      "no_speech_prob": 0.0019265918526798487,
      "seek": 16874,
      "start": 185.17999267578125,
      "temperature": 0.0,
      "text": " on a laptop sitting near a beach.",
      "tokens": [
        51186,
        322,
        257,
        10732,
        3798,
        2651,
        257,
        7534,
        13,
        51368
      ]
    },
    {
      "id": 47,
      "avg_logprob": -0.23875197768211365,
      "compression_ratio": 1.65625,
      "end": 190.67999267578125,
      "no_speech_prob": 0.0019265918526798487,
      "seek": 16874,
      "start": 190.17999267578125,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        51436,
        1033,
        13,
        51461
      ]
    },
    {
      "id": 48,
      "avg_logprob": -0.23875197768211365,
      "compression_ratio": 1.65625,
      "end": 193.02000427246094,
      "no_speech_prob": 0.0019265918526798487,
      "seek": 16874,
      "start": 190.97999572753906,
      "temperature": 0.0,
      "text": " And then a brief summary of the video.",
      "tokens": [
        51476,
        400,
        550,
        257,
        5353,
        12691,
        295,
        264,
        960,
        13,
        51578
      ]
    },
    {
      "id": 49,
      "avg_logprob": -0.22033977508544922,
      "compression_ratio": 1.694690227508545,
      "end": 197.89999389648438,
      "no_speech_prob": 0.02555611915886402,
      "seek": 19302,
      "start": 193.02000427246094,
      "temperature": 0.0,
      "text": " So we're going to just say like AI pipeline, uh, to automatically",
      "tokens": [
        50364,
        407,
        321,
        434,
        516,
        281,
        445,
        584,
        411,
        7318,
        15517,
        11,
        2232,
        11,
        281,
        6772,
        50608
      ]
    },
    {
      "id": 50,
      "avg_logprob": -0.22033977508544922,
      "compression_ratio": 1.694690227508545,
      "end": 203.5399932861328,
      "no_speech_prob": 0.02555611915886402,
      "seek": 19302,
      "start": 198.13999938964844,
      "temperature": 0.0,
      "text": " generate YouTube thumbnails based on user context.",
      "tokens": [
        50620,
        8460,
        3088,
        46987,
        2361,
        322,
        4195,
        4319,
        13,
        50890
      ]
    },
    {
      "id": 51,
      "avg_logprob": -0.22033977508544922,
      "compression_ratio": 1.694690227508545,
      "end": 205.1199951171875,
      "no_speech_prob": 0.02555611915886402,
      "seek": 19302,
      "start": 204.6199951171875,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        50944,
        1033,
        13,
        50969
      ]
    },
    {
      "id": 52,
      "avg_logprob": -0.22033977508544922,
      "compression_ratio": 1.694690227508545,
      "end": 207.6199951171875,
      "no_speech_prob": 0.02555611915886402,
      "seek": 19302,
      "start": 205.33999633789062,
      "temperature": 0.0,
      "text": " So, uh, it is generating right now.",
      "tokens": [
        50980,
        407,
        11,
        2232,
        11,
        309,
        307,
        17746,
        558,
        586,
        13,
        51094
      ]
    },
    {
      "id": 53,
      "avg_logprob": -0.22033977508544922,
      "compression_ratio": 1.694690227508545,
      "end": 210.22000122070312,
      "no_speech_prob": 0.02555611915886402,
      "seek": 19302,
      "start": 207.6199951171875,
      "temperature": 0.0,
      "text": " So we're going to switch back to the other parts of the video, and then",
      "tokens": [
        51094,
        407,
        321,
        434,
        516,
        281,
        3679,
        646,
        281,
        264,
        661,
        3166,
        295,
        264,
        960,
        11,
        293,
        550,
        51224
      ]
    },
    {
      "id": 54,
      "avg_logprob": -0.22033977508544922,
      "compression_ratio": 1.694690227508545,
      "end": 216.4600067138672,
      "no_speech_prob": 0.02555611915886402,
      "seek": 19302,
      "start": 210.22000122070312,
      "temperature": 0.0,
      "text": " we're going to come back to see what the output images now, uh, if we go to",
      "tokens": [
        51224,
        321,
        434,
        516,
        281,
        808,
        646,
        281,
        536,
        437,
        264,
        5598,
        5267,
        586,
        11,
        2232,
        11,
        498,
        321,
        352,
        281,
        51536
      ]
    },
    {
      "id": 55,
      "avg_logprob": -0.22033977508544922,
      "compression_ratio": 1.694690227508545,
      "end": 220.3000030517578,
      "no_speech_prob": 0.02555611915886402,
      "seek": 19302,
      "start": 216.4600067138672,
      "temperature": 0.0,
      "text": " the system design diagram here, you're going to see that to the model, we're",
      "tokens": [
        51536,
        264,
        1185,
        1715,
        10686,
        510,
        11,
        291,
        434,
        516,
        281,
        536,
        300,
        281,
        264,
        2316,
        11,
        321,
        434,
        51728
      ]
    },
    {
      "id": 56,
      "avg_logprob": -0.22426152229309082,
      "compression_ratio": 1.784403681755066,
      "end": 226.74000549316406,
      "no_speech_prob": 0.00136694370303303,
      "seek": 22030,
      "start": 220.3000030517578,
      "temperature": 0.0,
      "text": " going to pass a base image and this is going to be the image, uh, here.",
      "tokens": [
        50364,
        516,
        281,
        1320,
        257,
        3096,
        3256,
        293,
        341,
        307,
        516,
        281,
        312,
        264,
        3256,
        11,
        2232,
        11,
        510,
        13,
        50686
      ]
    },
    {
      "id": 57,
      "avg_logprob": -0.22426152229309082,
      "compression_ratio": 1.784403681755066,
      "end": 232.89999389648438,
      "no_speech_prob": 0.00136694370303303,
      "seek": 22030,
      "start": 227.5,
      "temperature": 0.0,
      "text": " So this is my base image where I tell the model how my thumbnail should look like.",
      "tokens": [
        50724,
        407,
        341,
        307,
        452,
        3096,
        3256,
        689,
        286,
        980,
        264,
        2316,
        577,
        452,
        26746,
        820,
        574,
        411,
        13,
        50994
      ]
    },
    {
      "id": 58,
      "avg_logprob": -0.22426152229309082,
      "compression_ratio": 1.784403681755066,
      "end": 237.05999755859375,
      "no_speech_prob": 0.00136694370303303,
      "seek": 22030,
      "start": 233.22000122070312,
      "temperature": 0.0,
      "text": " So I'm passing it the title, subtitle, and then three placeholders.",
      "tokens": [
        51010,
        407,
        286,
        478,
        8437,
        309,
        264,
        4876,
        11,
        30706,
        306,
        11,
        293,
        550,
        1045,
        1081,
        12916,
        13,
        51202
      ]
    },
    {
      "id": 59,
      "avg_logprob": -0.22426152229309082,
      "compression_ratio": 1.784403681755066,
      "end": 239.82000732421875,
      "no_speech_prob": 0.00136694370303303,
      "seek": 22030,
      "start": 238.5399932861328,
      "temperature": 0.0,
      "text": " The next thing is the mask.",
      "tokens": [
        51276,
        440,
        958,
        551,
        307,
        264,
        6094,
        13,
        51340
      ]
    },
    {
      "id": 60,
      "avg_logprob": -0.22426152229309082,
      "compression_ratio": 1.784403681755066,
      "end": 242.97999572753906,
      "no_speech_prob": 0.00136694370303303,
      "seek": 22030,
      "start": 240.02000427246094,
      "temperature": 0.0,
      "text": " And if you look at the mask image, this is another image file.",
      "tokens": [
        51350,
        400,
        498,
        291,
        574,
        412,
        264,
        6094,
        3256,
        11,
        341,
        307,
        1071,
        3256,
        3991,
        13,
        51498
      ]
    },
    {
      "id": 61,
      "avg_logprob": -0.22426152229309082,
      "compression_ratio": 1.784403681755066,
      "end": 247.86000061035156,
      "no_speech_prob": 0.00136694370303303,
      "seek": 22030,
      "start": 243.22000122070312,
      "temperature": 0.0,
      "text": " It's almost the same format as the base image, but for the icons, I need to",
      "tokens": [
        51510,
        467,
        311,
        1920,
        264,
        912,
        7877,
        382,
        264,
        3096,
        3256,
        11,
        457,
        337,
        264,
        23308,
        11,
        286,
        643,
        281,
        51742
      ]
    },
    {
      "id": 62,
      "avg_logprob": -0.2269318401813507,
      "compression_ratio": 1.864341139793396,
      "end": 252.4199981689453,
      "no_speech_prob": 0.0013458363246172667,
      "seek": 24786,
      "start": 247.86000061035156,
      "temperature": 0.0,
      "text": " make them transparent and send them to the model so that they can actually fill",
      "tokens": [
        50364,
        652,
        552,
        12737,
        293,
        2845,
        552,
        281,
        264,
        2316,
        370,
        300,
        436,
        393,
        767,
        2836,
        50592
      ]
    },
    {
      "id": 63,
      "avg_logprob": -0.2269318401813507,
      "compression_ratio": 1.864341139793396,
      "end": 256.0199890136719,
      "no_speech_prob": 0.0013458363246172667,
      "seek": 24786,
      "start": 252.4199981689453,
      "temperature": 0.0,
      "text": " in, uh, the three placeholders with the actual icon.",
      "tokens": [
        50592,
        294,
        11,
        2232,
        11,
        264,
        1045,
        1081,
        12916,
        365,
        264,
        3539,
        6528,
        13,
        50772
      ]
    },
    {
      "id": 64,
      "avg_logprob": -0.2269318401813507,
      "compression_ratio": 1.864341139793396,
      "end": 257.6600036621094,
      "no_speech_prob": 0.0013458363246172667,
      "seek": 24786,
      "start": 256.3399963378906,
      "temperature": 0.0,
      "text": " So here's the mask image.",
      "tokens": [
        50788,
        407,
        510,
        311,
        264,
        6094,
        3256,
        13,
        50854
      ]
    },
    {
      "id": 65,
      "avg_logprob": -0.2269318401813507,
      "compression_ratio": 1.864341139793396,
      "end": 262.17999267578125,
      "no_speech_prob": 0.0013458363246172667,
      "seek": 24786,
      "start": 258.17999267578125,
      "temperature": 0.0,
      "text": " Here's the base image, and we need to pass both of them to the, to the model.",
      "tokens": [
        50880,
        1692,
        311,
        264,
        3096,
        3256,
        11,
        293,
        321,
        643,
        281,
        1320,
        1293,
        295,
        552,
        281,
        264,
        11,
        281,
        264,
        2316,
        13,
        51080
      ]
    },
    {
      "id": 66,
      "avg_logprob": -0.2269318401813507,
      "compression_ratio": 1.864341139793396,
      "end": 266.5400085449219,
      "no_speech_prob": 0.0013458363246172667,
      "seek": 24786,
      "start": 262.70001220703125,
      "temperature": 0.0,
      "text": " If you don't want to deal with the mask and base image, you can just tell the",
      "tokens": [
        51106,
        759,
        291,
        500,
        380,
        528,
        281,
        2028,
        365,
        264,
        6094,
        293,
        3096,
        3256,
        11,
        291,
        393,
        445,
        980,
        264,
        51298
      ]
    },
    {
      "id": 67,
      "avg_logprob": -0.2269318401813507,
      "compression_ratio": 1.864341139793396,
      "end": 271.8999938964844,
      "no_speech_prob": 0.0013458363246172667,
      "seek": 24786,
      "start": 266.5400085449219,
      "temperature": 0.0,
      "text": " model to generate a thumbnail, but it's going to just randomly pick a format",
      "tokens": [
        51298,
        2316,
        281,
        8460,
        257,
        26746,
        11,
        457,
        309,
        311,
        516,
        281,
        445,
        16979,
        1888,
        257,
        7877,
        51566
      ]
    },
    {
      "id": 68,
      "avg_logprob": -0.2269318401813507,
      "compression_ratio": 1.864341139793396,
      "end": 276.7799987792969,
      "no_speech_prob": 0.0013458363246172667,
      "seek": 24786,
      "start": 271.94000244140625,
      "temperature": 0.0,
      "text": " rather than confirming, rather than conforming to the, to the templates",
      "tokens": [
        51568,
        2831,
        813,
        42861,
        11,
        2831,
        813,
        18975,
        278,
        281,
        264,
        11,
        281,
        264,
        21165,
        51810
      ]
    },
    {
      "id": 69,
      "avg_logprob": -0.2269318401813507,
      "compression_ratio": 1.864341139793396,
      "end": 277.5400085449219,
      "no_speech_prob": 0.0013458363246172667,
      "seek": 24786,
      "start": 276.7799987792969,
      "temperature": 0.0,
      "text": " that you pass it.",
      "tokens": [
        51810,
        300,
        291,
        1320,
        309,
        13,
        51848
      ]
    },
    {
      "id": 70,
      "avg_logprob": -0.19793382287025452,
      "compression_ratio": 1.6719367504119873,
      "end": 283.5400085449219,
      "no_speech_prob": 3.822835424216464e-05,
      "seek": 27786,
      "start": 278.0199890136719,
      "temperature": 0.0,
      "text": " In my case, if you looked at my other videos, I usually use a very similar",
      "tokens": [
        50372,
        682,
        452,
        1389,
        11,
        498,
        291,
        2956,
        412,
        452,
        661,
        2145,
        11,
        286,
        2673,
        764,
        257,
        588,
        2531,
        50648
      ]
    },
    {
      "id": 71,
      "avg_logprob": -0.19793382287025452,
      "compression_ratio": 1.6719367504119873,
      "end": 286.17999267578125,
      "no_speech_prob": 3.822835424216464e-05,
      "seek": 27786,
      "start": 283.70001220703125,
      "temperature": 0.0,
      "text": " thumbnail format for all my videos.",
      "tokens": [
        50656,
        26746,
        7877,
        337,
        439,
        452,
        2145,
        13,
        50780
      ]
    },
    {
      "id": 72,
      "avg_logprob": -0.19793382287025452,
      "compression_ratio": 1.6719367504119873,
      "end": 288.94000244140625,
      "no_speech_prob": 3.822835424216464e-05,
      "seek": 27786,
      "start": 286.5,
      "temperature": 0.0,
      "text": " So this way I can make sure everything is consistent.",
      "tokens": [
        50796,
        407,
        341,
        636,
        286,
        393,
        652,
        988,
        1203,
        307,
        8398,
        13,
        50918
      ]
    },
    {
      "id": 73,
      "avg_logprob": -0.19793382287025452,
      "compression_ratio": 1.6719367504119873,
      "end": 290.6600036621094,
      "no_speech_prob": 3.822835424216464e-05,
      "seek": 27786,
      "start": 290.3800048828125,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        50990,
        1033,
        13,
        51004
      ]
    },
    {
      "id": 74,
      "avg_logprob": -0.19793382287025452,
      "compression_ratio": 1.6719367504119873,
      "end": 295.1000061035156,
      "no_speech_prob": 3.822835424216464e-05,
      "seek": 27786,
      "start": 290.70001220703125,
      "temperature": 0.0,
      "text": " So going back to the diagram, you have the base image, the mask image, a",
      "tokens": [
        51006,
        407,
        516,
        646,
        281,
        264,
        10686,
        11,
        291,
        362,
        264,
        3096,
        3256,
        11,
        264,
        6094,
        3256,
        11,
        257,
        51226
      ]
    },
    {
      "id": 75,
      "avg_logprob": -0.19793382287025452,
      "compression_ratio": 1.6719367504119873,
      "end": 300.260009765625,
      "no_speech_prob": 3.822835424216464e-05,
      "seek": 27786,
      "start": 295.1000061035156,
      "temperature": 0.0,
      "text": " summary of the video that you just saw as input into the terminal, and then",
      "tokens": [
        51226,
        12691,
        295,
        264,
        960,
        300,
        291,
        445,
        1866,
        382,
        4846,
        666,
        264,
        14709,
        11,
        293,
        550,
        51484
      ]
    },
    {
      "id": 76,
      "avg_logprob": -0.19793382287025452,
      "compression_ratio": 1.6719367504119873,
      "end": 301.739990234375,
      "no_speech_prob": 3.822835424216464e-05,
      "seek": 27786,
      "start": 300.260009765625,
      "temperature": 0.0,
      "text": " the mask fill in detail.",
      "tokens": [
        51484,
        264,
        6094,
        2836,
        294,
        2607,
        13,
        51558
      ]
    },
    {
      "id": 77,
      "avg_logprob": -0.19793382287025452,
      "compression_ratio": 1.6719367504119873,
      "end": 306.739990234375,
      "no_speech_prob": 3.822835424216464e-05,
      "seek": 27786,
      "start": 301.739990234375,
      "temperature": 0.0,
      "text": " So this is going to tell the model for each mask, how to exactly replace them.",
      "tokens": [
        51558,
        407,
        341,
        307,
        516,
        281,
        980,
        264,
        2316,
        337,
        1184,
        6094,
        11,
        577,
        281,
        2293,
        7406,
        552,
        13,
        51808
      ]
    },
    {
      "id": 78,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.6680327653884888,
      "end": 312.7799987792969,
      "no_speech_prob": 7.843515049898997e-05,
      "seek": 30674,
      "start": 306.9800109863281,
      "temperature": 0.0,
      "text": " So in our case, we told it to replace the three icons with a penguin, uh, and",
      "tokens": [
        50376,
        407,
        294,
        527,
        1389,
        11,
        321,
        1907,
        309,
        281,
        7406,
        264,
        1045,
        23308,
        365,
        257,
        45752,
        11,
        2232,
        11,
        293,
        50666
      ]
    },
    {
      "id": 79,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.6680327653884888,
      "end": 315.3800048828125,
      "no_speech_prob": 7.843515049898997e-05,
      "seek": 30674,
      "start": 312.7799987792969,
      "temperature": 0.0,
      "text": " two logos, one for OpenAI, one for YouTube.",
      "tokens": [
        50666,
        732,
        40654,
        11,
        472,
        337,
        7238,
        48698,
        11,
        472,
        337,
        3088,
        13,
        50796
      ]
    },
    {
      "id": 80,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.6680327653884888,
      "end": 321.6199951171875,
      "no_speech_prob": 7.843515049898997e-05,
      "seek": 30674,
      "start": 316.1000061035156,
      "temperature": 0.0,
      "text": " So once you have everything in, you just call the OpenAI model and the model",
      "tokens": [
        50832,
        407,
        1564,
        291,
        362,
        1203,
        294,
        11,
        291,
        445,
        818,
        264,
        7238,
        48698,
        2316,
        293,
        264,
        2316,
        51108
      ]
    },
    {
      "id": 81,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.6680327653884888,
      "end": 324.70001220703125,
      "no_speech_prob": 7.843515049898997e-05,
      "seek": 30674,
      "start": 321.6600036621094,
      "temperature": 0.0,
      "text": " generates the file in its response.",
      "tokens": [
        51110,
        23815,
        264,
        3991,
        294,
        1080,
        4134,
        13,
        51262
      ]
    },
    {
      "id": 82,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.6680327653884888,
      "end": 329.3399963378906,
      "no_speech_prob": 7.843515049898997e-05,
      "seek": 30674,
      "start": 325.0199890136719,
      "temperature": 0.0,
      "text": " But when you get the file back, you can set it to two different modes.",
      "tokens": [
        51278,
        583,
        562,
        291,
        483,
        264,
        3991,
        646,
        11,
        291,
        393,
        992,
        309,
        281,
        732,
        819,
        14068,
        13,
        51494
      ]
    },
    {
      "id": 83,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.6680327653884888,
      "end": 333.8999938964844,
      "no_speech_prob": 7.843515049898997e-05,
      "seek": 30674,
      "start": 329.6600036621094,
      "temperature": 0.0,
      "text": " In the first mode, the response is going to be a base 64 encoded image",
      "tokens": [
        51510,
        682,
        264,
        700,
        4391,
        11,
        264,
        4134,
        307,
        516,
        281,
        312,
        257,
        3096,
        12145,
        2058,
        12340,
        3256,
        51722
      ]
    },
    {
      "id": 84,
      "avg_logprob": -0.2083333283662796,
      "compression_ratio": 1.6680327653884888,
      "end": 336.2200012207031,
      "no_speech_prob": 7.843515049898997e-05,
      "seek": 30674,
      "start": 333.8999938964844,
      "temperature": 0.0,
      "text": " file that needs to be decoded.",
      "tokens": [
        51722,
        3991,
        300,
        2203,
        281,
        312,
        979,
        12340,
        13,
        51838
      ]
    },
    {
      "id": 85,
      "avg_logprob": -0.19721482694149017,
      "compression_ratio": 1.7863247394561768,
      "end": 342.8599853515625,
      "no_speech_prob": 7.031051791273057e-05,
      "seek": 33622,
      "start": 336.70001220703125,
      "temperature": 0.0,
      "text": " And in the second mode, you can, uh, you can ask it to give you a URL, right?",
      "tokens": [
        50388,
        400,
        294,
        264,
        1150,
        4391,
        11,
        291,
        393,
        11,
        2232,
        11,
        291,
        393,
        1029,
        309,
        281,
        976,
        291,
        257,
        12905,
        11,
        558,
        30,
        50696
      ]
    },
    {
      "id": 86,
      "avg_logprob": -0.19721482694149017,
      "compression_ratio": 1.7863247394561768,
      "end": 346.82000732421875,
      "no_speech_prob": 7.031051791273057e-05,
      "seek": 33622,
      "start": 342.8599853515625,
      "temperature": 0.0,
      "text": " So the model is going to generate the image, upload it somewhere in the",
      "tokens": [
        50696,
        407,
        264,
        2316,
        307,
        516,
        281,
        8460,
        264,
        3256,
        11,
        6580,
        309,
        4079,
        294,
        264,
        50894
      ]
    },
    {
      "id": 87,
      "avg_logprob": -0.19721482694149017,
      "compression_ratio": 1.7863247394561768,
      "end": 348.9800109863281,
      "no_speech_prob": 7.031051791273057e-05,
      "seek": 33622,
      "start": 346.82000732421875,
      "temperature": 0.0,
      "text": " cloud, and then give you the URL.",
      "tokens": [
        50894,
        4588,
        11,
        293,
        550,
        976,
        291,
        264,
        12905,
        13,
        51002
      ]
    },
    {
      "id": 88,
      "avg_logprob": -0.19721482694149017,
      "compression_ratio": 1.7863247394561768,
      "end": 353.260009765625,
      "no_speech_prob": 7.031051791273057e-05,
      "seek": 33622,
      "start": 349.70001220703125,
      "temperature": 0.0,
      "text": " In that case, when you get the URL back, you need to download",
      "tokens": [
        51038,
        682,
        300,
        1389,
        11,
        562,
        291,
        483,
        264,
        12905,
        646,
        11,
        291,
        643,
        281,
        5484,
        51216
      ]
    },
    {
      "id": 89,
      "avg_logprob": -0.19721482694149017,
      "compression_ratio": 1.7863247394561768,
      "end": 355.1400146484375,
      "no_speech_prob": 7.031051791273057e-05,
      "seek": 33622,
      "start": 353.260009765625,
      "temperature": 0.0,
      "text": " it into your local device.",
      "tokens": [
        51216,
        309,
        666,
        428,
        2654,
        4302,
        13,
        51310
      ]
    },
    {
      "id": 90,
      "avg_logprob": -0.19721482694149017,
      "compression_ratio": 1.7863247394561768,
      "end": 360.1400146484375,
      "no_speech_prob": 7.031051791273057e-05,
      "seek": 33622,
      "start": 356.0199890136719,
      "temperature": 0.0,
      "text": " And in our case, we're going to stick to the base 64 encoded image.",
      "tokens": [
        51354,
        400,
        294,
        527,
        1389,
        11,
        321,
        434,
        516,
        281,
        2897,
        281,
        264,
        3096,
        12145,
        2058,
        12340,
        3256,
        13,
        51560
      ]
    },
    {
      "id": 91,
      "avg_logprob": -0.19721482694149017,
      "compression_ratio": 1.7863247394561768,
      "end": 364.1000061035156,
      "no_speech_prob": 7.031051791273057e-05,
      "seek": 33622,
      "start": 360.4599914550781,
      "temperature": 0.0,
      "text": " And if I go into the code, you're going to see, we do it right here, where we",
      "tokens": [
        51576,
        400,
        498,
        286,
        352,
        666,
        264,
        3089,
        11,
        291,
        434,
        516,
        281,
        536,
        11,
        321,
        360,
        309,
        558,
        510,
        11,
        689,
        321,
        51758
      ]
    },
    {
      "id": 92,
      "avg_logprob": -0.19548258185386658,
      "compression_ratio": 1.6666666269302368,
      "end": 367.5,
      "no_speech_prob": 0.0002780235081445426,
      "seek": 36410,
      "start": 364.1000061035156,
      "temperature": 0.0,
      "text": " take the response, we decode it, and then we save it to file.",
      "tokens": [
        50364,
        747,
        264,
        4134,
        11,
        321,
        979,
        1429,
        309,
        11,
        293,
        550,
        321,
        3155,
        309,
        281,
        3991,
        13,
        50534
      ]
    },
    {
      "id": 93,
      "avg_logprob": -0.19548258185386658,
      "compression_ratio": 1.6666666269302368,
      "end": 369.3800048828125,
      "no_speech_prob": 0.0002780235081445426,
      "seek": 36410,
      "start": 369.1000061035156,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        50614,
        1033,
        13,
        50628
      ]
    },
    {
      "id": 94,
      "avg_logprob": -0.19548258185386658,
      "compression_ratio": 1.6666666269302368,
      "end": 371.3399963378906,
      "no_speech_prob": 0.0002780235081445426,
      "seek": 36410,
      "start": 369.4200134277344,
      "temperature": 0.0,
      "text": " So that's how the design looks like.",
      "tokens": [
        50630,
        407,
        300,
        311,
        577,
        264,
        1715,
        1542,
        411,
        13,
        50726
      ]
    },
    {
      "id": 95,
      "avg_logprob": -0.19548258185386658,
      "compression_ratio": 1.6666666269302368,
      "end": 376.5799865722656,
      "no_speech_prob": 0.0002780235081445426,
      "seek": 36410,
      "start": 371.3800048828125,
      "temperature": 0.0,
      "text": " As a recap, we have base image, mask image, a summary of the video, and",
      "tokens": [
        50728,
        1018,
        257,
        20928,
        11,
        321,
        362,
        3096,
        3256,
        11,
        6094,
        3256,
        11,
        257,
        12691,
        295,
        264,
        960,
        11,
        293,
        50988
      ]
    },
    {
      "id": 96,
      "avg_logprob": -0.19548258185386658,
      "compression_ratio": 1.6666666269302368,
      "end": 381.05999755859375,
      "no_speech_prob": 0.0002780235081445426,
      "seek": 36410,
      "start": 376.5799865722656,
      "temperature": 0.0,
      "text": " then a prompt with all the details that the model needs to fill in the mask.",
      "tokens": [
        50988,
        550,
        257,
        12391,
        365,
        439,
        264,
        4365,
        300,
        264,
        2316,
        2203,
        281,
        2836,
        294,
        264,
        6094,
        13,
        51212
      ]
    },
    {
      "id": 97,
      "avg_logprob": -0.19548258185386658,
      "compression_ratio": 1.6666666269302368,
      "end": 383.1000061035156,
      "no_speech_prob": 0.0002780235081445426,
      "seek": 36410,
      "start": 381.4599914550781,
      "temperature": 0.0,
      "text": " We pass everything to the model.",
      "tokens": [
        51232,
        492,
        1320,
        1203,
        281,
        264,
        2316,
        13,
        51314
      ]
    },
    {
      "id": 98,
      "avg_logprob": -0.19548258185386658,
      "compression_ratio": 1.6666666269302368,
      "end": 389.05999755859375,
      "no_speech_prob": 0.0002780235081445426,
      "seek": 36410,
      "start": 383.5400085449219,
      "temperature": 0.0,
      "text": " The model generates the file either as a base 64 encoded file or",
      "tokens": [
        51336,
        440,
        2316,
        23815,
        264,
        3991,
        2139,
        382,
        257,
        3096,
        12145,
        2058,
        12340,
        3991,
        420,
        51612
      ]
    },
    {
      "id": 99,
      "avg_logprob": -0.19548258185386658,
      "compression_ratio": 1.6666666269302368,
      "end": 391.94000244140625,
      "no_speech_prob": 0.0002780235081445426,
      "seek": 36410,
      "start": 389.1000061035156,
      "temperature": 0.0,
      "text": " upload it into the cloud with the URL.",
      "tokens": [
        51614,
        6580,
        309,
        666,
        264,
        4588,
        365,
        264,
        12905,
        13,
        51756
      ]
    },
    {
      "id": 100,
      "avg_logprob": -0.2101338803768158,
      "compression_ratio": 1.7316176891326904,
      "end": 397.0199890136719,
      "no_speech_prob": 9.314398630522192e-05,
      "seek": 39194,
      "start": 392.4599914550781,
      "temperature": 0.0,
      "text": " It returns back either the encoded file or the URL, and you can",
      "tokens": [
        50390,
        467,
        11247,
        646,
        2139,
        264,
        2058,
        12340,
        3991,
        420,
        264,
        12905,
        11,
        293,
        291,
        393,
        50618
      ]
    },
    {
      "id": 101,
      "avg_logprob": -0.2101338803768158,
      "compression_ratio": 1.7316176891326904,
      "end": 398.8599853515625,
      "no_speech_prob": 9.314398630522192e-05,
      "seek": 39194,
      "start": 397.0199890136719,
      "temperature": 0.0,
      "text": " just download it to save it locally.",
      "tokens": [
        50618,
        445,
        5484,
        309,
        281,
        3155,
        309,
        16143,
        13,
        50710
      ]
    },
    {
      "id": 102,
      "avg_logprob": -0.2101338803768158,
      "compression_ratio": 1.7316176891326904,
      "end": 400.8599853515625,
      "no_speech_prob": 9.314398630522192e-05,
      "seek": 39194,
      "start": 400.5799865722656,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        50796,
        1033,
        13,
        50810
      ]
    },
    {
      "id": 103,
      "avg_logprob": -0.2101338803768158,
      "compression_ratio": 1.7316176891326904,
      "end": 403.9800109863281,
      "no_speech_prob": 9.314398630522192e-05,
      "seek": 39194,
      "start": 400.8999938964844,
      "temperature": 0.0,
      "text": " So now let's move to the final part where we're going to look at the code.",
      "tokens": [
        50812,
        407,
        586,
        718,
        311,
        1286,
        281,
        264,
        2572,
        644,
        689,
        321,
        434,
        516,
        281,
        574,
        412,
        264,
        3089,
        13,
        50966
      ]
    },
    {
      "id": 104,
      "avg_logprob": -0.2101338803768158,
      "compression_ratio": 1.7316176891326904,
      "end": 408.260009765625,
      "no_speech_prob": 9.314398630522192e-05,
      "seek": 39194,
      "start": 404.6199951171875,
      "temperature": 0.0,
      "text": " In the code, if I go from top to bottom, you're going to see, we",
      "tokens": [
        50998,
        682,
        264,
        3089,
        11,
        498,
        286,
        352,
        490,
        1192,
        281,
        2767,
        11,
        291,
        434,
        516,
        281,
        536,
        11,
        321,
        51180
      ]
    },
    {
      "id": 105,
      "avg_logprob": -0.2101338803768158,
      "compression_ratio": 1.7316176891326904,
      "end": 412.29998779296875,
      "no_speech_prob": 9.314398630522192e-05,
      "seek": 39194,
      "start": 408.260009765625,
      "temperature": 0.0,
      "text": " have some of the API keys listed, and then we have the path to the",
      "tokens": [
        51180,
        362,
        512,
        295,
        264,
        9362,
        9317,
        10052,
        11,
        293,
        550,
        321,
        362,
        264,
        3100,
        281,
        264,
        51382
      ]
    },
    {
      "id": 106,
      "avg_logprob": -0.2101338803768158,
      "compression_ratio": 1.7316176891326904,
      "end": 415.7799987792969,
      "no_speech_prob": 9.314398630522192e-05,
      "seek": 39194,
      "start": 412.29998779296875,
      "temperature": 0.0,
      "text": " template file and the mask, a mask file, right?",
      "tokens": [
        51382,
        12379,
        3991,
        293,
        264,
        6094,
        11,
        257,
        6094,
        3991,
        11,
        558,
        30,
        51556
      ]
    },
    {
      "id": 107,
      "avg_logprob": -0.2101338803768158,
      "compression_ratio": 1.7316176891326904,
      "end": 419.260009765625,
      "no_speech_prob": 9.314398630522192e-05,
      "seek": 39194,
      "start": 416.260009765625,
      "temperature": 0.0,
      "text": " Uh, both of these needs to be passed into the model.",
      "tokens": [
        51580,
        4019,
        11,
        1293,
        295,
        613,
        2203,
        281,
        312,
        4678,
        666,
        264,
        2316,
        13,
        51730
      ]
    },
    {
      "id": 108,
      "avg_logprob": -0.2101338803768158,
      "compression_ratio": 1.7316176891326904,
      "end": 421.3800048828125,
      "no_speech_prob": 9.314398630522192e-05,
      "seek": 39194,
      "start": 419.4200134277344,
      "temperature": 0.0,
      "text": " And you're going to see how we're doing that right here.",
      "tokens": [
        51738,
        400,
        291,
        434,
        516,
        281,
        536,
        577,
        321,
        434,
        884,
        300,
        558,
        510,
        13,
        51836
      ]
    },
    {
      "id": 109,
      "avg_logprob": -0.246337890625,
      "compression_ratio": 1.9102563858032227,
      "end": 422.6600036621094,
      "no_speech_prob": 5.144145688973367e-05,
      "seek": 42194,
      "start": 422.3800048828125,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        50386,
        1033,
        13,
        50400
      ]
    },
    {
      "id": 110,
      "avg_logprob": -0.246337890625,
      "compression_ratio": 1.9102563858032227,
      "end": 424.1400146484375,
      "no_speech_prob": 5.144145688973367e-05,
      "seek": 42194,
      "start": 423.3800048828125,
      "temperature": 0.0,
      "text": " Um, all right.",
      "tokens": [
        50436,
        3301,
        11,
        439,
        558,
        13,
        50474
      ]
    },
    {
      "id": 111,
      "avg_logprob": -0.246337890625,
      "compression_ratio": 1.9102563858032227,
      "end": 428.29998779296875,
      "no_speech_prob": 5.144145688973367e-05,
      "seek": 42194,
      "start": 424.1400146484375,
      "temperature": 0.0,
      "text": " So now this is where bulk of the logic is where we're opening both the files.",
      "tokens": [
        50474,
        407,
        586,
        341,
        307,
        689,
        16139,
        295,
        264,
        9952,
        307,
        689,
        321,
        434,
        5193,
        1293,
        264,
        7098,
        13,
        50682
      ]
    },
    {
      "id": 112,
      "avg_logprob": -0.246337890625,
      "compression_ratio": 1.9102563858032227,
      "end": 431.260009765625,
      "no_speech_prob": 5.144145688973367e-05,
      "seek": 42194,
      "start": 428.29998779296875,
      "temperature": 0.0,
      "text": " So we're opening both the template file and the mask file.",
      "tokens": [
        50682,
        407,
        321,
        434,
        5193,
        1293,
        264,
        12379,
        3991,
        293,
        264,
        6094,
        3991,
        13,
        50830
      ]
    },
    {
      "id": 113,
      "avg_logprob": -0.246337890625,
      "compression_ratio": 1.9102563858032227,
      "end": 435.5400085449219,
      "no_speech_prob": 5.144145688973367e-05,
      "seek": 42194,
      "start": 432.0199890136719,
      "temperature": 0.0,
      "text": " And then we're asking the user to input a bunch of details,",
      "tokens": [
        50868,
        400,
        550,
        321,
        434,
        3365,
        264,
        4195,
        281,
        4846,
        257,
        3840,
        295,
        4365,
        11,
        51044
      ]
    },
    {
      "id": 114,
      "avg_logprob": -0.246337890625,
      "compression_ratio": 1.9102563858032227,
      "end": 437.6199951171875,
      "no_speech_prob": 5.144145688973367e-05,
      "seek": 42194,
      "start": 436.0199890136719,
      "temperature": 0.0,
      "text": " going through them one by one.",
      "tokens": [
        51068,
        516,
        807,
        552,
        472,
        538,
        472,
        13,
        51148
      ]
    },
    {
      "id": 115,
      "avg_logprob": -0.246337890625,
      "compression_ratio": 1.9102563858032227,
      "end": 440.9800109863281,
      "no_speech_prob": 5.144145688973367e-05,
      "seek": 42194,
      "start": 437.6600036621094,
      "temperature": 0.0,
      "text": " We want the user to give us the title, the subtitle.",
      "tokens": [
        51150,
        492,
        528,
        264,
        4195,
        281,
        976,
        505,
        264,
        4876,
        11,
        264,
        30706,
        306,
        13,
        51316
      ]
    },
    {
      "id": 116,
      "avg_logprob": -0.246337890625,
      "compression_ratio": 1.9102563858032227,
      "end": 446.2200012207031,
      "no_speech_prob": 5.144145688973367e-05,
      "seek": 42194,
      "start": 441.05999755859375,
      "temperature": 0.0,
      "text": " So if I move here, so we're essentially asking the user, give us the title",
      "tokens": [
        51320,
        407,
        498,
        286,
        1286,
        510,
        11,
        370,
        321,
        434,
        4476,
        3365,
        264,
        4195,
        11,
        976,
        505,
        264,
        4876,
        51578
      ]
    },
    {
      "id": 117,
      "avg_logprob": -0.246337890625,
      "compression_ratio": 1.9102563858032227,
      "end": 451.8599853515625,
      "no_speech_prob": 5.144145688973367e-05,
      "seek": 42194,
      "start": 446.2200012207031,
      "temperature": 0.0,
      "text": " here, give us the subtitle, and then the background colors, in my case",
      "tokens": [
        51578,
        510,
        11,
        976,
        505,
        264,
        30706,
        306,
        11,
        293,
        550,
        264,
        3678,
        4577,
        11,
        294,
        452,
        1389,
        51860
      ]
    },
    {
      "id": 118,
      "avg_logprob": -0.23823335766792297,
      "compression_ratio": 1.6085106134414673,
      "end": 454.5799865722656,
      "no_speech_prob": 0.0001273103553103283,
      "seek": 45186,
      "start": 451.8599853515625,
      "temperature": 0.0,
      "text": " it's always black, but if you want a different color, you can",
      "tokens": [
        50364,
        309,
        311,
        1009,
        2211,
        11,
        457,
        498,
        291,
        528,
        257,
        819,
        2017,
        11,
        291,
        393,
        50500
      ]
    },
    {
      "id": 119,
      "avg_logprob": -0.23823335766792297,
      "compression_ratio": 1.6085106134414673,
      "end": 456.8599853515625,
      "no_speech_prob": 0.0001273103553103283,
      "seek": 45186,
      "start": 454.94000244140625,
      "temperature": 0.0,
      "text": " input that into the model as well.",
      "tokens": [
        50518,
        4846,
        300,
        666,
        264,
        2316,
        382,
        731,
        13,
        50614
      ]
    },
    {
      "id": 120,
      "avg_logprob": -0.23823335766792297,
      "compression_ratio": 1.6085106134414673,
      "end": 461.0199890136719,
      "no_speech_prob": 0.0001273103553103283,
      "seek": 45186,
      "start": 457.5400085449219,
      "temperature": 0.0,
      "text": " And then for the three icons, I'm going to ask them for a description.",
      "tokens": [
        50648,
        400,
        550,
        337,
        264,
        1045,
        23308,
        11,
        286,
        478,
        516,
        281,
        1029,
        552,
        337,
        257,
        3855,
        13,
        50822
      ]
    },
    {
      "id": 121,
      "avg_logprob": -0.23823335766792297,
      "compression_ratio": 1.6085106134414673,
      "end": 461.7799987792969,
      "no_speech_prob": 0.0001273103553103283,
      "seek": 45186,
      "start": 461.5400085449219,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        50848,
        1033,
        13,
        50860
      ]
    },
    {
      "id": 122,
      "avg_logprob": -0.23823335766792297,
      "compression_ratio": 1.6085106134414673,
      "end": 466.5400085449219,
      "no_speech_prob": 0.0001273103553103283,
      "seek": 45186,
      "start": 462.17999267578125,
      "temperature": 0.0,
      "text": " Finally, at the video summary to give a lot more context to the model.",
      "tokens": [
        50880,
        6288,
        11,
        412,
        264,
        960,
        12691,
        281,
        976,
        257,
        688,
        544,
        4319,
        281,
        264,
        2316,
        13,
        51098
      ]
    },
    {
      "id": 123,
      "avg_logprob": -0.23823335766792297,
      "compression_ratio": 1.6085106134414673,
      "end": 473.29998779296875,
      "no_speech_prob": 0.0001273103553103283,
      "seek": 45186,
      "start": 468.29998779296875,
      "temperature": 0.0,
      "text": " Once we gather all the information, we're just calling the images",
      "tokens": [
        51186,
        3443,
        321,
        5448,
        439,
        264,
        1589,
        11,
        321,
        434,
        445,
        5141,
        264,
        5267,
        51436
      ]
    },
    {
      "id": 124,
      "avg_logprob": -0.23823335766792297,
      "compression_ratio": 1.6085106134414673,
      "end": 480.3399963378906,
      "no_speech_prob": 0.0001273103553103283,
      "seek": 45186,
      "start": 473.7799987792969,
      "temperature": 0.0,
      "text": " model with a prompt, the image file, the mask file, the background,",
      "tokens": [
        51460,
        2316,
        365,
        257,
        12391,
        11,
        264,
        3256,
        3991,
        11,
        264,
        6094,
        3991,
        11,
        264,
        3678,
        11,
        51788
      ]
    },
    {
      "id": 125,
      "avg_logprob": -0.2379702925682068,
      "compression_ratio": 1.615702509880066,
      "end": 481.9800109863281,
      "no_speech_prob": 0.00016864640929270536,
      "seek": 48034,
      "start": 480.739990234375,
      "temperature": 0.0,
      "text": " output and size.",
      "tokens": [
        50384,
        5598,
        293,
        2744,
        13,
        50446
      ]
    },
    {
      "id": 126,
      "avg_logprob": -0.2379702925682068,
      "compression_ratio": 1.615702509880066,
      "end": 482.739990234375,
      "no_speech_prob": 0.00016864640929270536,
      "seek": 48034,
      "start": 482.4599914550781,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        50470,
        1033,
        13,
        50484
      ]
    },
    {
      "id": 127,
      "avg_logprob": -0.2379702925682068,
      "compression_ratio": 1.615702509880066,
      "end": 488.8599853515625,
      "no_speech_prob": 0.00016864640929270536,
      "seek": 48034,
      "start": 483.17999267578125,
      "temperature": 0.0,
      "text": " For the model, uh, to, to do the workflow that I'm showing here, I think you can",
      "tokens": [
        50506,
        1171,
        264,
        2316,
        11,
        2232,
        11,
        281,
        11,
        281,
        360,
        264,
        20993,
        300,
        286,
        478,
        4099,
        510,
        11,
        286,
        519,
        291,
        393,
        50790
      ]
    },
    {
      "id": 128,
      "avg_logprob": -0.2379702925682068,
      "compression_ratio": 1.615702509880066,
      "end": 490.5,
      "no_speech_prob": 0.00016864640929270536,
      "seek": 48034,
      "start": 488.8599853515625,
      "temperature": 0.0,
      "text": " only do this with two models.",
      "tokens": [
        50790,
        787,
        360,
        341,
        365,
        732,
        5245,
        13,
        50872
      ]
    },
    {
      "id": 129,
      "avg_logprob": -0.2379702925682068,
      "compression_ratio": 1.615702509880066,
      "end": 492.7799987792969,
      "no_speech_prob": 0.00016864640929270536,
      "seek": 48034,
      "start": 490.5,
      "temperature": 0.0,
      "text": " One is the GPT, uh, image one.",
      "tokens": [
        50872,
        1485,
        307,
        264,
        26039,
        51,
        11,
        2232,
        11,
        3256,
        472,
        13,
        50986
      ]
    },
    {
      "id": 130,
      "avg_logprob": -0.2379702925682068,
      "compression_ratio": 1.615702509880066,
      "end": 495.7799987792969,
      "no_speech_prob": 0.00016864640929270536,
      "seek": 48034,
      "start": 493.260009765625,
      "temperature": 0.0,
      "text": " And the other is, um, I'm forgetting.",
      "tokens": [
        51010,
        400,
        264,
        661,
        307,
        11,
        1105,
        11,
        286,
        478,
        25428,
        13,
        51136
      ]
    },
    {
      "id": 131,
      "avg_logprob": -0.2379702925682068,
      "compression_ratio": 1.615702509880066,
      "end": 502.3399963378906,
      "no_speech_prob": 0.00016864640929270536,
      "seek": 48034,
      "start": 495.7799987792969,
      "temperature": 0.0,
      "text": " I think it's a image 1.5 or one of the GPT 4.0 model or the DALI models.",
      "tokens": [
        51136,
        286,
        519,
        309,
        311,
        257,
        3256,
        502,
        13,
        20,
        420,
        472,
        295,
        264,
        26039,
        51,
        1017,
        13,
        15,
        2316,
        420,
        264,
        413,
        11566,
        5245,
        13,
        51464
      ]
    },
    {
      "id": 132,
      "avg_logprob": -0.2379702925682068,
      "compression_ratio": 1.615702509880066,
      "end": 506.739990234375,
      "no_speech_prob": 0.00016864640929270536,
      "seek": 48034,
      "start": 502.4200134277344,
      "temperature": 0.0,
      "text": " So you can look at the documentation, but after trying multiple times, I, I",
      "tokens": [
        51468,
        407,
        291,
        393,
        574,
        412,
        264,
        14333,
        11,
        457,
        934,
        1382,
        3866,
        1413,
        11,
        286,
        11,
        286,
        51684
      ]
    },
    {
      "id": 133,
      "avg_logprob": -0.2379702925682068,
      "compression_ratio": 1.615702509880066,
      "end": 509.6600036621094,
      "no_speech_prob": 0.00016864640929270536,
      "seek": 48034,
      "start": 506.739990234375,
      "temperature": 0.0,
      "text": " got the best result with GPT image one.",
      "tokens": [
        51684,
        658,
        264,
        1151,
        1874,
        365,
        26039,
        51,
        3256,
        472,
        13,
        51830
      ]
    },
    {
      "id": 134,
      "avg_logprob": -0.24483470618724823,
      "compression_ratio": 1.696969747543335,
      "end": 514.739990234375,
      "no_speech_prob": 4.539587826002389e-05,
      "seek": 51034,
      "start": 510.94000244140625,
      "temperature": 0.0,
      "text": " For the prompt, uh, you can see it's a prompt where I sub in the",
      "tokens": [
        50394,
        1171,
        264,
        12391,
        11,
        2232,
        11,
        291,
        393,
        536,
        309,
        311,
        257,
        12391,
        689,
        286,
        1422,
        294,
        264,
        50584
      ]
    },
    {
      "id": 135,
      "avg_logprob": -0.24483470618724823,
      "compression_ratio": 1.696969747543335,
      "end": 517.2999877929688,
      "no_speech_prob": 4.539587826002389e-05,
      "seek": 51034,
      "start": 514.739990234375,
      "temperature": 0.0,
      "text": " values that the user, uh, input before.",
      "tokens": [
        50584,
        4190,
        300,
        264,
        4195,
        11,
        2232,
        11,
        4846,
        949,
        13,
        50712
      ]
    },
    {
      "id": 136,
      "avg_logprob": -0.24483470618724823,
      "compression_ratio": 1.696969747543335,
      "end": 521.7000122070312,
      "no_speech_prob": 4.539587826002389e-05,
      "seek": 51034,
      "start": 517.8200073242188,
      "temperature": 0.0,
      "text": " And so we have the title going in, the subtitle going in, the background",
      "tokens": [
        50738,
        400,
        370,
        321,
        362,
        264,
        4876,
        516,
        294,
        11,
        264,
        30706,
        306,
        516,
        294,
        11,
        264,
        3678,
        50932
      ]
    },
    {
      "id": 137,
      "avg_logprob": -0.24483470618724823,
      "compression_ratio": 1.696969747543335,
      "end": 526.6199951171875,
      "no_speech_prob": 4.539587826002389e-05,
      "seek": 51034,
      "start": 521.7000122070312,
      "temperature": 0.0,
      "text": " color, the three icons, and then I think, do I pass the summary?",
      "tokens": [
        50932,
        2017,
        11,
        264,
        1045,
        23308,
        11,
        293,
        550,
        286,
        519,
        11,
        360,
        286,
        1320,
        264,
        12691,
        30,
        51178
      ]
    },
    {
      "id": 138,
      "avg_logprob": -0.24483470618724823,
      "compression_ratio": 1.696969747543335,
      "end": 527.7000122070312,
      "no_speech_prob": 4.539587826002389e-05,
      "seek": 51034,
      "start": 526.6199951171875,
      "temperature": 0.0,
      "text": " Yeah, I'm passing the summary here.",
      "tokens": [
        51178,
        865,
        11,
        286,
        478,
        8437,
        264,
        12691,
        510,
        13,
        51232
      ]
    },
    {
      "id": 139,
      "avg_logprob": -0.24483470618724823,
      "compression_ratio": 1.696969747543335,
      "end": 528.7000122070312,
      "no_speech_prob": 4.539587826002389e-05,
      "seek": 51034,
      "start": 528.5399780273438,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        51274,
        1033,
        13,
        51282
      ]
    },
    {
      "id": 140,
      "avg_logprob": -0.24483470618724823,
      "compression_ratio": 1.696969747543335,
      "end": 529.6199951171875,
      "no_speech_prob": 4.539587826002389e-05,
      "seek": 51034,
      "start": 528.97998046875,
      "temperature": 0.0,
      "text": " Whoops.",
      "tokens": [
        51296,
        45263,
        13,
        51328
      ]
    },
    {
      "id": 141,
      "avg_logprob": -0.24483470618724823,
      "compression_ratio": 1.696969747543335,
      "end": 531.7000122070312,
      "no_speech_prob": 4.539587826002389e-05,
      "seek": 51034,
      "start": 529.6599731445312,
      "temperature": 0.0,
      "text": " The summary is here.",
      "tokens": [
        51330,
        440,
        12691,
        307,
        510,
        13,
        51432
      ]
    },
    {
      "id": 142,
      "avg_logprob": -0.24483470618724823,
      "compression_ratio": 1.696969747543335,
      "end": 533.4600219726562,
      "no_speech_prob": 4.539587826002389e-05,
      "seek": 51034,
      "start": 533.1799926757812,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        51506,
        1033,
        13,
        51520
      ]
    },
    {
      "id": 143,
      "avg_logprob": -0.24483470618724823,
      "compression_ratio": 1.696969747543335,
      "end": 540.1400146484375,
      "no_speech_prob": 4.539587826002389e-05,
      "seek": 51034,
      "start": 533.4600219726562,
      "temperature": 0.0,
      "text": " So we get the result and then we do a base 64 decoding before writing it",
      "tokens": [
        51520,
        407,
        321,
        483,
        264,
        1874,
        293,
        550,
        321,
        360,
        257,
        3096,
        12145,
        979,
        8616,
        949,
        3579,
        309,
        51854
      ]
    },
    {
      "id": 144,
      "avg_logprob": -0.23203743994235992,
      "compression_ratio": 1.572614073753357,
      "end": 543.219970703125,
      "no_speech_prob": 8.75020632520318e-05,
      "seek": 54014,
      "start": 540.1400146484375,
      "temperature": 0.0,
      "text": " into a new file called youtube-thumbnail.jpg.",
      "tokens": [
        50364,
        666,
        257,
        777,
        3991,
        1219,
        12487,
        12,
        392,
        2860,
        629,
        388,
        13,
        73,
        49861,
        13,
        50518
      ]
    },
    {
      "id": 145,
      "avg_logprob": -0.23203743994235992,
      "compression_ratio": 1.572614073753357,
      "end": 546.6599731445312,
      "no_speech_prob": 8.75020632520318e-05,
      "seek": 54014,
      "start": 544.4600219726562,
      "temperature": 0.0,
      "text": " So that's the full end-to-end system.",
      "tokens": [
        50580,
        407,
        300,
        311,
        264,
        1577,
        917,
        12,
        1353,
        12,
        521,
        1185,
        13,
        50690
      ]
    },
    {
      "id": 146,
      "avg_logprob": -0.23203743994235992,
      "compression_ratio": 1.572614073753357,
      "end": 548.4600219726562,
      "no_speech_prob": 8.75020632520318e-05,
      "seek": 54014,
      "start": 546.739990234375,
      "temperature": 0.0,
      "text": " We start with the template file.",
      "tokens": [
        50694,
        492,
        722,
        365,
        264,
        12379,
        3991,
        13,
        50780
      ]
    },
    {
      "id": 147,
      "avg_logprob": -0.23203743994235992,
      "compression_ratio": 1.572614073753357,
      "end": 552.97998046875,
      "no_speech_prob": 8.75020632520318e-05,
      "seek": 54014,
      "start": 548.6599731445312,
      "temperature": 0.0,
      "text": " We go through the OpenAI API, and finally we save the file",
      "tokens": [
        50790,
        492,
        352,
        807,
        264,
        7238,
        48698,
        9362,
        11,
        293,
        2721,
        321,
        3155,
        264,
        3991,
        51006
      ]
    },
    {
      "id": 148,
      "avg_logprob": -0.23203743994235992,
      "compression_ratio": 1.572614073753357,
      "end": 554.2999877929688,
      "no_speech_prob": 8.75020632520318e-05,
      "seek": 54014,
      "start": 552.97998046875,
      "temperature": 0.0,
      "text": " into our local hard drive.",
      "tokens": [
        51006,
        666,
        527,
        2654,
        1152,
        3332,
        13,
        51072
      ]
    },
    {
      "id": 149,
      "avg_logprob": -0.23203743994235992,
      "compression_ratio": 1.572614073753357,
      "end": 558.6199951171875,
      "no_speech_prob": 8.75020632520318e-05,
      "seek": 54014,
      "start": 555.97998046875,
      "temperature": 0.0,
      "text": " So that's everything I had for you today.",
      "tokens": [
        51156,
        407,
        300,
        311,
        1203,
        286,
        632,
        337,
        291,
        965,
        13,
        51288
      ]
    },
    {
      "id": 150,
      "avg_logprob": -0.23203743994235992,
      "compression_ratio": 1.572614073753357,
      "end": 563.0999755859375,
      "no_speech_prob": 8.75020632520318e-05,
      "seek": 54014,
      "start": 559.0999755859375,
      "temperature": 0.0,
      "text": " We're going to quickly go and look at the program we kicked off in",
      "tokens": [
        51312,
        492,
        434,
        516,
        281,
        2661,
        352,
        293,
        574,
        412,
        264,
        1461,
        321,
        14609,
        766,
        294,
        51512
      ]
    },
    {
      "id": 151,
      "avg_logprob": -0.23203743994235992,
      "compression_ratio": 1.572614073753357,
      "end": 565.739990234375,
      "no_speech_prob": 8.75020632520318e-05,
      "seek": 54014,
      "start": 563.0999755859375,
      "temperature": 0.0,
      "text": " the background to, to end the video.",
      "tokens": [
        51512,
        264,
        3678,
        281,
        11,
        281,
        917,
        264,
        960,
        13,
        51644
      ]
    },
    {
      "id": 152,
      "avg_logprob": -0.23203743994235992,
      "compression_ratio": 1.572614073753357,
      "end": 567.1400146484375,
      "no_speech_prob": 8.75020632520318e-05,
      "seek": 54014,
      "start": 565.780029296875,
      "temperature": 0.0,
      "text": " So let me go back to terminal.",
      "tokens": [
        51646,
        407,
        718,
        385,
        352,
        646,
        281,
        14709,
        13,
        51714
      ]
    },
    {
      "id": 153,
      "avg_logprob": -0.2789744436740875,
      "compression_ratio": 1.6096256971359253,
      "end": 572.7000122070312,
      "no_speech_prob": 0.00017400042270310223,
      "seek": 56714,
      "start": 567.6599731445312,
      "temperature": 0.0,
      "text": " You can see that we have generating thumbnail, generated, and then saving.",
      "tokens": [
        50390,
        509,
        393,
        536,
        300,
        321,
        362,
        17746,
        26746,
        11,
        10833,
        11,
        293,
        550,
        6816,
        13,
        50642
      ]
    },
    {
      "id": 154,
      "avg_logprob": -0.2789744436740875,
      "compression_ratio": 1.6096256971359253,
      "end": 577.260009765625,
      "no_speech_prob": 0.00017400042270310223,
      "seek": 56714,
      "start": 572.9400024414062,
      "temperature": 0.0,
      "text": " And it saved the file in LLM images, YouTube thumbnail.",
      "tokens": [
        50654,
        400,
        309,
        6624,
        264,
        3991,
        294,
        441,
        43,
        44,
        5267,
        11,
        3088,
        26746,
        13,
        50870
      ]
    },
    {
      "id": 155,
      "avg_logprob": -0.2789744436740875,
      "compression_ratio": 1.6096256971359253,
      "end": 579.6599731445312,
      "no_speech_prob": 0.00017400042270310223,
      "seek": 56714,
      "start": 577.8200073242188,
      "temperature": 0.0,
      "text": " So let's see what it came up with.",
      "tokens": [
        50898,
        407,
        718,
        311,
        536,
        437,
        309,
        1361,
        493,
        365,
        13,
        50990
      ]
    },
    {
      "id": 156,
      "avg_logprob": -0.2789744436740875,
      "compression_ratio": 1.6096256971359253,
      "end": 582.8599853515625,
      "no_speech_prob": 0.00017400042270310223,
      "seek": 56714,
      "start": 580.8599853515625,
      "temperature": 0.0,
      "text": " Uh, here you go.",
      "tokens": [
        51050,
        4019,
        11,
        510,
        291,
        352,
        13,
        51150
      ]
    },
    {
      "id": 157,
      "avg_logprob": -0.2789744436740875,
      "compression_ratio": 1.6096256971359253,
      "end": 589.2999877929688,
      "no_speech_prob": 0.00017400042270310223,
      "seek": 56714,
      "start": 583.0999755859375,
      "temperature": 0.0,
      "text": " So it came up with, uh, the same, uh, title, subtitle, and then the two logos.",
      "tokens": [
        51162,
        407,
        309,
        1361,
        493,
        365,
        11,
        2232,
        11,
        264,
        912,
        11,
        2232,
        11,
        4876,
        11,
        30706,
        306,
        11,
        293,
        550,
        264,
        732,
        40654,
        13,
        51472
      ]
    },
    {
      "id": 158,
      "avg_logprob": -0.2789744436740875,
      "compression_ratio": 1.6096256971359253,
      "end": 592.1400146484375,
      "no_speech_prob": 0.00017400042270310223,
      "seek": 56714,
      "start": 589.4199829101562,
      "temperature": 0.0,
      "text": " And finally, uh, the icon of a penguin.",
      "tokens": [
        51478,
        400,
        2721,
        11,
        2232,
        11,
        264,
        6528,
        295,
        257,
        45752,
        13,
        51614
      ]
    },
    {
      "id": 159,
      "avg_logprob": -0.178909569978714,
      "compression_ratio": 1.8208333253860474,
      "end": 597.3400268554688,
      "no_speech_prob": 0.00020342394418548793,
      "seek": 59214,
      "start": 592.739990234375,
      "temperature": 0.0,
      "text": " Now you're going to see that, uh, the outlines are white over here, which",
      "tokens": [
        50394,
        823,
        291,
        434,
        516,
        281,
        536,
        300,
        11,
        2232,
        11,
        264,
        40125,
        366,
        2418,
        670,
        510,
        11,
        597,
        50624
      ]
    },
    {
      "id": 160,
      "avg_logprob": -0.178909569978714,
      "compression_ratio": 1.8208333253860474,
      "end": 600.0599975585938,
      "no_speech_prob": 0.00020342394418548793,
      "seek": 59214,
      "start": 597.3400268554688,
      "temperature": 0.0,
      "text": " makes the image quite jarring to look at.",
      "tokens": [
        50624,
        1669,
        264,
        3256,
        1596,
        361,
        18285,
        281,
        574,
        412,
        13,
        50760
      ]
    },
    {
      "id": 161,
      "avg_logprob": -0.178909569978714,
      "compression_ratio": 1.8208333253860474,
      "end": 603.7000122070312,
      "no_speech_prob": 0.00020342394418548793,
      "seek": 59214,
      "start": 600.739990234375,
      "temperature": 0.0,
      "text": " What you can do is, and this is going to be in my next video.",
      "tokens": [
        50794,
        708,
        291,
        393,
        360,
        307,
        11,
        293,
        341,
        307,
        516,
        281,
        312,
        294,
        452,
        958,
        960,
        13,
        50942
      ]
    },
    {
      "id": 162,
      "avg_logprob": -0.178909569978714,
      "compression_ratio": 1.8208333253860474,
      "end": 608.5399780273438,
      "no_speech_prob": 0.00020342394418548793,
      "seek": 59214,
      "start": 603.7000122070312,
      "temperature": 0.0,
      "text": " You're going to see when you receive, uh, when you receive an input or when",
      "tokens": [
        50942,
        509,
        434,
        516,
        281,
        536,
        562,
        291,
        4774,
        11,
        2232,
        11,
        562,
        291,
        4774,
        364,
        4846,
        420,
        562,
        51184
      ]
    },
    {
      "id": 163,
      "avg_logprob": -0.178909569978714,
      "compression_ratio": 1.8208333253860474,
      "end": 613.5399780273438,
      "no_speech_prob": 0.00020342394418548793,
      "seek": 59214,
      "start": 608.5399780273438,
      "temperature": 0.0,
      "text": " you receive an image from the model, you can keep iterating on it by passing",
      "tokens": [
        51184,
        291,
        4774,
        364,
        3256,
        490,
        264,
        2316,
        11,
        291,
        393,
        1066,
        17138,
        990,
        322,
        309,
        538,
        8437,
        51434
      ]
    },
    {
      "id": 164,
      "avg_logprob": -0.178909569978714,
      "compression_ratio": 1.8208333253860474,
      "end": 615.5,
      "no_speech_prob": 0.00020342394418548793,
      "seek": 59214,
      "start": 613.5399780273438,
      "temperature": 0.0,
      "text": " more and more prompts to the model.",
      "tokens": [
        51434,
        544,
        293,
        544,
        41095,
        281,
        264,
        2316,
        13,
        51532
      ]
    },
    {
      "id": 165,
      "avg_logprob": -0.178909569978714,
      "compression_ratio": 1.8208333253860474,
      "end": 619.5800170898438,
      "no_speech_prob": 0.00020342394418548793,
      "seek": 59214,
      "start": 615.8200073242188,
      "temperature": 0.0,
      "text": " So let's say in this example, we got the image back, but we don't like",
      "tokens": [
        51548,
        407,
        718,
        311,
        584,
        294,
        341,
        1365,
        11,
        321,
        658,
        264,
        3256,
        646,
        11,
        457,
        321,
        500,
        380,
        411,
        51736
      ]
    },
    {
      "id": 166,
      "avg_logprob": -0.22702190279960632,
      "compression_ratio": 1.658227801322937,
      "end": 623.260009765625,
      "no_speech_prob": 0.0021155287977308035,
      "seek": 61958,
      "start": 619.5800170898438,
      "temperature": 0.0,
      "text": " the white outline or the white background here.",
      "tokens": [
        50364,
        264,
        2418,
        16387,
        420,
        264,
        2418,
        3678,
        510,
        13,
        50548
      ]
    },
    {
      "id": 167,
      "avg_logprob": -0.22702190279960632,
      "compression_ratio": 1.658227801322937,
      "end": 628.9400024414062,
      "no_speech_prob": 0.0021155287977308035,
      "seek": 61958,
      "start": 623.6199951171875,
      "temperature": 0.0,
      "text": " So I can just do a follow-up to the model where we pass the image back and",
      "tokens": [
        50566,
        407,
        286,
        393,
        445,
        360,
        257,
        1524,
        12,
        1010,
        281,
        264,
        2316,
        689,
        321,
        1320,
        264,
        3256,
        646,
        293,
        50832
      ]
    },
    {
      "id": 168,
      "avg_logprob": -0.22702190279960632,
      "compression_ratio": 1.658227801322937,
      "end": 633.6199951171875,
      "no_speech_prob": 0.0021155287977308035,
      "seek": 61958,
      "start": 628.9400024414062,
      "temperature": 0.0,
      "text": " we tell it, Hey, uh, it looks pretty good, but we want it, we want you to",
      "tokens": [
        50832,
        321,
        980,
        309,
        11,
        1911,
        11,
        2232,
        11,
        309,
        1542,
        1238,
        665,
        11,
        457,
        321,
        528,
        309,
        11,
        321,
        528,
        291,
        281,
        51066
      ]
    },
    {
      "id": 169,
      "avg_logprob": -0.22702190279960632,
      "compression_ratio": 1.658227801322937,
      "end": 638.9000244140625,
      "no_speech_prob": 0.0021155287977308035,
      "seek": 61958,
      "start": 633.6199951171875,
      "temperature": 0.0,
      "text": " remove the outline, maybe make the logo more colored and as you iterate two to",
      "tokens": [
        51066,
        4159,
        264,
        16387,
        11,
        1310,
        652,
        264,
        9699,
        544,
        14332,
        293,
        382,
        291,
        44497,
        732,
        281,
        51330
      ]
    },
    {
      "id": 170,
      "avg_logprob": -0.22702190279960632,
      "compression_ratio": 1.658227801322937,
      "end": 642.5,
      "no_speech_prob": 0.0021155287977308035,
      "seek": 61958,
      "start": 638.9000244140625,
      "temperature": 0.0,
      "text": " three times, you're going to soon come to a form that you really like.",
      "tokens": [
        51330,
        1045,
        1413,
        11,
        291,
        434,
        516,
        281,
        2321,
        808,
        281,
        257,
        1254,
        300,
        291,
        534,
        411,
        13,
        51510
      ]
    },
    {
      "id": 171,
      "avg_logprob": -0.22702190279960632,
      "compression_ratio": 1.658227801322937,
      "end": 646.5,
      "no_speech_prob": 0.0021155287977308035,
      "seek": 61958,
      "start": 643.5399780273438,
      "temperature": 0.0,
      "text": " So this is needed in the first few iterations.",
      "tokens": [
        51562,
        407,
        341,
        307,
        2978,
        294,
        264,
        700,
        1326,
        36540,
        13,
        51710
      ]
    },
    {
      "id": 172,
      "avg_logprob": -0.21800324320793152,
      "compression_ratio": 1.6428571939468384,
      "end": 651.8599853515625,
      "no_speech_prob": 3.5912671592086554e-05,
      "seek": 64650,
      "start": 646.739990234375,
      "temperature": 0.0,
      "text": " And the goal is as you're generating more and more thumbnails, you start",
      "tokens": [
        50376,
        400,
        264,
        3387,
        307,
        382,
        291,
        434,
        17746,
        544,
        293,
        544,
        46987,
        11,
        291,
        722,
        50632
      ]
    },
    {
      "id": 173,
      "avg_logprob": -0.21800324320793152,
      "compression_ratio": 1.6428571939468384,
      "end": 657.02001953125,
      "no_speech_prob": 3.5912671592086554e-05,
      "seek": 64650,
      "start": 652.3800048828125,
      "temperature": 0.0,
      "text": " understanding patterns and then you incorporate the fixes to the",
      "tokens": [
        50658,
        3701,
        8294,
        293,
        550,
        291,
        16091,
        264,
        32539,
        281,
        264,
        50890
      ]
    },
    {
      "id": 174,
      "avg_logprob": -0.21800324320793152,
      "compression_ratio": 1.6428571939468384,
      "end": 659.3800048828125,
      "no_speech_prob": 3.5912671592086554e-05,
      "seek": 64650,
      "start": 657.02001953125,
      "temperature": 0.0,
      "text": " issues in your prompt, right?",
      "tokens": [
        50890,
        2663,
        294,
        428,
        12391,
        11,
        558,
        30,
        51008
      ]
    },
    {
      "id": 175,
      "avg_logprob": -0.21800324320793152,
      "compression_ratio": 1.6428571939468384,
      "end": 665.97998046875,
      "no_speech_prob": 3.5912671592086554e-05,
      "seek": 64650,
      "start": 659.6199951171875,
      "temperature": 0.0,
      "text": " So if we go to your prompt here, I can just edit the prompt to say that for my",
      "tokens": [
        51020,
        407,
        498,
        321,
        352,
        281,
        428,
        12391,
        510,
        11,
        286,
        393,
        445,
        8129,
        264,
        12391,
        281,
        584,
        300,
        337,
        452,
        51338
      ]
    },
    {
      "id": 176,
      "avg_logprob": -0.21800324320793152,
      "compression_ratio": 1.6428571939468384,
      "end": 671.0599975585938,
      "no_speech_prob": 3.5912671592086554e-05,
      "seek": 64650,
      "start": 665.97998046875,
      "temperature": 0.0,
      "text": " three icons, make sure the icons are colorful, make sure that don't have an",
      "tokens": [
        51338,
        1045,
        23308,
        11,
        652,
        988,
        264,
        23308,
        366,
        18506,
        11,
        652,
        988,
        300,
        500,
        380,
        362,
        364,
        51592
      ]
    },
    {
      "id": 177,
      "avg_logprob": -0.2495117336511612,
      "compression_ratio": 1.7169811725616455,
      "end": 677.6599731445312,
      "no_speech_prob": 0.002050669165328145,
      "seek": 67106,
      "start": 671.0599975585938,
      "temperature": 0.0,
      "text": " outline, um, and make sure that, uh, the, uh, the background for every icon is",
      "tokens": [
        50364,
        16387,
        11,
        1105,
        11,
        293,
        652,
        988,
        300,
        11,
        2232,
        11,
        264,
        11,
        2232,
        11,
        264,
        3678,
        337,
        633,
        6528,
        307,
        50694
      ]
    },
    {
      "id": 178,
      "avg_logprob": -0.2495117336511612,
      "compression_ratio": 1.7169811725616455,
      "end": 678.2999877929688,
      "no_speech_prob": 0.002050669165328145,
      "seek": 67106,
      "start": 677.6599731445312,
      "temperature": 0.0,
      "text": " transparent.",
      "tokens": [
        50694,
        12737,
        13,
        50726
      ]
    },
    {
      "id": 179,
      "avg_logprob": -0.2495117336511612,
      "compression_ratio": 1.7169811725616455,
      "end": 683.8599853515625,
      "no_speech_prob": 0.002050669165328145,
      "seek": 67106,
      "start": 678.2999877929688,
      "temperature": 0.0,
      "text": " So something like this, not something like this, this is going to be a work in",
      "tokens": [
        50726,
        407,
        746,
        411,
        341,
        11,
        406,
        746,
        411,
        341,
        11,
        341,
        307,
        516,
        281,
        312,
        257,
        589,
        294,
        51004
      ]
    },
    {
      "id": 180,
      "avg_logprob": -0.2495117336511612,
      "compression_ratio": 1.7169811725616455,
      "end": 684.4600219726562,
      "no_speech_prob": 0.002050669165328145,
      "seek": 67106,
      "start": 683.8599853515625,
      "temperature": 0.0,
      "text": " progress.",
      "tokens": [
        51004,
        4205,
        13,
        51034
      ]
    },
    {
      "id": 181,
      "avg_logprob": -0.2495117336511612,
      "compression_ratio": 1.7169811725616455,
      "end": 687.780029296875,
      "no_speech_prob": 0.002050669165328145,
      "seek": 67106,
      "start": 684.5,
      "temperature": 0.0,
      "text": " The more you see the output, the better you can refine the prompt.",
      "tokens": [
        51036,
        440,
        544,
        291,
        536,
        264,
        5598,
        11,
        264,
        1101,
        291,
        393,
        33906,
        264,
        12391,
        13,
        51200
      ]
    },
    {
      "id": 182,
      "avg_logprob": -0.2495117336511612,
      "compression_ratio": 1.7169811725616455,
      "end": 691.9400024414062,
      "no_speech_prob": 0.002050669165328145,
      "seek": 67106,
      "start": 688.0999755859375,
      "temperature": 0.0,
      "text": " And hopefully at some point you're going to reach a sweet balance between, uh,",
      "tokens": [
        51216,
        400,
        4696,
        412,
        512,
        935,
        291,
        434,
        516,
        281,
        2524,
        257,
        3844,
        4772,
        1296,
        11,
        2232,
        11,
        51408
      ]
    },
    {
      "id": 183,
      "avg_logprob": -0.2495117336511612,
      "compression_ratio": 1.7169811725616455,
      "end": 694.97998046875,
      "no_speech_prob": 0.002050669165328145,
      "seek": 67106,
      "start": 691.97998046875,
      "temperature": 0.0,
      "text": " quality and the number of times you need to iterate.",
      "tokens": [
        51410,
        3125,
        293,
        264,
        1230,
        295,
        1413,
        291,
        643,
        281,
        44497,
        13,
        51560
      ]
    },
    {
      "id": 184,
      "avg_logprob": -0.2495117336511612,
      "compression_ratio": 1.7169811725616455,
      "end": 696.8200073242188,
      "no_speech_prob": 0.002050669165328145,
      "seek": 67106,
      "start": 696.5399780273438,
      "temperature": 0.0,
      "text": " Okay.",
      "tokens": [
        51638,
        1033,
        13,
        51652
      ]
    },
    {
      "id": 185,
      "avg_logprob": -0.2495117336511612,
      "compression_ratio": 1.7169811725616455,
      "end": 698.6199951171875,
      "no_speech_prob": 0.002050669165328145,
      "seek": 67106,
      "start": 696.8200073242188,
      "temperature": 0.0,
      "text": " So that's everything I had for you today.",
      "tokens": [
        51652,
        407,
        300,
        311,
        1203,
        286,
        632,
        337,
        291,
        965,
        13,
        51742
      ]
    },
    {
      "id": 186,
      "avg_logprob": -0.2495117336511612,
      "compression_ratio": 1.7169811725616455,
      "end": 699.8599853515625,
      "no_speech_prob": 0.002050669165328145,
      "seek": 67106,
      "start": 698.6599731445312,
      "temperature": 0.0,
      "text": " Hopefully this was helpful.",
      "tokens": [
        51744,
        10429,
        341,
        390,
        4961,
        13,
        51804
      ]
    },
    {
      "id": 187,
      "avg_logprob": -0.24621286988258362,
      "compression_ratio": 1.4530386924743652,
      "end": 704.8599853515625,
      "no_speech_prob": 0.000709596264641732,
      "seek": 69986,
      "start": 700.1400146484375,
      "temperature": 0.0,
      "text": " I will have both the diagram and the code linked in the description below, and you",
      "tokens": [
        50378,
        286,
        486,
        362,
        1293,
        264,
        10686,
        293,
        264,
        3089,
        9408,
        294,
        264,
        3855,
        2507,
        11,
        293,
        291,
        50614
      ]
    },
    {
      "id": 188,
      "avg_logprob": -0.24621286988258362,
      "compression_ratio": 1.4530386924743652,
      "end": 707.9400024414062,
      "no_speech_prob": 0.000709596264641732,
      "seek": 69986,
      "start": 704.8599853515625,
      "temperature": 0.0,
      "text": " can also find both of them on my website if you're interested.",
      "tokens": [
        50614,
        393,
        611,
        915,
        1293,
        295,
        552,
        322,
        452,
        3144,
        498,
        291,
        434,
        3102,
        13,
        50768
      ]
    },
    {
      "id": 189,
      "avg_logprob": -0.24621286988258362,
      "compression_ratio": 1.4530386924743652,
      "end": 709.3800048828125,
      "no_speech_prob": 0.000709596264641732,
      "seek": 69986,
      "start": 708.6199951171875,
      "temperature": 0.0,
      "text": " Uh, that's it.",
      "tokens": [
        50802,
        4019,
        11,
        300,
        311,
        309,
        13,
        50840
      ]
    },
    {
      "id": 190,
      "avg_logprob": -0.24621286988258362,
      "compression_ratio": 1.4530386924743652,
      "end": 710.1799926757812,
      "no_speech_prob": 0.000709596264641732,
      "seek": 69986,
      "start": 709.4199829101562,
      "temperature": 0.0,
      "text": " I'll end it here.",
      "tokens": [
        50842,
        286,
        603,
        917,
        309,
        510,
        13,
        50880
      ]
    },
    {
      "id": 191,
      "avg_logprob": -0.24621286988258362,
      "compression_ratio": 1.4530386924743652,
      "end": 711.3400268554688,
      "no_speech_prob": 0.000709596264641732,
      "seek": 69986,
      "start": 710.219970703125,
      "temperature": 0.0,
      "text": " Thank you so much for watching.",
      "tokens": [
        50882,
        1044,
        291,
        370,
        709,
        337,
        1976,
        13,
        50938
      ]
    },
    {
      "id": 192,
      "avg_logprob": -0.24621286988258362,
      "compression_ratio": 1.4530386924743652,
      "end": 712.4600219726562,
      "no_speech_prob": 0.000709596264641732,
      "seek": 69986,
      "start": 711.3800048828125,
      "temperature": 0.0,
      "text": " Talk to you all in the next one.",
      "tokens": [
        50940,
        8780,
        281,
        291,
        439,
        294,
        264,
        958,
        472,
        13,
        50994
      ]
    },
    {
      "id": 193,
      "avg_logprob": -0.24621286988258362,
      "compression_ratio": 1.4530386924743652,
      "end": 712.97998046875,
      "no_speech_prob": 0.000709596264641732,
      "seek": 69986,
      "start": 712.5800170898438,
      "temperature": 0.0,
      "text": " Take care.",
      "tokens": [
        51000,
        3664,
        1127,
        13,
        51020
      ]
    },
    {
      "id": 194,
      "avg_logprob": -0.24621286988258362,
      "compression_ratio": 1.4530386924743652,
      "end": 713.3800048828125,
      "no_speech_prob": 0.000709596264641732,
      "seek": 69986,
      "start": 713.0599975585938,
      "temperature": 0.0,
      "text": " Bye bye.",
      "tokens": [
        51024,
        4621,
        6543,
        13,
        51040
      ]
    }
  ],
  "usage": {
    "seconds": 714.0,
    "type": "duration"
  },
  "words": null,
  "task": "transcribe"
}